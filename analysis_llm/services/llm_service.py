"""
LLM Analysis Service

ì´ ëª¨ë“ˆì€ LLMì„ í™œìš©í•œ ë°ì´í„° ë¶„ì„ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ì„ ë‹´ë‹¹í•˜ëŠ”
LLMAnalysisService í´ë˜ìŠ¤ë¥¼ ì œê³µí•©ë‹ˆë‹¤.

ê¸°ì¡´ main.pyì˜ LLM ê´€ë ¨ ë¶„ì„ ë¡œì§ì„ ëª¨ë“ˆí™”í•œ ê²ƒì…ë‹ˆë‹¤.
"""

from __future__ import annotations

import logging
import os

# ì„ì‹œë¡œ ì ˆëŒ€ import ì‚¬ìš© (ë‚˜ì¤‘ì— íŒ¨í‚¤ì§€ êµ¬ì¡° ì •ë¦¬ ì‹œ ìˆ˜ì •)
import sys
from abc import ABC, abstractmethod
from datetime import datetime
from typing import Any, Dict, List, Optional, Union

import pandas as pd

from ..exceptions import LLMError, ServiceError
from ..repositories import LLMClient, LLMRepository

# ë¡œê¹… ì„¤ì •
logger = logging.getLogger(__name__)


class LLMAnalysisError(ServiceError):
    """
    LLM ë¶„ì„ ê´€ë ¨ ì˜¤ë¥˜ ì˜ˆì™¸ í´ë˜ìŠ¤

    LLM ë¶„ì„ ê³¼ì •ì—ì„œ ë°œìƒí•˜ëŠ” ì˜¤ë¥˜ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤.
    """

    def __init__(
        self,
        message: str,
        details: Optional[Union[str, Dict[str, Any]]] = None,
        analysis_type: Optional[str] = None,
        prompt_preview: Optional[str] = None,
    ) -> None:
        """
        LLMAnalysisError ì´ˆê¸°í™”

        Args:
            message (str): ì˜¤ë¥˜ ë©”ì‹œì§€
            details (Optional[Union[str, Dict[str, Any]]]): ì¶”ê°€ ìƒì„¸ ì •ë³´
            analysis_type (Optional[str]): ë¶„ì„ ìœ í˜•
            prompt_preview (Optional[str]): í”„ë¡¬í”„íŠ¸ ë¯¸ë¦¬ë³´ê¸°
        """
        super().__init__(message=message, details=details, service_name="LLMAnalysisService", operation="analyze_data")
        self.analysis_type = analysis_type
        self.prompt_preview = prompt_preview

        logger.error("LLMAnalysisError ë°œìƒ: %s (ë¶„ì„ìœ í˜•: %s)", message, analysis_type)

    def to_dict(self) -> Dict[str, Any]:
        """ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ ë³€í™˜"""
        data = super().to_dict()
        data.update({"analysis_type": self.analysis_type, "prompt_preview": self.prompt_preview})
        return data


class BasePromptStrategy(ABC):
    """
    í”„ë¡¬í”„íŠ¸ ìƒì„± ì „ëµ ì¶”ìƒ ê¸°ë³¸ í´ë˜ìŠ¤

    ë‹¤ì–‘í•œ ë¶„ì„ ìœ í˜•ì— ë”°ë¥¸ í”„ë¡¬í”„íŠ¸ ìƒì„± ì „ëµì„ ì •ì˜í•©ë‹ˆë‹¤.
    Strategy Patternì„ êµ¬í˜„í•©ë‹ˆë‹¤.
    """

    @abstractmethod
    def build_prompt(self, processed_df: pd.DataFrame, n1_range: str, n_range: str, **kwargs) -> str:
        """
        í”„ë¡¬í”„íŠ¸ ìƒì„±

        Args:
            processed_df (pd.DataFrame): ì²˜ë¦¬ëœ PEG ë°ì´í„°
            n1_range (str): N-1 ê¸°ê°„ ë¬¸ìì—´
            n_range (str): N ê¸°ê°„ ë¬¸ìì—´
            **kwargs: ì¶”ê°€ ë§¤ê°œë³€ìˆ˜

        Returns:
            str: ìƒì„±ëœ í”„ë¡¬í”„íŠ¸
        """

    @abstractmethod
    def get_strategy_name(self) -> str:
        """ì „ëµ ì´ë¦„ ë°˜í™˜"""

    def validate_input_data(self, processed_df: pd.DataFrame) -> bool:
        """ì…ë ¥ ë°ì´í„° ìœ íš¨ì„± ê²€ì¦"""
        if processed_df is None or processed_df.empty:
            return False

        required_columns = ["peg_name", "avg_value", "period"]
        missing_columns = [col for col in required_columns if col not in processed_df.columns]

        if missing_columns:
            logger.warning("í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: %s", missing_columns)
            return False

        return True

    def format_dataframe_for_prompt(self, df: pd.DataFrame, max_rows: Optional[int] = None) -> str:
        """DataFrameì„ í”„ë¡¬í”„íŠ¸ìš© ë¬¸ìì—´ë¡œ í¬ë§·íŒ…"""
        if df.empty:
            return "ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."

        # í–‰ ìˆ˜ ì œí•œ
        if max_rows and len(df) > max_rows:
            df = df.head(max_rows)
            logger.debug("DataFrame í–‰ ìˆ˜ ì œí•œ ì ìš©: %dí–‰ìœ¼ë¡œ ë‹¨ì¶•", max_rows)

        # í…Œì´ë¸” í˜•íƒœë¡œ ë³€í™˜
        formatted = df.to_string(index=False, max_cols=10)
        logger.debug("DataFrame í¬ë§·íŒ… ì™„ë£Œ: %dí–‰, %dì»¬ëŸ¼", len(df), len(df.columns))

        return formatted


class EnhancedAnalysisPromptStrategy(BasePromptStrategy):
    """
    ê³ ë„í™”ëœ ì¢…í•© ë¶„ì„ í”„ë¡¬í”„íŠ¸ ì „ëµ
    (ê¸°ì¡´ main.pyì˜ create_llm_analysis_prompt_enhanced ë¡œì§)
    """

    def get_strategy_name(self) -> str:
        return "enhanced_analysis"

    def build_prompt(self, processed_df: pd.DataFrame, n1_range: str, n_range: str, **kwargs) -> str:
        """ê³ ë„í™”ëœ ì¢…í•© ë¶„ì„ í”„ë¡¬í”„íŠ¸ ìƒì„± (YAML í…œí”Œë¦¿ ì‚¬ìš©)"""
        logger.info("EnhancedAnalysisPromptStrategy.build_prompt() í˜¸ì¶œ")

        if not self.validate_input_data(processed_df):
            raise LLMAnalysisError("ì…ë ¥ ë°ì´í„°ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤", analysis_type=self.get_strategy_name())

        # ğŸ” í† í° ìµœì í™”: change_pctê°€ NULLì¸ PEGë“¤ì„ í”„ë¡¬í”„íŠ¸ì—ì„œ ì œì™¸
        original_peg_count = len(processed_df["peg_name"].unique())
        
        if "change_pct" in processed_df.columns:
            # change_pctê°€ NULLì´ ì•„ë‹Œ í–‰ë“¤ë§Œ í•„í„°ë§
            filtered_df = processed_df[pd.notna(processed_df["change_pct"])].copy()
            filtered_peg_count = len(filtered_df["peg_name"].unique())
            excluded_peg_count = original_peg_count - filtered_peg_count
            
            if excluded_peg_count > 0:
                logger.info(
                    f"ğŸ” í† í° ìµœì í™”: change_pct=NULLì¸ PEG {excluded_peg_count}ê°œ ì œì™¸ "
                    f"(ì „ì²´ {original_peg_count}ê°œ â†’ í”„ë¡¬í”„íŠ¸ {filtered_peg_count}ê°œ)"
                )
                
                # ì œì™¸ëœ PEG ì´ë¦„ë“¤ ìƒì„¸ ë¡œê¹… (DEBUG2 ë ˆë²¨)
                from config.logging_config import log_at_debug2
                excluded_pegs = set(processed_df["peg_name"].unique()) - set(filtered_df["peg_name"].unique())
                log_at_debug2(
                    logger,
                    f"ğŸ” í”„ë¡¬í”„íŠ¸ì—ì„œ ì œì™¸ëœ PEG ëª©ë¡ ({len(excluded_pegs)}ê°œ): {sorted(list(excluded_pegs))}"
                )
                
                # í•„í„°ë§ëœ ë°ì´í„° ì‚¬ìš©
                processed_df = filtered_df
            else:
                logger.info("ğŸ” í† í° ìµœì í™”: ì œì™¸í•  PEG ì—†ìŒ (ëª¨ë“  PEGì˜ change_pctê°€ ìœ íš¨í•¨)")
        else:
            logger.warning("ğŸ” í† í° ìµœì í™”: change_pct ì»¬ëŸ¼ì´ ì—†ì–´ í•„í„°ë§ì„ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

        # í•„í„°ë§ í›„ ë°ì´í„°ê°€ ë¹„ì–´ìˆëŠ”ì§€ í™•ì¸
        if processed_df.empty:
            raise LLMAnalysisError(
                "í•„í„°ë§ í›„ ë¶„ì„í•  PEG ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ëª¨ë“  PEGì˜ change_pctê°€ NULLì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
                analysis_type=self.get_strategy_name()
            )

        # ë°ì´í„° í¬ë§·íŒ… - ëª¨ë“  PEG í¬í•¨ (ë°ì´í„° ìœ ì‹¤ ë°©ì§€)
        preview_cols = [c for c in processed_df.columns if c in ("peg_name", "avg_value", "period", "change_pct")]
        if not preview_cols:
            preview_cols = list(processed_df.columns)[:6]

        # ëª¨ë“  PEGë¥¼ í¬í•¨í•˜ë„ë¡ ìˆ˜ì • (í–‰ ìˆ˜ ì œí•œ ì œê±°)
        # ê¸°ì¡´: preview_rows = int(os.getenv("PROMPT_PREVIEW_ROWS", "200"))
        # ê¸°ì¡´: preview_df = processed_df[preview_cols].head(preview_rows)
        preview_df = processed_df[preview_cols]  # ëª¨ë“  ë°ì´í„° í¬í•¨
        logger.info("í”„ë¡¬í”„íŠ¸ ë°ì´í„° ì¤€ë¹„: ì „ì²´ %dí–‰ í¬í•¨ (ëª¨ë“  PEG í¬í•¨)", len(preview_df))
        data_preview = self.format_dataframe_for_prompt(preview_df)

        # YAML í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì‚¬ìš©
        try:
            from analysis_llm.config.prompt_loader import PromptLoader
            prompt_loader = PromptLoader()
            prompt_template = prompt_loader.get_prompt_template("enhanced")
            
            # ë³€ìˆ˜ ì¹˜í™˜
            prompt = prompt_template.format(
                n1_range=n1_range,
                n_range=n_range,
                data_preview=data_preview,
                selected_pegs_str="All PEGs"  # enhanced í”„ë¡¬í”„íŠ¸ì—ì„œëŠ” ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
            )
            
            logger.info("YAML í…œí”Œë¦¿ ê¸°ë°˜ enhanced í”„ë¡¬í”„íŠ¸ ìƒì„± ì™„ë£Œ: %dì", len(prompt))
            return prompt
            
        except Exception as e:
            logger.warning("YAML í”„ë¡¬í”„íŠ¸ ë¡œë“œ ì‹¤íŒ¨, í•˜ë“œì½”ë”©ëœ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©: %s", e)
            
            # í´ë°±: í•˜ë“œì½”ë”©ëœ í”„ë¡¬í”„íŠ¸ ì‚¬ìš© (YAMLê³¼ ë™ì¼í•œ êµ¬ì¡°)
            prompt = f"""[í˜ë¥´ì†Œë‚˜ ë° ì„ë¬´]
ë‹¹ì‹ ì€ Tier-1 ì´ë™í†µì‹ ì‚¬ì—ì„œ 20ë…„ ê²½ë ¥ì„ ê°€ì§„ ìˆ˜ì„ ë„¤íŠ¸ì›Œí¬ ì§„ë‹¨ ë° ìµœì í™” ì „ëµê°€ì…ë‹ˆë‹¤. ë‹¹ì‹ ì˜ ì„ë¬´ëŠ” ì‹ ì†í•œ ê·¼ë³¸ ì›ì¸ ë¶„ì„(RCA)ì„ ìˆ˜í–‰í•˜ê³ , ê³ ê° ì˜í–¥ë„ì— ë”°ë¼ ë¬¸ì œì˜ ìš°ì„ ìˆœìœ„ë¥¼ ì •í•˜ë©°, í˜„ì¥ ì—”ì§€ë‹ˆì–´ë§ íŒ€ì„ ìœ„í•œ ëª…í™•í•˜ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ê³„íšì„ ì œê³µí•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ë‹¹ì‹ ì˜ ë¶„ì„ì€ 3GPP í‘œì¤€(TS 36/38.xxx ì‹œë¦¬ì¦ˆ)ê³¼ ìš´ì˜ ëª¨ë²” ì‚¬ë¡€ì— ë¶€í•©í•´ì•¼ í•˜ë©°, ì—„ê²©í•˜ê³  ì¦ê±°ì— ê¸°ë°˜í•´ì•¼ í•©ë‹ˆë‹¤.

[ì»¨í…ìŠ¤íŠ¸ ë° ê°€ì •]
- ë¶„ì„ ëŒ€ìƒì€ ë‘ ê¸°ê°„ ë™ì•ˆì˜ PEG(Performance Event Group) ì¹´ìš´í„° ë³€í™”ì…ë‹ˆë‹¤.
- ê¸°ê°„ n-1: {n1_range}
- ê¸°ê°„ n: {n_range}
- í•µì‹¬ ê°€ì •: ë‘ ê¸°ê°„ì€ ë™ì¼í•œ ì‹œí—˜í™˜ê²½(ë™ì¼ í•˜ë“œì›¨ì–´, ê¸°ë³¸ íŒŒë¼ë¯¸í„°, íŠ¸ë˜í”½ ëª¨ë¸)ì—ì„œ ìˆ˜í–‰ë˜ì—ˆìŠµë‹ˆë‹¤.
- ì…ë ¥ ë°ì´í„°ëŠ” PEG ë‹¨ìœ„ë¡œ ì§‘ê³„ëœ í‰ê· ê°’ì´ë©°, ê°œë³„ ì…€(cell) ë°ì´í„°ëŠ” í¬í•¨ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. ë”°ë¼ì„œ ì…€ ë‹¨ìœ„ì˜ íŠ¹ì • ë¬¸ì œ ì‹ë³„ì€ ë¶ˆê°€ëŠ¥í•˜ë©°, ì§‘ê³„ ë°ì´í„° ê¸°ë°˜ì˜ ê±°ì‹œì  ë¶„ì„ì„ ìˆ˜í–‰í•´ì•¼ í•©ë‹ˆë‹¤.

[ì…ë ¥ ë°ì´í„°]
- ì»¬ëŸ¼ ì„¤ëª…: peg_name(PEG ì´ë¦„), avg_n_minus_1(ê¸°ê°„ n-1 í‰ê· ), avg_n(ê¸°ê°„ n í‰ê· ), diff(ë³€í™”ëŸ‰), pct_change(ë³€í™”ìœ¨)
- ë°ì´í„° í…Œì´ë¸”:
{data_preview}

[ë¶„ì„ ì›Œí¬í”Œë¡œìš° ì§€ì¹¨]
ì•„ë˜ì˜ 4ë‹¨ê³„ ì—°ì‡„ì  ì‚¬ê³ (Chain-of-Thought) ì§„ë‹¨ ì›Œí¬í”Œë¡œìš°ë¥¼ ì—„ê²©íˆ ë”°ë¼ì„œ ë¶„ì„ì„ ìˆ˜í–‰í•˜ì‹­ì‹œì˜¤.

# [LLM-1] ë¬¸ì œ ë¶„ë¥˜ ë° ì¤‘ìš”ë„ í‰ê°€ (Triage and Significance Assessment)
ë¨¼ì €, ì…ë ¥ í…Œì´ë¸”ì˜ ëª¨ë“  PEGë¥¼ ê²€í† í•˜ì—¬ ê°€ì¥ ì‹¬ê°í•œ 'ë¶€ì •ì ' ë³€í™”ë¥¼ ë³´ì¸ ìƒìœ„ 3~5ê°œì˜ PEGë¥¼ ì‹ë³„í•˜ì‹­ì‹œì˜¤. 'ì¤‘ìš”ë„'ëŠ” 'pct_change'ì˜ ì ˆëŒ€ê°’ í¬ê¸°ì™€ í•´ë‹¹ PEGì˜ ìš´ì˜ìƒ 'ê³ ê° ì˜í–¥ë„'ë¥¼ ì¢…í•©í•˜ì—¬ íŒë‹¨í•©ë‹ˆë‹¤. ê° PEGê°€ ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” 3GPP ì„œë¹„ìŠ¤ ë²”ì£¼(Accessibility, Retainability, Mobility, Integrity, Latency)ì— ë”°ë¼ ì˜í–¥ë„ë¥¼ ë¶„ë¥˜í•˜ê³ , ê°€ì¥ ì‹œê¸‰í•˜ê²Œ ë‹¤ë£¨ì–´ì•¼ í•  ë¬¸ì œë¥¼ ì„ ì •í•˜ì‹­ì‹œì˜¤.

# [LLM-2] ì£¼ì œë³„ ê·¸ë£¹í™” ë° í•µì‹¬ ê°€ì„¤ ìƒì„± (Thematic Grouping and Primary Hypothesis Generation)
[LLM-1]ì—ì„œ ì‹ë³„ëœ ìš°ì„ ìˆœìœ„ê°€ ë†’ì€ ë¬¸ì œë“¤ì— ëŒ€í•´, ì—°ê´€ëœ PEGë“¤ì„ ë…¼ë¦¬ì ìœ¼ë¡œ ê·¸ë£¹í™”í•˜ì—¬ 'ì§„ë‹¨ ì£¼ì œ(Diagnostic Theme)'ë¥¼ ì •ì˜í•˜ì‹­ì‹œì˜¤. (ì˜ˆ: ë‹¤ìˆ˜ì˜ ì ‘ì† ê´€ë ¨ PEG ì•…í™” -> 'Accessibility Degradation' ì£¼ì œ). ê° ì£¼ì œì— ëŒ€í•´, 3GPP í˜¸ ì²˜ë¦¬ ì ˆì°¨(Call Flow) ë° ìš´ì˜ ê²½í—˜ì— ê¸°ë°˜í•˜ì—¬ ê°€ì¥ ê°œì—°ì„± ë†’ì€ ë‹¨ì¼ 'í•µì‹¬ ê°€ì„¤(Primary Hypothesis)'ì„ ìˆ˜ë¦½í•˜ì‹­ì‹œì˜¤. ì´ ê°€ì„¤ì€ êµ¬ì²´ì ì´ê³  ê²€ì¦ ê°€ëŠ¥í•´ì•¼ í•©ë‹ˆë‹¤.

# [LLM-3] ì‹œìŠ¤í…œì  ìš”ì¸ ë¶„ì„ ë° êµë€ ë³€ìˆ˜ ê³ ë ¤ (Systemic Factor Analysis & Confounding Variable Assessment)
ìˆ˜ë¦½í•œ í•µì‹¬ ê°€ì„¤ì„ ê²€ì¦í•˜ê¸° ìœ„í•´, ì „ì²´ ë°ì´í„° í…Œì´ë¸”ì—ì„œ ê°€ì„¤ì„ ë’·ë°›ì¹¨í•˜ê±°ë‚˜(supporting evidence) ë°˜ë°•í•˜ëŠ”(contradictory evidence) ë‹¤ë¥¸ PEG ë³€í™”ë¥¼ ë¶„ì„í•˜ì‹­ì‹œì˜¤. ë˜í•œ, 'ë™ì¼ í™˜ê²½' ê°€ì •ì´ ê¹¨ì§ˆ ìˆ˜ ìˆëŠ” ì ì¬ì  êµë€ ìš”ì¸(ì˜ˆ: ë¼ìš°íŒ… ì •ì±… ë³€ê²½, ì†Œí”„íŠ¸ì›¨ì–´ ë§ˆì´ë„ˆ íŒ¨ì¹˜, íŠ¹ì • íŒŒë¼ë¯¸í„° ë¡¤ë°±, ë‹¨ë§ê¸° ë¯¹ìŠ¤ ë³€í™”)ì„ ëª…ì‹œì ìœ¼ë¡œ ê³ ë ¤í•˜ê³ , ì´ëŸ¬í•œ ìš”ì¸ë“¤ì´ í˜„ì¬ ë¬¸ì œì˜ ì›ì¸ì¼ ê°€ëŠ¥ì„±ì´ ë†’ì€ì§€ ë‚®ì€ì§€, ê·¸ë¦¬ê³  ê·¸ íŒë‹¨ì˜ ê·¼ê±°ëŠ” ë¬´ì—‡ì¸ì§€ ë…¼ë¦¬ì ìœ¼ë¡œ ê¸°ìˆ í•˜ì‹­ì‹œì˜¤.

# [LLM-4] ì¦ê±° ê¸°ë°˜ì˜ ê²€ì¦ ê³„íš ìˆ˜ë¦½ (Formulation of an Evidence-Based Verification Plan)
ê° í•µì‹¬ ê°€ì„¤ì— ëŒ€í•´, í˜„ì¥ ì—”ì§€ë‹ˆì–´ê°€ ì¦‰ì‹œ ìˆ˜í–‰í•  ìˆ˜ ìˆëŠ” êµ¬ì²´ì ì´ê³  ìš°ì„ ìˆœìœ„ê°€ ë¶€ì—¬ëœ 'ê²€ì¦ ê³„íš'ì„ ìˆ˜ë¦½í•˜ì‹­ì‹œì˜¤. ì¡°ì¹˜ëŠ” ë°˜ë“œì‹œ êµ¬ì²´ì ì´ì–´ì•¼ í•©ë‹ˆë‹¤. (ì˜ˆ: 'ë¡œê·¸ í™•ì¸' ëŒ€ì‹  'íŠ¹ì • ì¹´ìš´í„°(pmRachAtt) ì¶”ì´ ë¶„ì„'). ì¡°ì¹˜ë³„ë¡œ P1(ì¦‰ì‹œ ì¡°ì¹˜), P2(ì‹¬ì¸µ ì¡°ì‚¬), P3(ì •ê¸° ê°ì‚¬)ì™€ ê°™ì€ ìš°ì„ ìˆœìœ„ë¥¼ ë¶€ì—¬í•˜ê³ , í•„ìš”í•œ ë°ì´í„°(ì¹´ìš´í„°, íŒŒë¼ë¯¸í„° ë“±)ë‚˜ ë„êµ¬ë¥¼ ëª…ì‹œí•˜ì‹­ì‹œì˜¤.

[ì¶œë ¥ í˜•ì‹ ì œì•½]
- ë¶„ì„ ê²°ê³¼ëŠ” ë°˜ë“œì‹œ ì•„ë˜ì˜ JSON ìŠ¤í‚¤ë§ˆë¥¼ ì •í™•íˆ ì¤€ìˆ˜í•˜ì—¬ ìƒì„±í•´ì•¼ í•©ë‹ˆë‹¤.
- ëª¨ë“  ë¬¸ìì—´ ê°’ì€ í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ì‹­ì‹œì˜¤.
- ê° í•„ë“œì— ëŒ€í•œ ì„¤ëª…ê³¼ ì—´ê±°í˜•(Enum) ê°’ì„ ë°˜ë“œì‹œ ë”°ë¥´ì‹­ì‹œì˜¤.

{{
  "executive_summary": "ë„¤íŠ¸ì›Œí¬ ìƒíƒœ ë³€í™”ì™€ ì‹ë³„ëœ ê°€ì¥ ì¹˜ëª…ì ì¸ ë¬¸ì œì— ëŒ€í•œ 1-2 ë¬¸ì¥ì˜ ìµœìƒìœ„ ìš”ì•½",
  "diagnostic_findings": [
    {{
      "primary_hypothesis": "ê°€ì¥ ê°€ëŠ¥ì„± ë†’ì€ ë‹¨ì¼ ê·¼ë³¸ ì›ì¸ ê°€ì„¤",
      "supporting_evidence": "ë°ì´í„° í…Œì´ë¸” ë‚´ì—ì„œ ê°€ì„¤ì„ ë’·ë°›ì¹¨í•˜ëŠ” ë‹¤ë¥¸ PEG ë³€í™”ë‚˜ ë…¼ë¦¬ì  ê·¼ê±°",
      "confounding_factors_assessment": "êµë€ ë³€ìˆ˜ë“¤ì˜ ê°€ëŠ¥ì„±ì— ëŒ€í•œ í‰ê°€ ë° ê·¸ ê·¼ê±°"
    }}
  ],
  "recommended_actions": [
    {{
      "priority": "P1|P2|P3",
      "action": "êµ¬ì²´ì  ì‹¤í–‰ í•­ëª©",
      "details": "í•„ìš” ë°ì´í„°/ë„êµ¬ ë° ìˆ˜í–‰ ë°©ë²•"
    }}
  ]
}}"""

            logger.info("í•˜ë“œì½”ë”©ëœ enhanced í”„ë¡¬í”„íŠ¸ ìƒì„± ì™„ë£Œ: %dì", len(prompt))
            return prompt


# class SpecificPEGsAnalysisPromptStrategy(BasePromptStrategy):
#     """
#     íŠ¹ì • PEG ì „ìš© ë¶„ì„ í”„ë¡¬í”„íŠ¸ ì „ëµ
#     (ê¸°ì¡´ main.pyì˜ create_llm_analysis_prompt_specific_pegs ë¡œì§)
#     """

#     def get_strategy_name(self) -> str:
#         return "specific_pegs_analysis"

#     def build_prompt(
#         self,
#         processed_df: pd.DataFrame,
#         n1_range: str,
#         n_range: str,
#         **kwargs,
#     ) -> str:
#         """íŠ¹ì • PEG ì „ìš© ë¶„ì„ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
#         logger.info("SpecificPEGsAnalysisPromptStrategy.build_prompt() í˜¸ì¶œ")

#         if not self.validate_input_data(processed_df):
#             raise LLMAnalysisError("ì…ë ¥ ë°ì´í„°ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤", analysis_type=self.get_strategy_name())

#         if processed_df.empty:
#             raise LLMAnalysisError(
#                 f"ë¶„ì„í•  PEG ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.",
#                 analysis_type=self.get_strategy_name(),
#             )

#         # ë°ì´í„° í¬ë§·íŒ…
#         preview_rows = int(os.getenv("PROMPT_PREVIEW_ROWS", "200"))
#         preview_df = processed_df.head(preview_rows)
#         data_preview = self.format_dataframe_for_prompt(preview_df)

#         # ì„ íƒëœ PEG ëª©ë¡ (DataFrameì—ì„œ ì§ì ‘ ì¶”ì¶œ)
#         pegs_list = ", ".join(processed_df["peg_name"].unique())

#         # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
#         prompt = f"""
# 3GPP Cell ì„±ëŠ¥ íŠ¹ì • PEG ì§‘ì¤‘ ë¶„ì„

# **ë¶„ì„ ëŒ€ìƒ PEG:** {pegs_list}

# **ë¶„ì„ ê¸°ê°„:**
# - N-1 ê¸°ê°„: {n1_range}
# - N ê¸°ê°„: {n_range}

# **ì„ íƒëœ PEG ë°ì´í„°:**
# {data_preview}

# **ì§‘ì¤‘ ë¶„ì„ ìš”êµ¬ì‚¬í•­:**
# ì„ íƒëœ PEGë“¤ì— ëŒ€í•´ ë‹¤ìŒ í˜•ì‹ì˜ JSON ì‘ë‹µì„ ìƒì„±í•´ì£¼ì„¸ìš”:

# {{
#   "summary": "ì„ íƒëœ PEGë“¤ì˜ ì„±ëŠ¥ ìš”ì•½",
#   "peg_analysis": {{
#     "PEG_NAME": {{
#       "status": "GOOD/WARNING/CRITICAL",
#       "n1_value": "N-1 ê¸°ê°„ ê°’",
#       "n_value": "N ê¸°ê°„ ê°’",
#       "change_analysis": "ë³€í™” ë¶„ì„",
#       "recommendations": ["PEGë³„ ê¶Œê³ ì‚¬í•­"]
#     }}
#   }},
#   "cross_peg_insights": [
#     "PEGê°„ ìƒê´€ê´€ê³„ ë° íŒ¨í„´ ë¶„ì„"
#   ],
#   "focused_recommendations": [
#     "ì„ íƒëœ PEGë“¤ì— íŠ¹í™”ëœ ê¶Œê³ ì‚¬í•­"
#   ],
#   "technical_details": {{
#     "measurement_quality": "ì¸¡ì • í’ˆì§ˆ í‰ê°€",
#     "data_completeness": "ë°ì´í„° ì™„ì„±ë„",
#     "analysis_confidence": "ë¶„ì„ ì‹ ë¢°ë„"
#   }}
# }}

# **ë¶„ì„ ì§€ì¹¨:**
# 1. ì„ íƒëœ PEGë“¤ì—ë§Œ ì§‘ì¤‘í•˜ì—¬ ì‹¬ì¸µ ë¶„ì„
# 2. PEGê°„ ìƒí˜¸ì‘ìš© ë° ì˜ì¡´ì„± ë¶„ì„
# 3. ê° PEGë³„ ê°œë³„ ì„±ëŠ¥ í‰ê°€
# 4. íŠ¹í™”ëœ ìµœì í™” ë°©ì•ˆ ì œì‹œ
# """

#         logger.info("íŠ¹ì • PEG ë¶„ì„ í”„ë¡¬í”„íŠ¸ ìƒì„± ì™„ë£Œ: %dì (PEG: %dê°œ)", len(prompt), len(processed_df["peg_name"].unique()))
#         return prompt


class LLMAnalysisService:
    """
    LLM ë¶„ì„ ì„œë¹„ìŠ¤ í´ë˜ìŠ¤

    LLMì„ í™œìš©í•œ ë°ì´í„° ë¶„ì„ì˜ ì „ì²´ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ì„ ë‹´ë‹¹í•©ë‹ˆë‹¤.
    í”„ë¡¬í”„íŠ¸ ìƒì„±, LLM í˜¸ì¶œ, ì‘ë‹µ ì²˜ë¦¬ë¥¼ í†µí•© ê´€ë¦¬í•©ë‹ˆë‹¤.

    ê¸°ì¡´ main.pyì˜ LLM ë¶„ì„ ë¡œì§ì„ ëª¨ë“ˆí™”í•œ ê²ƒì…ë‹ˆë‹¤.
    """

    def __init__(self, llm_repository: Optional[LLMRepository] = None):
        """
        LLMAnalysisService ì´ˆê¸°í™”

        Args:
            llm_repository (Optional[LLMRepository]): LLM Repository ì¸ìŠ¤í„´ìŠ¤
        """
        # LLM Repository ì„¤ì • (ì˜ì¡´ì„± ì£¼ì…)
        if llm_repository:
            self.llm_repository = llm_repository
        else:
            # ê¸°ë³¸ê°’: LLMClient ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
            self.llm_repository = LLMClient()

        # í”„ë¡¬í”„íŠ¸ ì „ëµë“¤ ì´ˆê¸°í™”
        self.prompt_strategies = {
            "enhanced": EnhancedAnalysisPromptStrategy(),
            # "specific": SpecificPEGsAnalysisPromptStrategy(),  # ì£¼ì„ì²˜ë¦¬: ì‚¬ìš©ë˜ì§€ ì•ŠìŒ
        }

        logger.info(
            "LLMAnalysisService ì´ˆê¸°í™” ì™„ë£Œ: repository=%s, strategies=%dê°œ",
            type(self.llm_repository).__name__,
            len(self.prompt_strategies),
        )

    def get_available_strategies(self) -> List[str]:
        """ì‚¬ìš© ê°€ëŠ¥í•œ ë¶„ì„ ì „ëµ ëª©ë¡ ë°˜í™˜"""
        return list(self.prompt_strategies.keys())

    def analyze_peg_data(
        self,
        processed_df: pd.DataFrame,
        n1_range: str,
        n_range: str,
        analysis_type: str = "enhanced",
        enable_mock: bool = False,
        **kwargs,
    ) -> Dict[str, Any]:
        """
        PEG ë°ì´í„° ë¶„ì„ ì‹¤í–‰

        Args:
            processed_df (pd.DataFrame): ì²˜ë¦¬ëœ PEG ë°ì´í„°
            n1_range (str): N-1 ê¸°ê°„ ë¬¸ìì—´
            n_range (str): N ê¸°ê°„ ë¬¸ìì—´
            analysis_type (str): ë¶„ì„ ìœ í˜• ('enhanced')  # 'specific' ì£¼ì„ì²˜ë¦¬: ì‚¬ìš©ë˜ì§€ ì•ŠìŒ
            enable_mock (bool): ëª¨í‚¹ ëª¨ë“œ í™œì„±í™”
            **kwargs: ì¶”ê°€ ë§¤ê°œë³€ìˆ˜

        Returns:
            Dict[str, Any]: LLM ë¶„ì„ ê²°ê³¼

        Raises:
            LLMAnalysisError: ë¶„ì„ ì‹¤íŒ¨ ì‹œ
        """
        logger.info(
            "analyze_peg_data() í˜¸ì¶œ: ë¶„ì„ìœ í˜•=%s, ë°ì´í„°=%dí–‰, ëª¨í‚¹=%s", analysis_type, len(processed_df), enable_mock
        )

        # ë¶„ì„ ì „ëµ ì„ íƒ
        if analysis_type not in self.prompt_strategies:
            raise LLMAnalysisError(
                f"ì§€ì›ë˜ì§€ ì•ŠëŠ” ë¶„ì„ ìœ í˜•: {analysis_type}",
                analysis_type=analysis_type,
                details={"available_types": list(self.prompt_strategies.keys())},
            )

        strategy = self.prompt_strategies[analysis_type]

        try:
            # DEBUG2 ë¡œê¹… ìœ í‹¸ë¦¬í‹° import
            from config.logging_config import log_step, log_data_flow
            
            # í”„ë¡¬í”„íŠ¸ ìƒì„±
            log_step(logger, "[LLM ë‹¨ê³„ 1] í”„ë¡¬í”„íŠ¸ ìƒì„± ì‹œì‘", f"ì „ëµ={strategy.get_strategy_name()}")
            prompt = strategy.build_prompt(processed_df, n1_range, n_range, **kwargs)
            log_data_flow(logger, "ìƒì„±ëœ í”„ë¡¬í”„íŠ¸", {"prompt": prompt, "length": len(prompt)})

            # í”„ë¡¬í”„íŠ¸ ê²€ì¦
            if not self.llm_repository.validate_prompt(prompt):
                logger.warning("í”„ë¡¬í”„íŠ¸ ê²€ì¦ ì‹¤íŒ¨, ìë¥´ê¸° ì ìš©")
                # í”„ë¡¬í”„íŠ¸ê°€ ë„ˆë¬´ ê¸´ ê²½ìš° ì²˜ë¦¬ ë¡œì§ì´ LLMClientì— ìˆìŒ

            # LLM ë¶„ì„ ì‹¤í–‰
            logger.info("LLM ë¶„ì„ ì‹œì‘: ì „ëµ=%s, í”„ë¡¬í”„íŠ¸=%dì", strategy.get_strategy_name(), len(prompt))
            log_step(logger, "[LLM ë‹¨ê³„ 2] LLM API í˜¸ì¶œ ì‹œì‘", f"ëª¨í‚¹={enable_mock}")

            analysis_result = self.llm_repository.analyze_data(prompt, enable_mock=enable_mock)
            log_data_flow(logger, "LLM ì›ë³¸ ì‘ë‹µ", analysis_result)

            # ì‘ë‹µ í›„ì²˜ë¦¬
            log_step(logger, "[LLM ë‹¨ê³„ 3] ì‘ë‹µ í›„ì²˜ë¦¬ ì‹œì‘")
            processed_result = self._post_process_analysis_result(analysis_result, analysis_type, processed_df)
            log_data_flow(logger, "í›„ì²˜ë¦¬ëœ LLM ê²°ê³¼", processed_result)

            logger.info("LLM ë¶„ì„ ì™„ë£Œ: ì „ëµ=%s, ê²°ê³¼í‚¤=%dê°œ", strategy.get_strategy_name(), len(processed_result))

            return processed_result

        except LLMError as e:
            raise LLMAnalysisError(
                f"LLM í˜¸ì¶œ ì‹¤íŒ¨: {e.message}",
                analysis_type=analysis_type,
                prompt_preview=prompt[:200] if "prompt" in locals() else None,
                details=e.to_dict(),
            ) from e

        except Exception as e:
            raise LLMAnalysisError(
                f"ë¶„ì„ ì‹¤í–‰ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}",
                analysis_type=analysis_type,
                prompt_preview=prompt[:200] if "prompt" in locals() else None,
            ) from e

    def _post_process_analysis_result(
        self, raw_result: Dict[str, Any], analysis_type: str, original_df: pd.DataFrame
    ) -> Dict[str, Any]:
        """
        LLM ë¶„ì„ ê²°ê³¼ í›„ì²˜ë¦¬
        (ê¸°ì¡´ main.pyì˜ build_results_overview ë¡œì§ ê°œì„ )
        """
        logger.debug("_post_process_analysis_result() í˜¸ì¶œ: ë¶„ì„ìœ í˜•=%s", analysis_type)

        # ê¸°ë³¸ ê²°ê³¼ êµ¬ì¡° í™•ì¸
        if not isinstance(raw_result, dict):
            logger.warning("LLM ê²°ê³¼ê°€ ë”•ì…”ë„ˆë¦¬ê°€ ì•„ë‹˜, ë¬¸ìì—´ë¡œ ì²˜ë¦¬")
            raw_result = {"summary": str(raw_result)}

        # ê²°ê³¼ ê°•í™”
        enhanced_result = raw_result.copy()

        # ë©”íƒ€ë°ì´í„° ì¶”ê°€
        enhanced_result.update(
            {
                "_analysis_metadata": {
                    "analysis_type": analysis_type,
                    "data_rows": len(original_df),
                    "data_columns": len(original_df.columns),
                    "unique_pegs": len(original_df["peg_name"].unique()) if "peg_name" in original_df.columns else 0,
                    "timestamp": datetime.now().isoformat(),
                    "strategy_used": analysis_type,
                },
                "model_name": getattr(self.llm_repository, 'config', {}).get('model', 'unknown'),
                "model_used": getattr(self.llm_repository, 'config', {}).get('model', 'unknown')
            }
        )

        # Enhanced í”„ë¡¬í”„íŠ¸ êµ¬ì¡° í•„ë“œë§Œ ë³´ì¥
        enhanced_default_fields = {
            "executive_summary": "ë¶„ì„ ìš”ì•½ì´ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤",
            "diagnostic_findings": [],
            "recommended_actions": [],
        }

        for field, default_value in enhanced_default_fields.items():
            if field not in enhanced_result:
                enhanced_result[field] = default_value
                logger.debug("Enhanced ê¸°ë³¸ í•„ë“œ ì¶”ê°€: %s", field)

        logger.debug("ë¶„ì„ ê²°ê³¼ í›„ì²˜ë¦¬ ì™„ë£Œ: %dê°œ í•„ë“œ", len(enhanced_result))
        return enhanced_result

    def get_service_info(self) -> Dict[str, Any]:
        """ì„œë¹„ìŠ¤ ì •ë³´ ë°˜í™˜"""
        return {
            "service_name": "LLMAnalysisService",
            "available_strategies": self.get_available_strategies(),
            "llm_repository_type": type(self.llm_repository).__name__,
            "strategies_count": len(self.prompt_strategies),
        }

    def close(self) -> None:
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        if hasattr(self.llm_repository, "close"):
            self.llm_repository.close()
            logger.info("LLMAnalysisService ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ")

    def __enter__(self):
        """ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì € ì§„ì…"""
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        """ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì € ì¢…ë£Œ"""
        self.close()

        # ì˜ˆì™¸ ë°œìƒ ì‹œ ë¡œê·¸ ê¸°ë¡
        if exc_type:
            logger.error("LLMAnalysisService ì»¨í…ìŠ¤íŠ¸ì—ì„œ ì˜ˆì™¸ ë°œìƒ: %s", exc_val)

        return False  # ì˜ˆì™¸ë¥¼ ë‹¤ì‹œ ë°œìƒì‹œí‚´
