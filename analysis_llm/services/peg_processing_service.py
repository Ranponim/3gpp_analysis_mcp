"""
PEG Processing Service

ì´ ëª¨ë“ˆì€ PEG ë°ì´í„°ì˜ ì¡°íšŒÂ·ê²€ì¦Â·ì§‘ê³„ ë° íŒŒìƒ PEG ê³„ì‚°ì„ ë‹´ë‹¹í•˜ëŠ”
`PEGProcessingService` í´ë˜ìŠ¤ë¥¼ ì œê³µí•©ë‹ˆë‹¤. ê¸°ì¡´ `AnalysisService`ì—ì„œ
PEG ê´€ë ¨ ë¡œì§ì„ ë¶„ë¦¬í•˜ì—¬ ë‹¨ì¼ ì±…ì„ ì›ì¹™ì„ ê°•í™”í•˜ê³  ì¬ì‚¬ìš©ì„±ì„ ë†’ì˜€ìŠµë‹ˆë‹¤.
"""

from __future__ import annotations

import logging
from datetime import datetime
from typing import Any, Dict, Optional, Tuple, Union

import pandas as pd

from ..exceptions import ServiceError
from ..repositories import DatabaseRepository
from ..models.request import _DEFAULT_TABLE
from .peg_service import PEGCalculator

# ë¡œê¹… ì„¤ì •
logger = logging.getLogger(__name__)


class PEGProcessingError(ServiceError):
    """
    PEG ì²˜ë¦¬ ê´€ë ¨ ì˜¤ë¥˜ ì˜ˆì™¸ í´ë˜ìŠ¤

    PEG ë°ì´í„° ì¡°íšŒ ë° ì²˜ë¦¬ì—ì„œ ë°œìƒí•˜ëŠ” ì˜¤ë¥˜ë¥¼ ë˜í•‘í•©ë‹ˆë‹¤.
    """

    def __init__(
        self,
        message: str,
        details: Optional[Union[str, Dict[str, Any]]] = None,
        processing_step: Optional[str] = None,
        data_context: Optional[Dict[str, Any]] = None,
    ) -> None:
        """
        PEGProcessingError ì´ˆê¸°í™”

        Args:
            message (str): ì˜¤ë¥˜ ë©”ì‹œì§€
            details (Optional[Union[str, Dict[str, Any]]]): ì¶”ê°€ ìƒì„¸ ì •ë³´
            processing_step (Optional[str]): ì‹¤íŒ¨ ë‹¨ê³„
            data_context (Optional[Dict[str, Any]]): ë°ì´í„° ì»¨í…ìŠ¤íŠ¸
        """
        super().__init__(
            message=message, details=details, service_name="PEGProcessingService", operation="process_peg_data"
        )
        self.processing_step = processing_step
        self.data_context = data_context

        logger.error("PEGProcessingError ë°œìƒ: %s (ë‹¨ê³„: %s)", message, processing_step)

    def to_dict(self) -> Dict[str, Any]:
        """ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ ë³€í™˜"""
        data = super().to_dict()
        data.update({"processing_step": self.processing_step, "data_context": self.data_context})
        return data


class PEGProcessingService:
    """
    PEG ë°ì´í„° ì²˜ë¦¬ ì„œë¹„ìŠ¤ í´ë˜ìŠ¤

    - ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ PEG ì›ì‹œ ë°ì´í„°ë¥¼ ì¡°íšŒ
    - ë°ì´í„° ê²€ì¦ ë° ì§‘ê³„ ìˆ˜í–‰
    - `PEGCalculator`ë¥¼ ì‚¬ìš©í•œ íŒŒìƒ PEG ê³„ì‚°
    - ìµœì¢… ì²˜ë¦¬ ê²°ê³¼ë¥¼ ë°˜í™˜
    """

    def __init__(self, database_repository: DatabaseRepository, peg_calculator: Optional[PEGCalculator] = None):
        """
        PEGProcessingService ì´ˆê¸°í™”

        Args:
            database_repository (DatabaseRepository): ë°ì´í„°ë² ì´ìŠ¤ Repository
            peg_calculator (Optional[PEGCalculator]): PEG ê³„ì‚°ê¸°
        """
        self.database_repository = database_repository
        self.peg_calculator = peg_calculator or PEGCalculator()

        # ì²˜ë¦¬ ë‹¨ê³„ ì •ì˜
        self.processing_steps = [
            "data_retrieval",
            "data_validation",
            "aggregation",
            "derived_calculation",
            "result_formatting",
        ]

        logger.info("PEGProcessingService ì´ˆê¸°í™” ì™„ë£Œ: calculator=%s", type(self.peg_calculator).__name__)

    def get_service_info(self) -> Dict[str, Any]:
        """ì„œë¹„ìŠ¤ ì •ë³´ ë°˜í™˜"""
        return {
            "service_name": "PEGProcessingService",
            "processing_steps": self.processing_steps,
            "dependencies": {
                "database_repository": type(self.database_repository).__name__,
                "peg_calculator": type(self.peg_calculator).__name__,
            },
        }

    def _validate_time_ranges(self, time_ranges: Tuple[datetime, datetime, datetime, datetime]) -> None:
        """
        ì‹œê°„ ë²”ìœ„ ìœ íš¨ì„± ê²€ì¦

        Args:
            time_ranges (Tuple): (n1_start, n1_end, n_start, n_end)

        Raises:
            PEGProcessingError: ì‹œê°„ ë²”ìœ„ê°€ ìœ íš¨í•˜ì§€ ì•Šì€ ê²½ìš°
        """
        logger.debug("_validate_time_ranges() í˜¸ì¶œ: ì‹œê°„ ë²”ìœ„ ê²€ì¦")

        n1_start, n1_end, n_start, n_end = time_ranges

        # ì‹œì‘ ì‹œê°„ì´ ì¢…ë£Œ ì‹œê°„ë³´ë‹¤ ë¹ ë¥¸ì§€ ê²€ì¦
        if n1_start >= n1_end:
            raise PEGProcessingError(
                "N-1 ê¸°ê°„ì˜ ì‹œì‘ ì‹œê°„ì´ ì¢…ë£Œ ì‹œê°„ë³´ë‹¤ í¬ê±°ë‚˜ ê°™ìŠµë‹ˆë‹¤",
                processing_step="data_validation",
                data_context={"n1_start": n1_start, "n1_end": n1_end},
            )

        if n_start >= n_end:
            raise PEGProcessingError(
                "N ê¸°ê°„ì˜ ì‹œì‘ ì‹œê°„ì´ ì¢…ë£Œ ì‹œê°„ë³´ë‹¤ í¬ê±°ë‚˜ ê°™ìŠµë‹ˆë‹¤",
                processing_step="data_validation",
                data_context={"n_start": n_start, "n_end": n_end},
            )

        logger.info("ì‹œê°„ ë²”ìœ„ ê²€ì¦ ê²°ê³¼: N-1(%s~%s), N(%s~%s)", n1_start, n1_end, n_start, n_end)

    def _retrieve_raw_peg_data(
        self,
        time_ranges: Tuple[datetime, datetime, datetime, datetime],
        table_config: Dict[str, Any],
        filters: Dict[str, Any],
    ) -> Tuple[pd.DataFrame, pd.DataFrame]:
        """
        ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì›ì‹œ PEG ë°ì´í„° ì¡°íšŒ

        Args:
            time_ranges (Tuple): (n1_start, n1_end, n_start, n_end)
            table_config (Dict[str, Any]): í…Œì´ë¸”/ì»¬ëŸ¼ ì„¤ì •
            filters (Dict[str, Any]): ì¶”ê°€ í•„í„° ì¡°ê±´

        Returns:
            Tuple[pd.DataFrame, pd.DataFrame]: (n1_df, n_df)

        Raises:
            PEGProcessingError: ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨ ì‹œ
        """
        logger.debug("_retrieve_raw_peg_data() í˜¸ì¶œ: ì›ì‹œ ë°ì´í„° ì¡°íšŒ ì‹œì‘")

        try:
            n1_start, n1_end, n_start, n_end = time_ranges

            table_name = table_config.get("table", _DEFAULT_TABLE)
            # ìƒˆ ìŠ¤í‚¤ë§ˆ ê¸°ë³¸ ë§¤í•‘ (datetime, family_id, ne_key, rel_ver, swname, values, version)
            # ìƒìœ„ì—ì„œ ë³´ì¡´ëœ columnsë¥¼ ìš°ì„  ì‚¬ìš©, ì—†ìœ¼ë©´ JSONB ê¸°ë³¸ ë§¤í•‘ ì ìš©
            columns = table_config.get("columns") or {
                "time": "datetime",
                "family_name": "family_id",
                "values": "values",
                "ne": "ne_key",
                "rel_ver": "rel_ver",
                "swname": "swname",
            }
            data_limit = table_config.get("data_limit")

            # N-1 ê¸°ê°„ ë°ì´í„° ì¡°íšŒ
            logger.info("N-1 ê¸°ê°„ ë°ì´í„° ì¡°íšŒ: %s ~ %s", n1_start, n1_end)
            n1_data = self.database_repository.fetch_peg_data(
                table_name=table_name, columns=columns, time_range=(n1_start, n1_end), filters=filters, limit=data_limit
            )

            # N ê¸°ê°„ ë°ì´í„° ì¡°íšŒ
            logger.info("N ê¸°ê°„ ë°ì´í„° ì¡°íšŒ: %s ~ %s", n_start, n_end)
            n_data = self.database_repository.fetch_peg_data(
                table_name=table_name, columns=columns, time_range=(n_start, n_end), filters=filters, limit=data_limit
            )

            # DataFrame ë³€í™˜
            n1_df = pd.DataFrame(n1_data)
            n_df = pd.DataFrame(n_data)

            logger.info("ì›ì‹œ ë°ì´í„° ì¡°íšŒ ì™„ë£Œ: N-1=%dí–‰, N=%dí–‰", len(n1_df), len(n_df))
            return n1_df, n_df

        except Exception as e:
            raise PEGProcessingError(
                f"ì›ì‹œ PEG ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {e}",
                processing_step="data_retrieval",
                data_context={
                    "table_name": table_name,
                    "time_ranges": str(time_ranges)[:100],
                    "filters": str(filters)[:100],
                },
            ) from e

    def _validate_raw_data(self, n1_df: pd.DataFrame, n_df: pd.DataFrame) -> None:
        """
        ì›ì‹œ ë°ì´í„° ìœ íš¨ì„± ê²€ì¦

        Args:
            n1_df (pd.DataFrame): N-1 ê¸°ê°„ ë°ì´í„°
            n_df (pd.DataFrame): N ê¸°ê°„ ë°ì´í„°

        Raises:
            PEGProcessingError: ë°ì´í„°ê°€ ìœ íš¨í•˜ì§€ ì•Šì€ ê²½ìš°
        """
        logger.debug("_validate_raw_data() í˜¸ì¶œ: ì›ì‹œ ë°ì´í„° ê²€ì¦")

        # ë¹ˆ ë°ì´í„° ê²½ê³ 
        if len(n1_df) == 0 or len(n_df) == 0:
            logger.warning("í•œìª½ ê¸°ê°„ ë°ì´í„°ê°€ ë¹„ì–´ìˆìŒ: N-1=%dí–‰, N=%dí–‰ - ë¶„ì„ ì‹ ë¢°ì„±ì— ì˜í–¥ ê°€ëŠ¥", len(n1_df), len(n_df))

        # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸
        required_columns = ["peg_name", "value"]

        for df_name, df in [("N-1", n1_df), ("N", n_df)]:
            if not df.empty:
                missing_columns = [col for col in required_columns if col not in df.columns]
                if missing_columns:
                    raise PEGProcessingError(
                        f"{df_name} ë°ì´í„°ì— í•„ìˆ˜ ì»¬ëŸ¼ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤: {missing_columns}",
                        processing_step="data_validation",
                        data_context={"period": df_name, "columns": list(df.columns)},
                    )

        logger.info("ì›ì‹œ ë°ì´í„° ê²€ì¦ ì™„ë£Œ: N-1=%dí–‰, N=%dí–‰", len(n1_df), len(n_df))

    def _process_with_calculator(
        self, n1_df: pd.DataFrame, n_df: pd.DataFrame, peg_config: Dict[str, Any], filters: Dict[str, Any]
    ) -> pd.DataFrame:
        """
        PEGCalculatorë¥¼ ì‚¬ìš©í•˜ì—¬ ë°ì´í„° ì²˜ë¦¬ (ì‹ë³„ì ë³´ì¡´)

        Args:
            n1_df (pd.DataFrame): N-1 ê¸°ê°„ ë°ì´í„°
            n_df (pd.DataFrame): N ê¸°ê°„ ë°ì´í„°
            peg_config (Dict[str, Any]): PEG ì„¤ì • (ë¯¸ì‚¬ìš© ì‹œ ë¹ˆ ë”•ì…”ë„ˆë¦¬)
            filters (Dict[str, Any]): í•„í„° ì¡°ê±´ (cell_id í‰ê· í™” íŒë‹¨ìš©)

        Returns:
            pd.DataFrame: ì²˜ë¦¬ëœ PEG ë°ì´í„° (ì‹ë³„ì ì»¬ëŸ¼ í¬í•¨)

        Raises:
            PEGProcessingError: PEG ì²˜ë¦¬ ì‹¤íŒ¨ ì‹œ
        """
        logger.debug("_process_with_calculator() í˜¸ì¶œ: PEGCalculator ì²˜ë¦¬ ì‹œì‘")

        try:
            # âœ¨ ì‹ë³„ì ì •ë³´ ì¶”ì¶œ (ì§‘ê³„ ì „ - DB ì¡°íšŒ ê°’ ë³´ì¡´)
            metadata = {}
            source_df = n1_df if not n1_df.empty else n_df
            
            if not source_df.empty:
                first_row = source_df.iloc[0]
                
                # ne_key ì¶”ì¶œ (DBê°€ 'ne'ë¡œ ë°˜í™˜)
                if "ne" in source_df.columns:
                    metadata["ne_key"] = str(first_row["ne"]) if pd.notna(first_row["ne"]) else None
                
                # swname ì¶”ì¶œ (DB ì»¬ëŸ¼ëª… ê·¸ëŒ€ë¡œ)
                if "swname" in source_df.columns:
                    metadata["swname"] = str(first_row["swname"]) if pd.notna(first_row["swname"]) else None
                
                # rel_ver ì¶”ì¶œ (DB ì»¬ëŸ¼ëª… ê·¸ëŒ€ë¡œ)
                if "rel_ver" in source_df.columns:
                    metadata["rel_ver"] = str(first_row["rel_ver"]) if pd.notna(first_row["rel_ver"]) else None
                
                # index_name ì¶”ì¶œ (JSONB values ë‚´ë¶€ì— ìˆì„ ìˆ˜ ìˆìŒ)
                if "index_name" in source_df.columns:
                    metadata["index_name"] = str(first_row["index_name"]) if pd.notna(first_row["index_name"]) else None
                
                logger.debug(
                    "ì‹ë³„ì ì¶”ì¶œ (ì§‘ê³„ ì „): ne_key=%s, swname=%s, rel_ver=%s, index_name=%s",
                    metadata.get("ne_key"),
                    metadata.get("swname"),
                    metadata.get("rel_ver"),
                    metadata.get("index_name")
                )
            
            # âœ¨ ìš”êµ¬ì‚¬í•­ 2: cell_id í•„í„° ì—†ìœ¼ë©´ ì—¬ëŸ¬ cell í‰ê· í™”
            if 'cellid' not in filters or not filters.get('cellid'):
                logger.info("cell_id ë¯¸ì§€ì • - ì—¬ëŸ¬ cell í‰ê· í™” ìˆ˜í–‰")
                
                for df_name, df in [("N-1", n1_df), ("N", n_df)]:
                    if not df.empty and 'peg_name' in df.columns:
                        # peg_nameì—ì„œ CellIdentity ì°¨ì› ì œê±°
                        # íŒ¨í„´: 'CellIdentity:ìˆ«ì,' í˜•ì‹ ì œê±°
                        # ì˜ˆ: CellIdentity:0,QCI:20,PEG â†’ QCI:20,PEG
                        original_count = len(df)
                        df['peg_name'] = df['peg_name'].str.replace(
                            r'CellIdentity:\d+,',  # CellIdentity:ìˆ«ì, íŒ¨í„´
                            '', 
                            regex=True
                        )
                        logger.debug(
                            "%s ê¸°ê°„: peg_nameì—ì„œ CellIdentity ì°¨ì› ì œê±° (í–‰ìˆ˜: %d)",
                            df_name, original_count
                        )
                
                # ì¬ì§‘ê³„ (cellì´ ì œê±°ëœ peg_name ê¸°ì¤€)
                if not n1_df.empty:
                    logger.debug("N-1 ì¬ì§‘ê³„ ì „: %dí–‰", len(n1_df))
                    n1_df = n1_df.groupby(['timestamp', 'peg_name']).agg({
                        'value': 'mean',
                        'ne': 'first',
                        'swname': 'first',
                        'family_name': 'first'
                    }).reset_index()
                    logger.info("N-1 cell í‰ê· í™” ì™„ë£Œ: %dí–‰", len(n1_df))
                
                if not n_df.empty:
                    logger.debug("N ì¬ì§‘ê³„ ì „: %dí–‰", len(n_df))
                    n_df = n_df.groupby(['timestamp', 'peg_name']).agg({
                        'value': 'mean',
                        'ne': 'first',
                        'swname': 'first',
                        'family_name': 'first'
                    }).reset_index()
                    logger.info("N cell í‰ê· í™” ì™„ë£Œ: %dí–‰", len(n_df))
            else:
                logger.debug("cell_id í•„í„° ì¡´ì¬ - cell í‰ê· í™” ê±´ë„ˆëœ€")
            
            # ê°„ë‹¨í•œ ì§‘ê³„ ë¡œì§ (PEGCalculator ì™„ì „ í†µí•© ì „ ì„ì‹œ)
            # N-1 ê¸°ê°„ ì§‘ê³„
            if not n1_df.empty:
                # ğŸ” ë””ë²„ê¹…: ì›ì‹œ ë°ì´í„°ì˜ value ì»¬ëŸ¼ í™•ì¸
                logger.debug(
                    "N-1 ì›ì‹œ ë°ì´í„° value ìƒ˜í”Œ: %s (null=%dê°œ, 0=%dê°œ, ì´=%dê°œ)",
                    n1_df['value'].head(10).tolist() if 'value' in n1_df.columns else 'value ì»¬ëŸ¼ ì—†ìŒ',
                    n1_df['value'].isnull().sum() if 'value' in n1_df.columns else 0,
                    (n1_df['value'] == 0).sum() if 'value' in n1_df.columns else 0,
                    len(n1_df)
                )
                
                n1_aggregated = n1_df.groupby("peg_name")["value"].mean().reset_index()
                n1_aggregated["period"] = "N-1"
                
                # ğŸ” ë””ë²„ê¹…: ì§‘ê³„ í›„ ê°’ í™•ì¸
                logger.debug(
                    "N-1 ì§‘ê³„ í›„ value ìƒ˜í”Œ: %s (null=%dê°œ, 0=%dê°œ, ì´=%dê°œ)",
                    n1_aggregated['value'].head(10).tolist(),
                    n1_aggregated['value'].isnull().sum(),
                    (n1_aggregated['value'] == 0).sum(),
                    len(n1_aggregated)
                )
            else:
                n1_aggregated = pd.DataFrame(columns=["peg_name", "value", "period"])

            # N ê¸°ê°„ ì§‘ê³„
            if not n_df.empty:
                # ğŸ” ë””ë²„ê¹…: ì›ì‹œ ë°ì´í„°ì˜ value ì»¬ëŸ¼ í™•ì¸
                logger.debug(
                    "N ì›ì‹œ ë°ì´í„° value ìƒ˜í”Œ: %s (null=%dê°œ, 0=%dê°œ, ì´=%dê°œ)",
                    n_df['value'].head(10).tolist() if 'value' in n_df.columns else 'value ì»¬ëŸ¼ ì—†ìŒ',
                    n_df['value'].isnull().sum() if 'value' in n_df.columns else 0,
                    (n_df['value'] == 0).sum() if 'value' in n_df.columns else 0,
                    len(n_df)
                )
                
                n_aggregated = n_df.groupby("peg_name")["value"].mean().reset_index()
                n_aggregated["period"] = "N"
                
                # ğŸ” ë””ë²„ê¹…: ì§‘ê³„ í›„ ê°’ í™•ì¸
                logger.debug(
                    "N ì§‘ê³„ í›„ value ìƒ˜í”Œ: %s (null=%dê°œ, 0=%dê°œ, ì´=%dê°œ)",
                    n_aggregated['value'].head(10).tolist(),
                    n_aggregated['value'].isnull().sum(),
                    (n_aggregated['value'] == 0).sum(),
                    len(n_aggregated)
                )
            else:
                n_aggregated = pd.DataFrame(columns=["peg_name", "value", "period"])

            # ê²°í•© ë° ë³€í™”ìœ¨ ê³„ì‚°
            combined_df = pd.concat([n1_aggregated, n_aggregated], ignore_index=True)

            # ë³€í™”ìœ¨ ê³„ì‚° ë¡œì§
            if not combined_df.empty:
                # ğŸ” ë””ë²„ê¹…: pivot ì „ combined_df í™•ì¸
                logger.debug(
                    "pivot ì „ combined_df: shape=%s, ìƒ˜í”Œ ë°ì´í„°=%s",
                    combined_df.shape,
                    combined_df.head(10).to_dict('records') if len(combined_df) > 0 else []
                )
                
                # pivotìœ¼ë¡œ N-1, N ê¸°ê°„ì„ ì»¬ëŸ¼ìœ¼ë¡œ ë³€í™˜
                # âš ï¸ fillna(0) ì œê±° - ì‹¤ì œ null ê°’ ë³´ì¡´í•˜ì—¬ ë””ë²„ê¹…
                pivot_df = combined_df.pivot(index="peg_name", columns="period", values="value")
                
                # ğŸ” ë””ë²„ê¹…: pivot í›„ null ê°’ í™•ì¸
                logger.debug(
                    "pivot ê²°ê³¼ (fillna ì „): shape=%s, columns=%s, N-1_ì¡´ì¬=%s, N_ì¡´ì¬=%s",
                    pivot_df.shape,
                    list(pivot_df.columns),
                    "N-1" in pivot_df.columns,
                    "N" in pivot_df.columns
                )
                
                if "N-1" in pivot_df.columns:
                    logger.debug(
                        "N-1 ì»¬ëŸ¼ í†µê³„: null=%dê°œ, 0=%dê°œ, ìƒ˜í”Œ ê°’=%s",
                        pivot_df["N-1"].isnull().sum(),
                        (pivot_df["N-1"] == 0).sum(),
                        pivot_df["N-1"].head(10).tolist()
                    )
                
                if "N" in pivot_df.columns:
                    logger.debug(
                        "N ì»¬ëŸ¼ í†µê³„: null=%dê°œ, 0=%dê°œ, ìƒ˜í”Œ ê°’=%s",
                        pivot_df["N"].isnull().sum(),
                        (pivot_df["N"] == 0).sum(),
                        pivot_df["N"].head(10).tolist()
                    )

                if "N-1" in pivot_df.columns and "N" in pivot_df.columns:
                    # âœ… ë³€í™”ìœ¨ ê³„ì‚° ê°œì„ 
                    # 1. N-1ì´ 0ì¸ ê²½ìš° ì²´í¬ (division by zero ë°©ì§€)
                    zero_n1_mask = (pivot_df["N-1"] == 0)
                    null_n1_mask = pivot_df["N-1"].isnull()
                    null_n_mask = pivot_df["N"].isnull()
                    
                    zero_n1_count = zero_n1_mask.sum()
                    null_n1_count = null_n1_mask.sum()
                    null_n_count = null_n_mask.sum()
                    
                    logger.debug(
                        "ë³€í™”ìœ¨ ê³„ì‚° ì „: N-1=0ì¸ PEG=%dê°œ, N-1=nullì¸ PEG=%dê°œ, N=nullì¸ PEG=%dê°œ",
                        zero_n1_count, null_n1_count, null_n_count
                    )
                    
                    # 2. ë³€í™”ìœ¨ ê³„ì‚° (null ê°’ ë³´ì¡´)
                    # N-1ì´ë‚˜ Nì´ nullì´ë©´ ë³€í™”ìœ¨ë„ nullë¡œ ì²˜ë¦¬
                    # N-1ì´ 0ì´ë©´ ë³€í™”ìœ¨ ê³„ì‚° ë¶ˆê°€ (0ìœ¼ë¡œ ë‚˜ëˆ„ê¸°) -> null ì²˜ë¦¬
                    pivot_df["change_pct"] = None  # ì´ˆê¸°í™”
                    
                    # ìœ íš¨í•œ ë°ì´í„°ë§Œ ê³„ì‚° (N-1, N ëª¨ë‘ ì¡´ì¬í•˜ê³ , N-1ì´ 0ì´ ì•„ë‹˜)
                    valid_mask = (~null_n1_mask) & (~null_n_mask) & (~zero_n1_mask)
                    
                    if valid_mask.sum() > 0:
                        pivot_df.loc[valid_mask, "change_pct"] = (
                            (pivot_df.loc[valid_mask, "N"] - pivot_df.loc[valid_mask, "N-1"]) 
                            / pivot_df.loc[valid_mask, "N-1"] 
                            * 100
                        )
                        logger.info(
                            "ë³€í™”ìœ¨ ê³„ì‚° ì™„ë£Œ: %dê°œ PEG (ìœ íš¨ ë°ì´í„°ë§Œ ê³„ì‚°)",
                            valid_mask.sum()
                        )
                    else:
                        logger.warning("ìœ íš¨í•œ ë°ì´í„°ê°€ ì—†ì–´ ë³€í™”ìœ¨ì„ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
                    
                    # N-1ì´ 0ì¸ ê²½ìš° ê²½ê³  (ë³€í™”ìœ¨ ê³„ì‚° ë¶ˆê°€)
                    if zero_n1_count > 0:
                        logger.warning(
                            "N-1 ê°’ì´ 0ì¸ PEGê°€ %dê°œ ìˆìŠµë‹ˆë‹¤ (ë³€í™”ìœ¨ ê³„ì‚° ë¶ˆê°€, null ì²˜ë¦¬)",
                            zero_n1_count
                        )
                        # N-1=0ì¸ PEG ëª©ë¡ ì¶œë ¥ (ìµœëŒ€ 10ê°œ)
                        zero_pegs = pivot_df[zero_n1_mask].head(10).index.tolist()
                        logger.debug("N-1=0ì¸ PEG ìƒ˜í”Œ: %s", zero_pegs)
                    
                    # null ê°’ì´ ìˆëŠ” ê²½ìš° ê²½ê³ 
                    if null_n1_count > 0 or null_n_count > 0:
                        logger.warning(
                            "ë°ì´í„° ëˆ„ë½: N-1=nullì¸ PEG=%dê°œ, N=nullì¸ PEG=%dê°œ",
                            null_n1_count, null_n_count
                        )
                    
                    # change_pct í†µê³„ ì¶œë ¥ (ë””ë²„ê¹…)
                    non_zero_changes = (pivot_df["change_pct"] != 0).sum()
                    if len(pivot_df) > 0:
                        sample_pegs = pivot_df.head(5)
                        logger.debug(
                            "change_pct ê³„ì‚° ì™„ë£Œ: ì´=%d, 0ì´_ì•„ë‹Œ_ê°’=%dê°œ, ìƒ˜í”Œ_PEG=%s",
                            len(pivot_df),
                            non_zero_changes,
                            [(idx, row["N-1"], row["N"], row["change_pct"]) 
                             for idx, row in sample_pegs.iterrows()]
                        )
                else:
                    logger.warning("pivot ê²°ê³¼ì— N-1 ë˜ëŠ” N ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤! change_pctë¥¼ 0ìœ¼ë¡œ ì„¤ì •")
                    pivot_df["change_pct"] = 0

                # ìµœì¢… í˜•íƒœë¡œ ë³€í™˜
                processed_df = pivot_df.reset_index()
                processed_df = processed_df.melt(
                    id_vars=["peg_name", "change_pct"],
                    value_vars=["N-1", "N"],
                    var_name="period",
                    value_name="avg_value",
                )
            else:
                logger.warning("combined_dfê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤!")
                processed_df = pd.DataFrame(columns=["peg_name", "period", "avg_value", "change_pct"])
            
            # âœ¨ ì‹ë³„ì ì •ë³´ë¥¼ ëª¨ë“  í–‰ì— ì¶”ê°€ (DB ì¡°íšŒ ê°’ ë³´ì¡´)
            if metadata:
                for key, value in metadata.items():
                    if value is not None:
                        processed_df[key] = value
                        logger.debug("ì»¬ëŸ¼ ì¶”ê°€: %s=%s", key, value)

            logger.info(
                "PEGCalculator ì²˜ë¦¬ ì™„ë£Œ: %dí–‰ (ì‹ë³„ì ë³´ì¡´: ne_key=%s, swname=%s, rel_ver=%s, index_name=%s)",
                len(processed_df),
                metadata.get("ne_key"),
                metadata.get("swname"),
                metadata.get("rel_ver"),
                metadata.get("index_name")
            )
            return processed_df

        except Exception as e:
            raise PEGProcessingError(
                f"PEGCalculator ì²˜ë¦¬ ì‹¤íŒ¨: {e}",
                processing_step="aggregation",
                data_context={"n1_rows": len(n1_df), "n_rows": len(n_df)},
            ) from e

    def process_peg_data(
        self,
        time_ranges: Tuple[datetime, datetime, datetime, datetime],
        table_config: Dict[str, Any],
        filters: Dict[str, Any],
        peg_config: Optional[Dict[str, Any]] = None,
    ) -> pd.DataFrame:
        """
        ì „ì²´ PEG ë°ì´í„° ì²˜ë¦¬ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰

        Args:
            time_ranges (Tuple): (n1_start, n1_end, n_start, n_end)
            table_config (Dict[str, Any]): í…Œì´ë¸”/ì»¬ëŸ¼ ì„¤ì •
            filters (Dict[str, Any]): í•„í„° ì¡°ê±´
            peg_config (Optional[Dict[str, Any]]): PEG ì„¤ì •

        Returns:
            pd.DataFrame: ì²˜ë¦¬ëœ PEG ë°ì´í„°

        Raises:
            PEGProcessingError: ì²˜ë¦¬ ì‹¤íŒ¨ ì‹œ
        """
        logger.info("process_peg_data() í˜¸ì¶œ: PEG ë°ì´í„° ì²˜ë¦¬ ì›Œí¬í”Œë¡œìš° ì‹œì‘")

        try:
            # 1ë‹¨ê³„: ì‹œê°„ ë²”ìœ„ ê²€ì¦
            logger.info("1ë‹¨ê³„: ì‹œê°„ ë²”ìœ„ ê²€ì¦")
            self._validate_time_ranges(time_ranges)
            logger.debug(
                "ì‹œê°„ ë²”ìœ„ ìš”ì•½: N-1=%s~%s, N=%s~%s",
                time_ranges[0],
                time_ranges[1],
                time_ranges[2],
                time_ranges[3],
            )

            # 2ë‹¨ê³„: ì›ì‹œ ë°ì´í„° ì¡°íšŒ
            logger.info("2ë‹¨ê³„: ì›ì‹œ ë°ì´í„° ì¡°íšŒ")
            n1_df, n_df = self._retrieve_raw_peg_data(time_ranges, table_config, filters)
            logger.debug(
                "ì›ì‹œ ë°ì´í„° ì¡°íšŒ ê²°ê³¼: N-1 rows=%d, N rows=%d", len(n1_df), len(n_df)
            )

            # 3ë‹¨ê³„: ì›ì‹œ ë°ì´í„° ê²€ì¦
            logger.info("3ë‹¨ê³„: ì›ì‹œ ë°ì´í„° ê²€ì¦")
            self._validate_raw_data(n1_df, n_df)

            # 4ë‹¨ê³„: PEGCalculator ì²˜ë¦¬
            logger.info("4ë‹¨ê³„: PEGCalculator ì²˜ë¦¬")
            processed_df = self._process_with_calculator(n1_df, n_df, peg_config or {}, filters)
            logger.debug(
                "PEGCalculator ì²˜ë¦¬ ê²°ê³¼: í–‰ìˆ˜=%d, ì»¬ëŸ¼=%s",
                len(processed_df),
                list(processed_df.columns),
            )

            logger.info("PEG ë°ì´í„° ì²˜ë¦¬ ì›Œí¬í”Œë¡œìš° ì™„ë£Œ: %dí–‰", len(processed_df))
            return processed_df

        except PEGProcessingError:
            # ì´ë¯¸ PEGProcessingErrorì¸ ê²½ìš° ê·¸ëŒ€ë¡œ ì „íŒŒ
            raise

        except Exception as e:
            # ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ë¥¼ PEGProcessingErrorë¡œ ë³€í™˜
            raise PEGProcessingError(
                f"PEG ë°ì´í„° ì²˜ë¦¬ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}",
                processing_step="unknown",
                data_context={"time_ranges": str(time_ranges)[:100]},
            ) from e

    def get_processing_status(self) -> Dict[str, Any]:
        """ì²˜ë¦¬ ìƒíƒœ ì •ë³´ ë°˜í™˜"""
        return {
            "processing_steps": self.processing_steps,
            "step_count": len(self.processing_steps),
            "dependencies_ready": {
                "database_repository": self.database_repository is not None,
                "peg_calculator": self.peg_calculator is not None,
            },
        }

    def close(self) -> None:
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        if hasattr(self.database_repository, "disconnect"):
            self.database_repository.disconnect()

        logger.info("PEGProcessingService ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ")

    def __enter__(self):
        """ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì € ì§„ì…"""
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        """ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì € ì¢…ë£Œ"""
        self.close()

        # ì˜ˆì™¸ ë°œìƒ ì‹œ ë¡œê·¸ ê¸°ë¡
        if exc_type:
            logger.error("PEGProcessingService ì»¨í…ìŠ¤íŠ¸ì—ì„œ ì˜ˆì™¸ ë°œìƒ: %s", exc_val)
        return False  # ì˜ˆì™¸ë¥¼ ë‹¤ì‹œ ë°œìƒì‹œí‚´

