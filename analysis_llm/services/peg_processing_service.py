"""
PEG Processing Service

ì´ ëª¨ë“ˆì€ PEG ë°ì´í„°ì˜ ì¡°íšŒÂ·ê²€ì¦Â·ì§‘ê³„ ë° íŒŒìƒ PEG ê³„ì‚°ì„ ë‹´ë‹¹í•˜ëŠ”
`PEGProcessingService` í´ë˜ìŠ¤ë¥¼ ì œê³µí•©ë‹ˆë‹¤. ê¸°ì¡´ `AnalysisService`ì—ì„œ
PEG ê´€ë ¨ ë¡œì§ì„ ë¶„ë¦¬í•˜ì—¬ ë‹¨ì¼ ì±…ì„ ì›ì¹™ì„ ê°•í™”í•˜ê³  ì¬ì‚¬ìš©ì„±ì„ ë†’ì˜€ìŠµë‹ˆë‹¤.
"""

from __future__ import annotations

import logging
import os
from datetime import datetime
from typing import Any, Dict, Optional, Tuple, Union
from collections import defaultdict

import pandas as pd

from config import get_settings
from ..exceptions import ServiceError
from ..repositories import DatabaseRepository
from ..models.request import _DEFAULT_TABLE
from .peg_service import PEGCalculator
from ..utils.csv_filter_loader import load_peg_definitions_from_csv

# ë¡œê¹… ì„¤ì •
logger = logging.getLogger(__name__)


class PEGProcessingError(ServiceError):
    """
    PEG ì²˜ë¦¬ ê´€ë ¨ ì˜¤ë¥˜ ì˜ˆì™¸ í´ë˜ìŠ¤

    PEG ë°ì´í„° ì¡°íšŒ ë° ì²˜ë¦¬ì—ì„œ ë°œìƒí•˜ëŠ” ì˜¤ë¥˜ë¥¼ ë˜í•‘í•©ë‹ˆë‹¤.
    """

    def __init__(
        self,
        message: str,
        details: Optional[Union[str, Dict[str, Any]]] = None,
        processing_step: Optional[str] = None,
        data_context: Optional[Dict[str, Any]] = None,
    ) -> None:
        """
        PEGProcessingError ì´ˆê¸°í™”

        Args:
            message (str): ì˜¤ë¥˜ ë©”ì‹œì§€
            details (Optional[Union[str, Dict[str, Any]]]): ì¶”ê°€ ìƒì„¸ ì •ë³´
            processing_step (Optional[str]): ì‹¤íŒ¨ ë‹¨ê³„
            data_context (Optional[Dict[str, Any]]): ë°ì´í„° ì»¨í…ìŠ¤íŠ¸
        """
        super().__init__(
            message=message, details=details, service_name="PEGProcessingService", operation="process_peg_data"
        )
        self.processing_step = processing_step
        self.data_context = data_context

        logger.error("PEGProcessingError ë°œìƒ: %s (ë‹¨ê³„: %s)", message, processing_step)

    def to_dict(self) -> Dict[str, Any]:
        """ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ ë³€í™˜"""
        data = super().to_dict()
        data.update({"processing_step": self.processing_step, "data_context": self.data_context})
        return data


class PEGProcessingService:
    """
    PEG ë°ì´í„° ì²˜ë¦¬ ì„œë¹„ìŠ¤ í´ë˜ìŠ¤

    - ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ PEG ì›ì‹œ ë°ì´í„°ë¥¼ ì¡°íšŒ
    - ë°ì´í„° ê²€ì¦ ë° ì§‘ê³„ ìˆ˜í–‰
    - `PEGCalculator`ë¥¼ ì‚¬ìš©í•œ íŒŒìƒ PEG ê³„ì‚°
    - ìµœì¢… ì²˜ë¦¬ ê²°ê³¼ë¥¼ ë°˜í™˜
    """

    def __init__(self, database_repository: DatabaseRepository, peg_calculator: Optional[PEGCalculator] = None):
        """
        PEGProcessingService ì´ˆê¸°í™”

        Args:
            database_repository (DatabaseRepository): ë°ì´í„°ë² ì´ìŠ¤ Repository
            peg_calculator (Optional[PEGCalculator]): PEG ê³„ì‚°ê¸°
        """
        self.database_repository = database_repository
        self.peg_calculator = peg_calculator or PEGCalculator()

        # ì²˜ë¦¬ ë‹¨ê³„ ì •ì˜
        self.processing_steps = [
            "data_retrieval",
            "data_validation",
            "aggregation",
            "derived_calculation",
            "result_formatting",
        ]

        logger.info("PEGProcessingService ì´ˆê¸°í™” ì™„ë£Œ: calculator=%s", type(self.peg_calculator).__name__)

    def get_service_info(self) -> Dict[str, Any]:
        """ì„œë¹„ìŠ¤ ì •ë³´ ë°˜í™˜"""
        return {
            "service_name": "PEGProcessingService",
            "processing_steps": self.processing_steps,
            "dependencies": {
                "database_repository": type(self.database_repository).__name__,
                "peg_calculator": type(self.peg_calculator).__name__,
            },
        }

    def _validate_time_ranges(self, time_ranges: Tuple[datetime, datetime, datetime, datetime]) -> None:
        """
        ì‹œê°„ ë²”ìœ„ ìœ íš¨ì„± ê²€ì¦

        Args:
            time_ranges (Tuple): (n1_start, n1_end, n_start, n_end)

        Raises:
            PEGProcessingError: ì‹œê°„ ë²”ìœ„ê°€ ìœ íš¨í•˜ì§€ ì•Šì€ ê²½ìš°
        """
        logger.debug("_validate_time_ranges() í˜¸ì¶œ: ì‹œê°„ ë²”ìœ„ ê²€ì¦")

        n1_start, n1_end, n_start, n_end = time_ranges

        # ì‹œì‘ ì‹œê°„ì´ ì¢…ë£Œ ì‹œê°„ë³´ë‹¤ ë¹ ë¥¸ì§€ ê²€ì¦
        if n1_start >= n1_end:
            raise PEGProcessingError(
                "N-1 ê¸°ê°„ì˜ ì‹œì‘ ì‹œê°„ì´ ì¢…ë£Œ ì‹œê°„ë³´ë‹¤ í¬ê±°ë‚˜ ê°™ìŠµë‹ˆë‹¤",
                processing_step="data_validation",
                data_context={"n1_start": n1_start, "n1_end": n1_end},
            )

        if n_start >= n_end:
            raise PEGProcessingError(
                "N ê¸°ê°„ì˜ ì‹œì‘ ì‹œê°„ì´ ì¢…ë£Œ ì‹œê°„ë³´ë‹¤ í¬ê±°ë‚˜ ê°™ìŠµë‹ˆë‹¤",
                processing_step="data_validation",
                data_context={"n_start": n_start, "n_end": n_end},
            )

        logger.info("ì‹œê°„ ë²”ìœ„ ê²€ì¦ ê²°ê³¼: N-1(%s~%s), N(%s~%s)", n1_start, n1_end, n_start, n_end)

    def _retrieve_raw_peg_data(
        self,
        time_ranges: Tuple[datetime, datetime, datetime, datetime],
        table_config: Dict[str, Any],
        filters: Dict[str, Any],
        peg_filter: Dict[int, Set[str]],
    ) -> Tuple[pd.DataFrame, pd.DataFrame]:
        """
        ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì›ì‹œ PEG ë°ì´í„° ì¡°íšŒ

        Args:
            time_ranges (Tuple): (n1_start, n1_end, n_start, n_end)
            table_config (Dict[str, Any]): í…Œì´ë¸”/ì»¬ëŸ¼ ì„¤ì •
            filters (Dict[str, Any]): ì¶”ê°€ í•„í„° ì¡°ê±´
            peg_filter (Dict[int, Set[str]]): CSVì—ì„œ ë¡œë“œëœ PEG í•„í„°

        Returns:
            Tuple[pd.DataFrame, pd.DataFrame]: (n1_df, n_df)

        Raises:
            PEGProcessingError: ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨ ì‹œ
        """
        logger.debug("_retrieve_raw_peg_data() í˜¸ì¶œ: ì›ì‹œ ë°ì´í„° ì¡°íšŒ ì‹œì‘")

        try:
            n1_start, n1_end, n_start, n_end = time_ranges

            table_name = table_config.get("table", _DEFAULT_TABLE)
            # ìƒˆ ìŠ¤í‚¤ë§ˆ ê¸°ë³¸ ë§¤í•‘ (datetime, family_id, family_name, ne_key, rel_ver, swname, values, version)
            # ìƒìœ„ì—ì„œ ë³´ì¡´ëœ columnsë¥¼ ìš°ì„  ì‚¬ìš©, ì—†ìœ¼ë©´ JSONB ê¸°ë³¸ ë§¤í•‘ ì ìš©
            columns = table_config.get("columns") or {
                "time": "datetime",
                "family_id": "family_id",      # DB ì»¬ëŸ¼ (int, CSVì˜ family_idì™€ ë§¤ì¹­)
                "family_name": "family_name",  # DB ì»¬ëŸ¼ (char, family ì´ë¦„)
                "values": "values",
                "ne": "ne_key",
                "rel_ver": "rel_ver",
                "swname": "swname",
            }
            data_limit = table_config.get("data_limit")

            # N-1 ê¸°ê°„ ë°ì´í„° ì¡°íšŒ
            logger.info("N-1 ê¸°ê°„ ë°ì´í„° ì¡°íšŒ: %s ~ %s", n1_start, n1_end)
            n1_data = self.database_repository.fetch_peg_data(
                table_name=table_name, columns=columns, time_range=(n1_start, n1_end), filters=filters, limit=data_limit, peg_filter=peg_filter
            )

            # N ê¸°ê°„ ë°ì´í„° ì¡°íšŒ
            logger.info("N ê¸°ê°„ ë°ì´í„° ì¡°íšŒ: %s ~ %s", n_start, n_end)
            n_data = self.database_repository.fetch_peg_data(
                table_name=table_name, columns=columns, time_range=(n_start, n_end), filters=filters, limit=data_limit, peg_filter=peg_filter
            )

            # DataFrame ë³€í™˜
            n1_df = pd.DataFrame(n1_data)
            n_df = pd.DataFrame(n_data)

            logger.info("ì›ì‹œ ë°ì´í„° ì¡°íšŒ ì™„ë£Œ: N-1=%dí–‰, N=%dí–‰", len(n1_df), len(n_df))
            return n1_df, n_df

        except Exception as e:
            raise PEGProcessingError(
                f"ì›ì‹œ PEG ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {e}",
                processing_step="data_retrieval",
                data_context={
                    "table_name": table_name,
                    "time_ranges": str(time_ranges)[:100],
                    "filters": str(filters)[:100],
                },
            ) from e

    def _validate_raw_data(self, n1_df: pd.DataFrame, n_df: pd.DataFrame) -> None:
        """
        ì›ì‹œ ë°ì´í„° ìœ íš¨ì„± ê²€ì¦

        Args:
            n1_df (pd.DataFrame): N-1 ê¸°ê°„ ë°ì´í„°
            n_df (pd.DataFrame): N ê¸°ê°„ ë°ì´í„°

        Raises:
            PEGProcessingError: ë°ì´í„°ê°€ ìœ íš¨í•˜ì§€ ì•Šì€ ê²½ìš°
        """
        logger.debug("_validate_raw_data() í˜¸ì¶œ: ì›ì‹œ ë°ì´í„° ê²€ì¦")

        # ë¹ˆ ë°ì´í„° ê²½ê³ 
        if len(n1_df) == 0 or len(n_df) == 0:
            logger.warning("í•œìª½ ê¸°ê°„ ë°ì´í„°ê°€ ë¹„ì–´ìˆìŒ: N-1=%dí–‰, N=%dí–‰ - ë¶„ì„ ì‹ ë¢°ì„±ì— ì˜í–¥ ê°€ëŠ¥", len(n1_df), len(n_df))

        # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸
        required_columns = ["peg_name", "value"]

        for df_name, df in [("N-1", n1_df), ("N", n_df)]:
            if not df.empty:
                missing_columns = [col for col in required_columns if col not in df.columns]
                if missing_columns:
                    raise PEGProcessingError(
                        f"{df_name} ë°ì´í„°ì— í•„ìˆ˜ ì»¬ëŸ¼ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤: {missing_columns}",
                        processing_step="data_validation",
                        data_context={"period": df_name, "columns": list(df.columns)},
                    )

        logger.info("ì›ì‹œ ë°ì´í„° ê²€ì¦ ì™„ë£Œ: N-1=%dí–‰, N=%dí–‰", len(n1_df), len(n_df))

    def _resolve_dependency_order(self, derived_pegs: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        íŒŒìƒ PEG ê°„ì˜ ì˜ì¡´ì„±ì„ ë¶„ì„í•˜ì—¬ ê³„ì‚° ìˆœì„œë¥¼ ê²°ì •í•©ë‹ˆë‹¤. (ìœ„ìƒ ì •ë ¬)

        Args:
            derived_pegs (List[Dict[str, Any]]): íŒŒìƒ PEG ì •ì˜ ë¦¬ìŠ¤íŠ¸

        Returns:
            List[Dict[str, Any]]: ê³„ì‚° ìˆœì„œëŒ€ë¡œ ì •ë ¬ëœ íŒŒìƒ PEG ë¦¬ìŠ¤íŠ¸

        Raises:
            PEGProcessingError: ìˆœí™˜ ì°¸ì¡°ê°€ ë°œê²¬ëœ ê²½ìš°
        """
        if not derived_pegs:
            return []

        logger.debug("íŒŒìƒ PEG ì˜ì¡´ì„± ë¶„ì„ ì‹œì‘: %dê°œ", len(derived_pegs))
        
        peg_map = {peg['output_peg']: peg for peg in derived_pegs}
        
        # ê° PEGì˜ ì˜ì¡´ì„± ìˆ˜ ê³„ì‚°
        in_degree = {peg['output_peg']: 0 for peg in derived_pegs}
        # ê° PEGì´ ì–´ë–¤ ë‹¤ë¥¸ PEGë“¤ì˜ ê³„ì‚°ì— í•„ìš”í•œì§€
        adj = defaultdict(list)

        all_peg_names = set(peg_map.keys())

        for peg in derived_pegs:
            output_peg = peg['output_peg']
            for dep in peg['dependencies']:
                if dep in all_peg_names: # ì˜ì¡´ì„±ì´ ë‹¤ë¥¸ íŒŒìƒ PEGì¸ ê²½ìš°
                    in_degree[output_peg] += 1
                    adj[dep].append(output_peg)

        # ì§„ì… ì°¨ìˆ˜ê°€ 0ì¸ PEGë“¤ì„ íì— ì¶”ê°€
        queue = [peg_name for peg_name, degree in in_degree.items() if degree == 0]
        
        sorted_order = []
        while queue:
            peg_name = queue.pop(0)
            sorted_order.append(peg_map[peg_name])
            
            for dependent_peg in adj[peg_name]:
                in_degree[dependent_peg] -= 1
                if in_degree[dependent_peg] == 0:
                    queue.append(dependent_peg)
        
        if len(sorted_order) != len(derived_pegs):
            circular_deps = {p for p, d in in_degree.items() if d > 0}
            raise PEGProcessingError(
                "íŒŒìƒ PEG ì •ì˜ì— ìˆœí™˜ ì°¸ì¡°ê°€ ìˆìŠµë‹ˆë‹¤.",
                processing_step="dependency_resolution",
                details={"circular_dependencies": list(circular_deps)}
            )
            
        logger.info("íŒŒìƒ PEG ê³„ì‚° ìˆœì„œ ê²°ì • ì™„ë£Œ: %s", [p['output_peg'] for p in sorted_order])
        return sorted_order

    def _process_with_calculator(
        self, n1_df: pd.DataFrame, n_df: pd.DataFrame, peg_config: Dict[str, Any], filters: Dict[str, Any], derived_pegs: List[Dict[str, Any]]
    ) -> pd.DataFrame:
        """
        PEGCalculatorë¥¼ ì‚¬ìš©í•˜ì—¬ ë°ì´í„° ì²˜ë¦¬ ë° íŒŒìƒ PEG ê³„ì‚°

        Args:
            n1_df (pd.DataFrame): N-1 ê¸°ê°„ ë°ì´í„°
            n_df (pd.DataFrame): N ê¸°ê°„ ë°ì´í„°
            peg_config (Dict[str, Any]): PEG ì„¤ì •
            filters (Dict[str, Any]): í•„í„° ì¡°ê±´
            derived_pegs (List[Dict[str, Any]]): íŒŒìƒ PEG ì •ì˜ ë¦¬ìŠ¤íŠ¸

        Returns:
            pd.DataFrame: ì²˜ë¦¬ëœ PEG ë°ì´í„° (íŒŒìƒ PEG í¬í•¨)
        """
        logger.debug("_process_with_calculator() í˜¸ì¶œ: PEGCalculator ì²˜ë¦¬ ì‹œì‘")

        try:
            # ì‹ë³„ì ì •ë³´ ì¶”ì¶œ (ì§‘ê³„ ì „)
            metadata = {}
            source_df = n1_df if not n1_df.empty else n_df
            if not source_df.empty:
                first_row = source_df.iloc[0]
                if "ne" in source_df.columns: metadata["ne_key"] = str(first_row["ne"]) if pd.notna(first_row["ne"]) else None
                if "swname" in source_df.columns: metadata["swname"] = str(first_row["swname"]) if pd.notna(first_row["swname"]) else None
                if "rel_ver" in source_df.columns: metadata["rel_ver"] = str(first_row["rel_ver"]) if pd.notna(first_row["rel_ver"]) else None
                if "index_name" in source_df.columns: metadata["index_name"] = str(first_row["index_name"]) if pd.notna(first_row["index_name"]) else None

            # cell_id í•„í„° ì—†ìœ¼ë©´ ì—¬ëŸ¬ cell í‰ê· í™”
            if 'cellid' not in filters or not filters.get('cellid'):
                logger.info("cell_id ë¯¸ì§€ì • - ì—¬ëŸ¬ cell í‰ê· í™” ìˆ˜í–‰")
                for df_name, df in [("N-1", n1_df), ("N", n_df)]:
                    if not df.empty and 'dimensions' in df.columns:
                        df['dimensions'] = df['dimensions'].str.replace(r'CellIdentity=\d+,?', '', regex=True).str.strip(',')
                agg_cols = ['value']
                first_cols = ['ne', 'swname', 'family_name']
                if not n1_df.empty:
                    group_keys = ['timestamp', 'peg_name', 'dimensions'] if 'dimensions' in n1_df.columns else ['timestamp', 'peg_name']
                    agg_dict = {'value': 'mean'}
                    for col in first_cols: 
                        if col in n1_df.columns: agg_dict[col] = 'first'
                    n1_df = n1_df.groupby(group_keys).agg(agg_dict).reset_index()
                if not n_df.empty:
                    group_keys = ['timestamp', 'peg_name', 'dimensions'] if 'dimensions' in n_df.columns else ['timestamp', 'peg_name']
                    agg_dict = {'value': 'mean'}
                    for col in first_cols:
                        if col in n_df.columns: agg_dict[col] = 'first'
                    n_df = n_df.groupby(group_keys).agg(agg_dict).reset_index()

            # ê¸°ë³¸ PEG ì§‘ê³„
            group_keys = ['peg_name', 'dimensions'] if 'dimensions' in n1_df.columns else ['peg_name']
            n1_aggregated = n1_df.groupby(group_keys)["value"].mean().reset_index() if not n1_df.empty else pd.DataFrame(columns=group_keys + ["value"])
            n1_aggregated["period"] = "N-1"
            
            group_keys = ['peg_name', 'dimensions'] if 'dimensions' in n_df.columns else ['peg_name']
            n_aggregated = n_df.groupby(group_keys)["value"].mean().reset_index() if not n_df.empty else pd.DataFrame(columns=group_keys + ["value"])
            n_aggregated["period"] = "N"

            combined_df = pd.concat([n1_aggregated, n_aggregated], ignore_index=True)
            if combined_df.empty:
                return pd.DataFrame(columns=["peg_name", "period", "avg_value", "change_pct"])

            # --- [íŒŒìƒ PEG ê³„ì‚° ë¡œì§] ---
            # íŒŒìƒ PEG êµ¬ë¶„ì„ ìœ„í•œ í”Œë˜ê·¸ ì¶”ê°€
            combined_df['is_derived'] = False
            derived_peg_names = []
            
            if derived_pegs:
                logger.info("íŒŒìƒ PEG ê³„ì‚° ì‹œì‘: %dê°œ", len(derived_pegs))
                # íŒŒìƒ PEG ê³„ì‚° ì‹œì—ëŠ” dimensionsë¥¼ ê³ ë ¤í•˜ì§€ ì•ŠìŒ (ë‹¨ìˆœí™”ë¥¼ ìœ„í•´)
                # peg_nameë§Œìœ¼ë¡œ pivotí•˜ì—¬ ê³„ì‚° í›„, ì›ë˜ ë°ì´í„°ì™€ merge
                simple_combined_df = combined_df.groupby(['peg_name', 'period'])['value'].mean().reset_index()
                eval_df = simple_combined_df.pivot(index="period", columns="peg_name", values="value")

                sorted_derived_pegs = self._resolve_dependency_order(derived_pegs)

                for peg_def in sorted_derived_pegs:
                    output_peg = peg_def['output_peg']
                    formula = peg_def['formula']
                    try:
                        eval_df[output_peg] = eval_df.eval(formula, engine='python')
                        logger.debug("íŒŒìƒ PEG ê³„ì‚° ì„±ê³µ: %s", output_peg)
                    except Exception as e:
                        logger.warning("íŒŒìƒ PEG '%s' ê³„ì‚° ì‹¤íŒ¨. ìˆ˜ì‹: '%s'. ì˜¤ë¥˜: %s", output_peg, formula, e)
                        eval_df[output_peg] = pd.NA

                # ê³„ì‚°ëœ íŒŒìƒ PEGë¥¼ long formatìœ¼ë¡œ ë³€í™˜
                derived_peg_names = [p['output_peg'] for p in derived_pegs if p['output_peg'] in eval_df.columns]
                if derived_peg_names:
                    derived_df_long = eval_df[derived_peg_names].reset_index().melt(
                        id_vars=['period'], var_name='peg_name', value_name='value'
                    )
                    # íŒŒìƒ PEG í‘œì‹œ
                    derived_df_long['is_derived'] = True
                    # ê¸°ì¡´ ë°ì´í„°ì™€ íŒŒìƒ ë°ì´í„° ê²°í•© (íŒŒìƒ PEGê°€ ë’¤ì— ì¶”ê°€ë¨)
                    combined_df = pd.concat([combined_df, derived_df_long], ignore_index=True)
                    logger.info("íŒŒìƒ PEG ë°ì´í„° ê²°í•© ì™„ë£Œ: %dê°œ (is_derived=True í”Œë˜ê·¸ ì¶”ê°€)", len(derived_peg_names))
            # --- [ê³„ì‚° ë¡œì§ ì™„ë£Œ] ---

            # ë³€í™”ìœ¨ ê³„ì‚°
            index_keys = ['peg_name', 'dimensions'] if 'dimensions' in combined_df.columns else ['peg_name']
            pivot_df = combined_df.pivot_table(index=index_keys, columns="period", values="value", aggfunc='mean')

            if "N-1" in pivot_df.columns and "N" in pivot_df.columns:
                # N-1=0 & N=0ì¸ PEG ì‹ë³„ (í† í° ìµœì í™”ìš©)
                zero_both_mask = (pivot_df["N-1"] == 0) & (pivot_df["N"] == 0)
                
                # ë³€í™”ìœ¨ ê³„ì‚° ê°€ëŠ¥í•œ PEG ì‹ë³„ (N-1ì´ 0ì´ ì•„ë‹Œ ê²½ìš°)
                valid_mask = (pivot_df["N-1"].notna()) & (pivot_df["N"].notna()) & (pivot_df["N-1"] != 0)
                
                # ì´ˆê¸°í™”: ëª¨ë“  change_pctë¥¼ NULLë¡œ ì„¤ì •
                pivot_df["change_pct"] = None
                
                # ğŸ“Š í†µê³„ ë¡œê¹… (INFO ë ˆë²¨): ì œì™¸ëœ PEG ê°œìˆ˜
                if zero_both_mask.sum() > 0:
                    logger.info(
                        f"ğŸ“Š í† í° ìµœì í™”: N-1=0 & N=0ì¸ PEG {zero_both_mask.sum()}ê°œ ë°œê²¬ "
                        f"â†’ change_pct=NULL ì²˜ë¦¬ (í”„ë¡¬í”„íŠ¸ì—ì„œ ì œì™¸ë¨, DataFrameì—ëŠ” ìœ ì§€)"
                    )
                    
                    # ğŸ” ìƒì„¸ ë¡œê¹… (DEBUG2 ë ˆë²¨): ì œì™¸ëœ PEG ì´ë¦„
                    from config.logging_config import log_at_debug2
                    zero_both_pegs = pivot_df[zero_both_mask].index.tolist()
                    log_at_debug2(
                        logger,
                        f"ğŸ” N-1=0 & N=0 PEG ëª©ë¡ ({len(zero_both_pegs)}ê°œ): {zero_both_pegs}"
                    )
                
                # ì •ìƒ ì¼€ì´ìŠ¤: ë³€í™”ìœ¨ ê³„ì‚° (N-1ì´ 0ì´ ì•„ë‹Œ ê²½ìš°ë§Œ)
                if valid_mask.sum() > 0:
                    # ë³€í™”ìœ¨ ê³„ì‚° ì „ ìŒìˆ˜ ê°’ ê²€ì¦
                    negative_n1_mask = (pivot_df["N-1"] < 0)
                    negative_n_mask = (pivot_df["N"] < 0)
                    
                    if negative_n1_mask.sum() > 0:
                        logger.error("âŒ N-1 ê¸°ê°„ì— ìŒìˆ˜ ê°’ì´ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤:")
                        for peg_name, value in pivot_df.loc[negative_n1_mask, "N-1"].items():
                            logger.error(f"   PEG: {peg_name}, N-1 ê°’: {value}")
                    
                    if negative_n_mask.sum() > 0:
                        logger.error("âŒ N ê¸°ê°„ì— ìŒìˆ˜ ê°’ì´ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤:")
                        for peg_name, value in pivot_df.loc[negative_n_mask, "N"].items():
                            logger.error(f"   PEG: {peg_name}, N ê°’: {value}")
                    
                    # ë³€í™”ìœ¨ ê³„ì‚°
                    pivot_df.loc[valid_mask, "change_pct"] = ((pivot_df.loc[valid_mask, "N"] - pivot_df.loc[valid_mask, "N-1"]) / pivot_df.loc[valid_mask, "N-1"] * 100)
                    
                    # ë³€í™”ìœ¨ì´ ìŒìˆ˜ì¸ ê²½ìš° ìƒì„¸ ë¡œê¹… (í° ë³€í™”ë§Œ)
                    large_negative_changes = pivot_df[(pivot_df["change_pct"] < -20) & valid_mask]
                    if len(large_negative_changes) > 0:
                        logger.warning("âš ï¸ í° í­ì˜ ê°ì†Œê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤ (ë³€í™”ìœ¨ < -20%):")
                        for peg_name, row in large_negative_changes.iterrows():
                            n_minus_1_val = row["N-1"]
                            n_val = row["N"]
                            change_val = row["change_pct"]
                            logger.warning(f"   PEG: {peg_name}")
                            logger.warning(f"      N-1 ê°’: {n_minus_1_val:.2f}")
                            logger.warning(f"      N ê°’: {n_val:.2f}")
                            logger.warning(f"      ë³€í™”ìœ¨: {change_val:.2f}%")
                            logger.warning(f"      í•´ì„: ê°’ì´ {abs(change_val):.1f}% ê°ì†Œí–ˆìŠµë‹ˆë‹¤")
            else:
                pivot_df["change_pct"] = 0

            # ìµœì¢… í˜•íƒœë¡œ ë³€í™˜
            processed_df = pivot_df.reset_index()
            id_vars = [key for key in index_keys] + ["change_pct"]
            value_vars = [col for col in ["N-1", "N"] if col in processed_df.columns]
            processed_df = processed_df.melt(
                id_vars=id_vars,
                value_vars=value_vars,
                var_name="period",
                value_name="avg_value",
            )

            # ì‹ë³„ì ì •ë³´ë¥¼ ëª¨ë“  í–‰ì— ì¶”ê°€
            if metadata:
                for key, value in metadata.items():
                    if value is not None: processed_df[key] = value

            # --- [íŒŒìƒ PEGë¥¼ DataFrame ë§¨ ë§ˆì§€ë§‰ìœ¼ë¡œ ì •ë ¬] ---
            # íŒŒìƒ PEG í‘œì‹œ ì»¬ëŸ¼ ì¶”ê°€
            processed_df['is_derived'] = processed_df['peg_name'].isin(derived_peg_names)
            
            # ì •ë ¬: ê¸°ë³¸ PEGê°€ ë¨¼ì €, íŒŒìƒ PEGê°€ ë‚˜ì¤‘ì—
            # is_derived=False(ê¸°ë³¸ PEG)ê°€ ë¨¼ì € ì˜¤ê³ , is_derived=True(íŒŒìƒ PEG)ê°€ ë‚˜ì¤‘ì— ì˜´
            processed_df = processed_df.sort_values(by=['is_derived', 'peg_name', 'period']).reset_index(drop=True)
            
            logger.info("PEGCalculator ì²˜ë¦¬ ì™„ë£Œ: %dí–‰ (íŒŒìƒ PEG %dê°œëŠ” DataFrame ë§¨ ë§ˆì§€ë§‰ì— ë°°ì¹˜ë¨)", 
                       len(processed_df), len(derived_peg_names))
            return processed_df

        except Exception as e:
            raise PEGProcessingError(
                f"PEGCalculator ì²˜ë¦¬ ì‹¤íŒ¨: {e}",
                processing_step="aggregation",
                data_context={"n1_rows": len(n1_df), "n_rows": len(n_df)},
            ) from e

    def process_peg_data(
        self,
        time_ranges: Tuple[datetime, datetime, datetime, datetime],
        table_config: Dict[str, Any],
        filters: Dict[str, Any],
        peg_config: Optional[Dict[str, Any]] = None,
        request_context: Optional[Dict[str, Any]] = None,
    ) -> pd.DataFrame:
        """
        ì „ì²´ PEG ë°ì´í„° ì²˜ë¦¬ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰

        Args:
            time_ranges (Tuple): (n1_start, n1_end, n_start, n_end)
            table_config (Dict[str, Any]): í…Œì´ë¸”/ì»¬ëŸ¼ ì„¤ì •
            filters (Dict[str, Any]): í•„í„° ì¡°ê±´
            peg_config (Optional[Dict[str, Any]]): PEG ì„¤ì •
            request_context (Optional[Dict[str, Any]]): API ìš”ì²­ ì»¨í…ìŠ¤íŠ¸ (CSV ê²½ë¡œ ì¬ì •ì˜ìš©)

        Returns:
            pd.DataFrame: ì²˜ë¦¬ëœ PEG ë°ì´í„°

        Raises:
            PEGProcessingError: ì²˜ë¦¬ ì‹¤íŒ¨ ì‹œ
        """
        logger.info("process_peg_data() í˜¸ì¶œ: PEG ë°ì´í„° ì²˜ë¦¬ ì›Œí¬í”Œë¡œìš° ì‹œì‘")

        # --- [CSV í•„í„° ë¡œì§ ìˆ˜ì •] ---
        settings = get_settings()
        db_filter = {}
        derived_pegs = []
        if settings.peg_filter_enabled:
            request_context = request_context or {}
            filter_file_override = request_context.get("peg_filter_file")
            filename_to_use = filter_file_override if filter_file_override else settings.peg_filter_default_file
            full_csv_path = os.path.join(settings.peg_filter_dir_path, filename_to_use)
            
            # í™•ì¥ëœ ë¡œë” í˜¸ì¶œ
            db_filter, derived_pegs = load_peg_definitions_from_csv(full_csv_path)
            logger.info("CSV ë¡œë“œ: DBí•„í„° %d families, íŒŒìƒPEG %dê°œ", len(db_filter), len(derived_pegs))
        else:
            logger.debug("CSV í•„í„°ë§ ê¸°ëŠ¥ì´ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
        # --- [ìˆ˜ì • ì™„ë£Œ] ---

        try:
            # DEBUG2 ë¡œê¹… ìœ í‹¸ë¦¬í‹° import
            from config.logging_config import log_step, log_data_flow
            
            # 1ë‹¨ê³„: ì‹œê°„ ë²”ìœ„ ê²€ì¦
            logger.info("1ë‹¨ê³„: ì‹œê°„ ë²”ìœ„ ê²€ì¦")
            log_step(logger, "[PEG ì²˜ë¦¬ ë‹¨ê³„ 1] ì‹œê°„ ë²”ìœ„ ê²€ì¦")
            self._validate_time_ranges(time_ranges)
            logger.debug(
                "ì‹œê°„ ë²”ìœ„ ìš”ì•½: N-1=%s~%s, N=%s~%s",
                time_ranges[0],
                time_ranges[1],
                time_ranges[2],
                time_ranges[3],
            )

            # 2ë‹¨ê³„: ì›ì‹œ ë°ì´í„° ì¡°íšŒ
            logger.info("2ë‹¨ê³„: ì›ì‹œ ë°ì´í„° ì¡°íšŒ")
            log_step(logger, "[PEG ì²˜ë¦¬ ë‹¨ê³„ 2] DB ì›ì‹œ ë°ì´í„° ì¡°íšŒ", f"table={table_config.get('table')}")
            n1_df, n_df = self._retrieve_raw_peg_data(time_ranges, table_config, filters, peg_filter=db_filter)
            log_data_flow(logger, "ì¡°íšŒëœ N-1 ë°ì´í„°", {"shape": n1_df.shape, "columns": list(n1_df.columns), "sample": n1_df.head(3).to_dict() if len(n1_df) > 0 else {}})
            log_data_flow(logger, "ì¡°íšŒëœ N ë°ì´í„°", {"shape": n_df.shape, "columns": list(n_df.columns), "sample": n_df.head(3).to_dict() if len(n_df) > 0 else {}})
            logger.debug(
                "ì›ì‹œ ë°ì´í„° ì¡°íšŒ ê²°ê³¼: N-1 rows=%d, N rows=%d", len(n1_df), len(n_df)
            )

            # 3ë‹¨ê³„: ì›ì‹œ ë°ì´í„° ê²€ì¦
            logger.info("3ë‹¨ê³„: ì›ì‹œ ë°ì´í„° ê²€ì¦")
            log_step(logger, "[PEG ì²˜ë¦¬ ë‹¨ê³„ 3] ì›ì‹œ ë°ì´í„° ê²€ì¦")
            self._validate_raw_data(n1_df, n_df)

            # 4ë‹¨ê³„: PEGCalculator ë° íŒŒìƒ PEG ì²˜ë¦¬
            logger.info("4ë‹¨ê³„: PEGCalculator ë° íŒŒìƒ PEG ì²˜ë¦¬")
            log_step(logger, "[PEG ì²˜ë¦¬ ë‹¨ê³„ 4] ë°ì´í„° ë³€í™˜ ë° ê³„ì‚°", f"íŒŒìƒPEG={len(derived_pegs)}ê°œ")
            processed_df = self._process_with_calculator(n1_df, n_df, peg_config or {}, filters, derived_pegs=derived_pegs)
            log_data_flow(logger, "ë³€í™˜ëœ PEG ë°ì´í„°", {"shape": processed_df.shape, "columns": list(processed_df.columns), "sample": processed_df.head(3).to_dict() if len(processed_df) > 0 else {}})
            logger.debug(
                "PEGCalculator ì²˜ë¦¬ ê²°ê³¼: í–‰ìˆ˜=%d, ì»¬ëŸ¼=%s",
                len(processed_df),
                list(processed_df.columns),
            )

            logger.info("PEG ë°ì´í„° ì²˜ë¦¬ ì›Œí¬í”Œë¡œìš° ì™„ë£Œ: %dí–‰", len(processed_df))
            return processed_df

        except PEGProcessingError:
            # ì´ë¯¸ PEGProcessingErrorì¸ ê²½ìš° ê·¸ëŒ€ë¡œ ì „íŒŒ
            raise

        except Exception as e:
            # ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ë¥¼ PEGProcessingErrorë¡œ ë³€í™˜
            raise PEGProcessingError(
                f"PEG ë°ì´í„° ì²˜ë¦¬ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}",
                processing_step="unknown",
                data_context={"time_ranges": str(time_ranges)[:100]},
            ) from e

    def get_processing_status(self) -> Dict[str, Any]:
        """ì²˜ë¦¬ ìƒíƒœ ì •ë³´ ë°˜í™˜"""
        return {
            "processing_steps": self.processing_steps,
            "step_count": len(self.processing_steps),
            "dependencies_ready": {
                "database_repository": self.database_repository is not None,
                "peg_calculator": self.peg_calculator is not None,
            },
        }

    def close(self) -> None:
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        if hasattr(self.database_repository, "disconnect"):
            self.database_repository.disconnect()

        logger.info("PEGProcessingService ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ")

    def __enter__(self):
        """ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì € ì§„ì…"""
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        """ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì € ì¢…ë£Œ"""
        self.close()

        # ì˜ˆì™¸ ë°œìƒ ì‹œ ë¡œê·¸ ê¸°ë¡
        if exc_type:
            logger.error("PEGProcessingService ì»¨í…ìŠ¤íŠ¸ì—ì„œ ì˜ˆì™¸ ë°œìƒ: %s", exc_val)
        return False  # ì˜ˆì™¸ë¥¼ ë‹¤ì‹œ ë°œìƒì‹œí‚´

