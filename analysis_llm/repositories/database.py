"""
Database Repository Interface and PostgreSQL Implementation

ì´ ëª¨ë“ˆì€ ë°ì´í„°ë² ì´ìŠ¤ ì•¡ì„¸ìŠ¤ë¥¼ ìœ„í•œ Repository íŒ¨í„´ì„ êµ¬í˜„í•©ë‹ˆë‹¤.
ì¶”ìƒ ì¸í„°í˜ì´ìŠ¤ì™€ PostgreSQL êµ¬ì²´ êµ¬í˜„ì„ ì œê³µí•©ë‹ˆë‹¤.

ê¸°ì¡´ main.pyì˜ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ë° ì¿¼ë¦¬ ë¡œì§ì„ ëª¨ë“ˆí™”í•œ ê²ƒì…ë‹ˆë‹¤.
"""

from __future__ import annotations

import logging
import os
import time

# ì„ì‹œë¡œ ì ˆëŒ€ import ì‚¬ìš© (ë‚˜ì¤‘ì— íŒ¨í‚¤ì§€ êµ¬ì¡° ì •ë¦¬ ì‹œ ìˆ˜ì •)
import sys
from abc import ABC, abstractmethod
from contextlib import contextmanager
from datetime import datetime
from typing import Any, Dict, List, Optional, Tuple

import psycopg2
import psycopg2.extras
import psycopg2.pool

# config ëª¨ë“ˆ ì§€ì—° import
_config_get_settings = None


def get_config_settings():
    """Configuration Managerì—ì„œ ì„¤ì • ê°€ì ¸ì˜¤ê¸° (ì§€ì—° ë¡œë”©)"""
    global _config_get_settings
    if _config_get_settings is None:
        from config import get_settings

        _config_get_settings = get_settings
    return _config_get_settings()


from ..exceptions import DatabaseError

# ë¡œê¹… ì„¤ì •
logger = logging.getLogger(__name__)


class DatabaseRepository(ABC):
    """
    ë°ì´í„°ë² ì´ìŠ¤ Repository ì¶”ìƒ ê¸°ë³¸ í´ë˜ìŠ¤

    ë°ì´í„°ë² ì´ìŠ¤ ì•¡ì„¸ìŠ¤ë¥¼ ìœ„í•œ ê³µí†µ ì¸í„°í˜ì´ìŠ¤ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.
    êµ¬ì²´ì ì¸ ë°ì´í„°ë² ì´ìŠ¤ êµ¬í˜„ì²´ë“¤ì€ ì´ ì¸í„°í˜ì´ìŠ¤ë¥¼ êµ¬í˜„í•´ì•¼ í•©ë‹ˆë‹¤.

    ì£¼ìš” ê¸°ëŠ¥:
    1. ì—°ê²° ê´€ë¦¬ (connect, disconnect)
    2. ë°ì´í„° ì¡°íšŒ (fetch_data)
    3. ì¿¼ë¦¬ ì‹¤í–‰ (execute_query)
    4. ë™ì  ì¿¼ë¦¬ ìƒì„± ì§€ì›
    """

    @abstractmethod
    def connect(self) -> None:
        """
        ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì„¤ì •

        Raises:
            DatabaseError: ì—°ê²° ì‹¤íŒ¨ ì‹œ
        """

    @abstractmethod
    def disconnect(self) -> None:
        """
        ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í•´ì œ

        Raises:
            DatabaseError: ì—°ê²° í•´ì œ ì‹¤íŒ¨ ì‹œ
        """

    @abstractmethod
    def fetch_data(
        self,
        query: str,
        params: Optional[Dict[str, Any]] = None,
        table_name: Optional[str] = None,
        columns: Optional[List[str]] = None,
        time_range: Optional[Tuple[datetime, datetime]] = None,
        limit: Optional[int] = None,
    ) -> List[Dict[str, Any]]:
        """
        ë°ì´í„° ì¡°íšŒ (SELECT ì¿¼ë¦¬)

        Args:
            query (str): ì‹¤í–‰í•  SQL ì¿¼ë¦¬
            params (Optional[Dict[str, Any]]): ì¿¼ë¦¬ ë§¤ê°œë³€ìˆ˜
            table_name (Optional[str]): ë™ì  í…Œì´ë¸”ëª… (ì¿¼ë¦¬ì— {table} í”Œë ˆì´ìŠ¤í™€ë” ì‚¬ìš© ì‹œ)
            columns (Optional[List[str]]): ë™ì  ì»¬ëŸ¼ëª… (ì¿¼ë¦¬ì— {columns} í”Œë ˆì´ìŠ¤í™€ë” ì‚¬ìš© ì‹œ)
            time_range (Optional[Tuple[datetime, datetime]]): ì‹œê°„ ë²”ìœ„ í•„í„°
            limit (Optional[int]): ê²°ê³¼ ê°œìˆ˜ ì œí•œ

        Returns:
            List[Dict[str, Any]]: ì¡°íšŒ ê²°ê³¼ (ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸)

        Raises:
            DatabaseError: ì¿¼ë¦¬ ì‹¤í–‰ ì‹¤íŒ¨ ì‹œ
        """

    @abstractmethod
    def execute_query(self, query: str, params: Optional[Dict[str, Any]] = None, commit: bool = True) -> int:
        """
        ì¿¼ë¦¬ ì‹¤í–‰ (INSERT, UPDATE, DELETE)

        Args:
            query (str): ì‹¤í–‰í•  SQL ì¿¼ë¦¬
            params (Optional[Dict[str, Any]]): ì¿¼ë¦¬ ë§¤ê°œë³€ìˆ˜
            commit (bool): íŠ¸ëœì­ì…˜ ì»¤ë°‹ ì—¬ë¶€

        Returns:
            int: ì˜í–¥ë°›ì€ í–‰ ìˆ˜

        Raises:
            DatabaseError: ì¿¼ë¦¬ ì‹¤í–‰ ì‹¤íŒ¨ ì‹œ
        """

    @abstractmethod
    def test_connection(self) -> bool:
        """
        ì—°ê²° í…ŒìŠ¤íŠ¸

        Returns:
            bool: ì—°ê²° ì„±ê³µ ì—¬ë¶€
        """

    def build_dynamic_query(
        self,
        base_query: str,
        table_name: Optional[str] = None,
        columns: Optional[List[str]] = None,
        time_range: Optional[Tuple[datetime, datetime]] = None,
        additional_conditions: Optional[List[str]] = None,
    ) -> Tuple[str, Dict[str, Any]]:
        """
        ë™ì  ì¿¼ë¦¬ ìƒì„± (ê³µí†µ ìœ í‹¸ë¦¬í‹°)

        Args:
            base_query (str): ê¸°ë³¸ ì¿¼ë¦¬ í…œí”Œë¦¿
            table_name (Optional[str]): í…Œì´ë¸”ëª…
            columns (Optional[List[str]]): ì»¬ëŸ¼ ëª©ë¡
            time_range (Optional[Tuple[datetime, datetime]]): ì‹œê°„ ë²”ìœ„
            additional_conditions (Optional[List[str]]): ì¶”ê°€ ì¡°ê±´ë“¤

        Returns:
            Tuple[str, Dict[str, Any]]: (ì™„ì„±ëœ ì¿¼ë¦¬, ë§¤ê°œë³€ìˆ˜)
        """
        params = {}

        # í…Œì´ë¸”ëª… ì¹˜í™˜
        if table_name and "{table}" in base_query:
            # SQL ì¸ì ì…˜ ë°©ì§€ë¥¼ ìœ„í•œ ê¸°ë³¸ ê²€ì¦
            if not table_name.replace("_", "").replace("-", "").isalnum():
                raise DatabaseError("ìœ íš¨í•˜ì§€ ì•Šì€ í…Œì´ë¸”ëª…", details={"table_name": table_name})
            base_query = base_query.replace("{table}", table_name)

        # ì»¬ëŸ¼ëª… ì¹˜í™˜
        if columns and "{columns}" in base_query:
            # SQL ì¸ì ì…˜ ë°©ì§€ë¥¼ ìœ„í•œ ê¸°ë³¸ ê²€ì¦
            for col in columns:
                if not col.replace("_", "").replace("-", "").isalnum():
                    raise DatabaseError("ìœ íš¨í•˜ì§€ ì•Šì€ ì»¬ëŸ¼ëª…", details={"column": col})
            columns_str = ", ".join(columns)
            base_query = base_query.replace("{columns}", columns_str)

        # ì‹œê°„ ë²”ìœ„ ì¡°ê±´ ì¶”ê°€
        conditions = []
        if time_range:
            start_time, end_time = time_range
            conditions.append("timestamp BETWEEN %(start_time)s AND %(end_time)s")
            params["start_time"] = start_time
            params["end_time"] = end_time

        # ì¶”ê°€ ì¡°ê±´ë“¤
        if additional_conditions:
            conditions.extend(additional_conditions)

        # WHERE ì ˆ ì¶”ê°€
        if conditions:
            if "WHERE" in base_query.upper():
                base_query += " AND " + " AND ".join(conditions)
            else:
                base_query += " WHERE " + " AND ".join(conditions)

        logger.debug("ë™ì  ì¿¼ë¦¬ ìƒì„±: %s (ë§¤ê°œë³€ìˆ˜: %dê°œ)", base_query, len(params))
        return base_query, params


class PostgreSQLRepository(DatabaseRepository):
    """
    PostgreSQL ë°ì´í„°ë² ì´ìŠ¤ Repository êµ¬í˜„ì²´

    psycopg2ë¥¼ ì‚¬ìš©í•˜ì—¬ PostgreSQL ë°ì´í„°ë² ì´ìŠ¤ì— ì•¡ì„¸ìŠ¤í•©ë‹ˆë‹¤.
    ì—°ê²° í’€ë§, ì˜¤ë¥˜ ì²˜ë¦¬, ë¦¬ì†ŒìŠ¤ ê´€ë¦¬ë¥¼ í¬í•¨í•©ë‹ˆë‹¤.

    ê¸°ì¡´ main.pyì˜ PostgreSQL ì—°ê²° ë¡œì§ì„ ëª¨ë“ˆí™”í•œ ê²ƒì…ë‹ˆë‹¤.
    """

    def __init__(self, config_override: Optional[Dict[str, Any]] = None):
        """
        PostgreSQLRepository ì´ˆê¸°í™”

        Args:
            config_override (Optional[Dict[str, Any]]): ì„¤ì • ì˜¤ë²„ë¼ì´ë“œ (í…ŒìŠ¤íŠ¸ìš©)
        """
        # Configuration Managerì—ì„œ ì„¤ì • ë¡œë“œ
        try:
            settings = get_config_settings()
            self.config = {
                "host": settings.db_host,
                "port": settings.db_port,
                "database": settings.db_name,
                "user": settings.db_user,
                "password": settings.db_password.get_secret_value(),
                "pool_size": settings.db_pool_size,
            }
            logger.info("Configuration Managerì—ì„œ DB ì„¤ì • ë¡œë“œ ì™„ë£Œ")
        except Exception as e:
            logger.warning("Configuration Manager ë¡œë”© ì‹¤íŒ¨, ê¸°ë³¸ê°’ ì‚¬ìš©: %s", e)
            self.config = {
                "host": os.getenv("DB_HOST", "165.213.69.30"),
                "port": int(os.getenv("DB_PORT", "5442")),
                "database": os.getenv("DB_NAME", "pvt_db"),
                "user": os.getenv("DB_USER", "testuser"),
                "password": os.getenv("DB_PASSWORD", "1234qwer"),
                "pool_size": int(os.getenv("DB_POOL_SIZE", "5")),
            }

        # ì„¤ì • ì˜¤ë²„ë¼ì´ë“œ ì ìš© (í…ŒìŠ¤íŠ¸ìš©)
        if config_override:
            self.config.update(config_override)
            logger.debug("DB ì„¤ì • ì˜¤ë²„ë¼ì´ë“œ ì ìš©: %s", list(config_override.keys()))

        # ì—°ê²° í’€ ì´ˆê¸°í™” (ì§€ì—° ë¡œë”©)
        self._pool = None
        self._is_connected = False

        logger.info(
            "PostgreSQLRepository ì´ˆê¸°í™” ì™„ë£Œ: host=%s, database=%s", self.config["host"], self.config["database"]
        )

    def connect(self) -> None:
        """ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í’€ ì´ˆê¸°í™”"""
        if self._is_connected:
            logger.debug("connect(): ì´ë¯¸ ì—°ê²°ëœ ìƒíƒœ - host=%s, db=%s, pool_size=%s",
                         self.config.get("host"), self.config.get("database"), self.config.get("pool_size"))
            return

        try:
            logger.info("connect(): ì—°ê²° í’€ ìƒì„± ì‹œì‘ | host=%s, port=%s, db=%s, pool_size=%s",
                        self.config.get("host"), self.config.get("port"), self.config.get("database"), self.config.get("pool_size"))
            t0 = time.perf_counter()
            # ì—°ê²° í’€ ìƒì„±
            self._pool = psycopg2.pool.SimpleConnectionPool(
                minconn=1,
                maxconn=self.config["pool_size"],
                host=self.config["host"],
                port=self.config["port"],
                database=self.config["database"],
                user=self.config["user"],
                password=self.config["password"],
            )

            self._is_connected = True
            elapsed = (time.perf_counter() - t0) * 1000
            logger.info(
                "connect(): ì—°ê²° í’€ ìƒì„± ì™„ë£Œ | host=%s, db=%s, pool_size=%s, %.1fms",
                self.config["host"], self.config["database"], self.config["pool_size"], elapsed
            )

        except psycopg2.Error as e:
            raise DatabaseError(
                "PostgreSQL ì—°ê²° ì‹¤íŒ¨",
                details={
                    "host": self.config["host"],
                    "database": self.config["database"],
                    "error": str(e),
                },
                connection_info=self.get_connection_info(),
            ) from e

    def disconnect(self) -> None:
        """ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í’€ í•´ì œ"""
        if not self._is_connected or not self._pool:
            logger.debug("disconnect(): ì—°ê²°ë˜ì§€ ì•Šì€ ìƒíƒœ - ë¬´ì‹œ")
            return

        try:
            logger.info("disconnect(): ì—°ê²° í’€ í•´ì œ ì‹œì‘")
            self._pool.closeall()
            self._pool = None
            self._is_connected = False
            logger.info("disconnect(): ì—°ê²° í’€ í•´ì œ ì™„ë£Œ")

        except Exception as e:
            logger.error("ì—°ê²° í’€ í•´ì œ ì¤‘ ì˜¤ë¥˜: %s", e)
            raise DatabaseError("ì—°ê²° í’€ í•´ì œ ì‹¤íŒ¨") from e

    @contextmanager
    def get_connection(self):
        """
        ì—°ê²° í’€ì—ì„œ ì—°ê²° íšë“ (ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €)

        Yields:
            psycopg2.connection: ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°
        """
        if not self._is_connected or not self._pool:
            raise DatabaseError("ì—°ê²° í’€ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. connect()ë¥¼ ë¨¼ì € í˜¸ì¶œí•˜ì„¸ìš”")

        connection = None
        try:
            t0 = time.perf_counter()
            connection = self._pool.getconn()
            elapsed = (time.perf_counter() - t0) * 1000
            logger.debug("get_connection(): ì—°ê²° íšë“ ì™„ë£Œ (%.1fms)", elapsed)
            yield connection

        except psycopg2.Error as e:
            if connection:
                connection.rollback()
            raise DatabaseError(
                "ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì˜¤ë¥˜",
                details={"error": str(e)},
                connection_info=self.get_connection_info(),
            ) from e

        finally:
            if connection:
                self._pool.putconn(connection)
                logger.debug("get_connection(): ì—°ê²° ë°˜í™˜ ì™„ë£Œ")

    def test_connection(self) -> bool:
        """ì—°ê²° í…ŒìŠ¤íŠ¸"""
        try:
            if not self._is_connected:
                self.connect()

            with self.get_connection() as conn:
                with conn.cursor() as cursor:
                    cursor.execute("SELECT 1")
                    result = cursor.fetchone()
                    success = result is not None

            logger.info("ì—°ê²° í…ŒìŠ¤íŠ¸ %s", "ì„±ê³µ" if success else "ì‹¤íŒ¨")
            return success

        except Exception as e:
            logger.error("ì—°ê²° í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: %s", e)
            return False

    def fetch_data(
        self,
        query: str,
        params: Optional[Dict[str, Any]] = None,
        table_name: Optional[str] = None,
        columns: Optional[List[str]] = None,
        time_range: Optional[Tuple[datetime, datetime]] = None,
        limit: Optional[int] = None,
    ) -> List[Dict[str, Any]]:
        """
        ë°ì´í„° ì¡°íšŒ (SELECT ì¿¼ë¦¬)

        ê¸°ì¡´ main.pyì˜ ë°ì´í„°ë² ì´ìŠ¤ ì¡°íšŒ ë¡œì§ì„ ëª¨ë“ˆí™”í•œ ê²ƒì…ë‹ˆë‹¤.
        """
        logger.debug(
            "fetch_data(): í˜¸ì¶œ | query_len=%d, preview=%s, params_keys=%s, table=%s, time_range=%s, limit=%s",
            len(query or ""), (query or "")[:180].replace("\n", " "),
            list((params or {}).keys()), table_name, time_range, limit
        )

        if not self._is_connected:
            self.connect()

        # ë™ì  ì¿¼ë¦¬ ìƒì„±
        if table_name or columns or time_range:
            query, dynamic_params = self.build_dynamic_query(query, table_name, columns, time_range)
            # ë§¤ê°œë³€ìˆ˜ ë³‘í•©
            if params:
                dynamic_params.update(params)
            params = dynamic_params

        # LIMIT ì ˆ ì¶”ê°€
        if limit and limit > 0:
            query += f" LIMIT {limit}"

        try:
            with self.get_connection() as conn:
                with conn.cursor(cursor_factory=psycopg2.extras.RealDictCursor) as cursor:
                    # ì¿¼ë¦¬ ì‹¤í–‰
                    t0 = time.perf_counter()
                    cursor.execute(query, params or {})

                    # ê²°ê³¼ ì¡°íšŒ
                    results = cursor.fetchall()

                    # RealDictRowë¥¼ ì¼ë°˜ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
                    data = [dict(row) for row in results]
                    elapsed = (time.perf_counter() - t0) * 1000
                    first_keys = list(data[0].keys()) if data else []
                    logger.info(
                        "fetch_data(): ì¡°íšŒ ì™„ë£Œ | rows=%d, %.1fms, table=%s, window=%s, limit=%s, params_keys=%s, first_keys=%s",
                        len(data), elapsed, table_name, time_range, limit, list((params or {}).keys()), first_keys
                    )
                    return data

        except DatabaseError as e:
            # ì—°ê²° íšë“ ë‹¨ê³„ì—ì„œ ë°œìƒí•œ DatabaseErrorì— ì¿¼ë¦¬/íŒŒë¼ë¯¸í„°/ì—°ê²°ì •ë³´ë¥¼ ë³´ê°•
            error_msg = getattr(e, "message", "ë°ì´í„°ë² ì´ìŠ¤ ì˜¤ë¥˜")
            logger.error("fetch_data(): ì—°ê²° ì˜¤ë¥˜ | %s", error_msg)
            raise DatabaseError(
                error_msg,
                details={
                    "original": getattr(e, "details", None),
                    "query": (query or "")[:1000],
                    "params": params,
                },
                query=query,
                connection_info=self.get_connection_info(),
            ) from e
        except psycopg2.Error as e:
            error_msg = f"ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {e}"
            logger.error(error_msg)
            raise DatabaseError(
                error_msg,
                details={
                    "query": query[:200],
                    "params": params,
                    "error_code": e.pgcode if hasattr(e, "pgcode") else None,
                },
                query=query,
                connection_info=self.get_connection_info(),
            ) from e

    def execute_query(self, query: str, params: Optional[Dict[str, Any]] = None, commit: bool = True) -> int:
        """
        ì¿¼ë¦¬ ì‹¤í–‰ (INSERT, UPDATE, DELETE)

        ê¸°ì¡´ main.pyì˜ ì¿¼ë¦¬ ì‹¤í–‰ ë¡œì§ì„ ëª¨ë“ˆí™”í•œ ê²ƒì…ë‹ˆë‹¤.
        """
        logger.debug(
            "execute_query(): í˜¸ì¶œ | query_len=%d, preview=%s, commit=%s, params_keys=%s",
            len(query or ""), (query or "")[:180].replace("\n", " "), commit, list((params or {}).keys())
        )

        if not self._is_connected:
            self.connect()

        try:
            with self.get_connection() as conn:
                with conn.cursor() as cursor:
                    # ì¿¼ë¦¬ ì‹¤í–‰
                    t0 = time.perf_counter()
                    cursor.execute(query, params or {})

                    # ì˜í–¥ë°›ì€ í–‰ ìˆ˜
                    rowcount = cursor.rowcount

                    # íŠ¸ëœì­ì…˜ ì²˜ë¦¬
                    if commit:
                        conn.commit()
                        logger.debug("íŠ¸ëœì­ì…˜ ì»¤ë°‹ ì™„ë£Œ")

                    elapsed = (time.perf_counter() - t0) * 1000
                    logger.info("execute_query(): ì™„ë£Œ | affected=%d, %.1fms", rowcount, elapsed)
                    return rowcount

        except DatabaseError as e:
            # ì—°ê²° íšë“ ë‹¨ê³„ì—ì„œ ë°œìƒí•œ DatabaseErrorì— ì¿¼ë¦¬/íŒŒë¼ë¯¸í„°/ì—°ê²°ì •ë³´ë¥¼ ë³´ê°•
            error_msg = getattr(e, "message", "ë°ì´í„°ë² ì´ìŠ¤ ì˜¤ë¥˜")
            logger.error("execute_query(): ì—°ê²° ì˜¤ë¥˜ | %s", error_msg)
            raise DatabaseError(
                error_msg,
                details={
                    "original": getattr(e, "details", None),
                    "query": (query or "")[:1000],
                    "params": params,
                },
                query=query,
                connection_info=self.get_connection_info(),
            ) from e
        except psycopg2.Error as e:
            error_msg = f"ì¿¼ë¦¬ ì‹¤í–‰ ì‹¤íŒ¨: {e}"
            logger.error(error_msg)
            raise DatabaseError(
                error_msg,
                details={
                    "query": query[:200],
                    "params": params,
                    "error_code": e.pgcode if hasattr(e, "pgcode") else None,
                },
                query=query,
                connection_info=self.get_connection_info(),
            ) from e

    def fetch_peg_data(
        self,
        table_name: str,
        columns: Dict[str, str],
        time_range: Tuple[datetime, datetime],
        filters: Optional[Dict[str, Any]] = None,
        limit: Optional[int] = None,
    ) -> List[Dict[str, Any]]:
        """
        PEG ë°ì´í„° ì „ìš© ì¡°íšŒ ë©”ì„œë“œ (ê¸°ì¡´ main.py ë¡œì§ ê¸°ë°˜)

        Args:
            table_name (str): í…Œì´ë¸”ëª…
            columns (Dict[str, str]): ì»¬ëŸ¼ ë§¤í•‘ (time, peg_name, value, ne, cellid, host)
            time_range (Tuple[datetime, datetime]): ì‹œê°„ ë²”ìœ„
            filters (Optional[Dict[str, Any]]): ì¶”ê°€ í•„í„° ì¡°ê±´
            limit (Optional[int]): ê²°ê³¼ ê°œìˆ˜ ì œí•œ

        Returns:
            List[Dict[str, Any]]: PEG ë°ì´í„° ëª©ë¡
        """
        logger.info("fetch_peg_data(): í˜¸ì¶œ | table=%s, time_range=%s, filters_keys=%s",
                    table_name, time_range, list((filters or {}).keys()))
        # ì»¨í…ìŠ¤íŠ¸ ìš”ì•½ ë¡œê·¸
        try:
            logger.info(
                "fetch_peg_data(): ì»¨í…ìŠ¤íŠ¸ | table=%s | start=%s | end=%s | columns_keys=%s | filters=%s | limit=%s",
                table_name,
                time_range[0] if time_range else None,
                time_range[1] if time_range else None,
                list((columns or {}).keys()),
                (filters or {}),
                limit,
            )
        except Exception:
            logger.debug("fetch_peg_data(): ì»¨í…ìŠ¤íŠ¸ ë¡œê¹… ìŠ¤í‚µ")
        # Columns ë§¤í•‘ ë””ë²„ê·¸ ë¡œê·¸ (í‚¤/ê°’ê³¼ JSONB ê°ì§€ ê²°ê³¼ ì¶œë ¥)
        try:
            logger.debug(
                "fetch_peg_data(): columns keys=%s, values=%s",
                list((columns or {}).keys()), list((columns or {}).values()),
            )
        except Exception:
            logger.debug("fetch_peg_data(): columns ë¡œê¹… ì‹¤íŒ¨ (ë¹„ì •í˜• ì…ë ¥)")

        # JSONB ê¸°ë°˜ ìŠ¤í‚¤ë§ˆ ì—¬ë¶€ íŒë³„ (values/family_name ì¡´ì¬ ì‹œ)
        json_mode = (
            ('values' in (columns or {}))
            or ('family_name' in (columns or {}))
            or ('values' in list((columns or {}).values()))
            or ('family_name' in list((columns or {}).values()))
        )
        logger.debug("fetch_peg_data(): JSONB ê°ì§€ ê²°ê³¼ | json_mode=%s", json_mode)

        # WHERE ì¡°ê±´ êµ¬ì„± ê³µí†µ
        conditions: List[str] = []
        params: Dict[str, Any] = {}
        start_time, end_time = time_range

        if json_mode:
            time_col = columns.get('time', 'datetime')
            values_col = columns.get('values', 'values')
            family_col = columns.get('family_name', 'family_id')
            ne_col = columns.get('ne') or columns.get('ne_key') or 'ne_key'
            swname_col = columns.get('swname', 'swname')
            relver_col = columns.get('rel_ver', 'rel_ver')
            # ì°¨ì›(alias) ë§¤í•‘: JSONB index_name â†’ í•„í„° í‚¤
            dimension_alias_map = {
                'cellid': 'CellIdentity',
                'qci': 'QCI',
                'bpu_id': 'BPU_ID',
            }
            logger.debug(
                "fetch_peg_data(): JSONB ëª¨ë“œ | cols={time:%s,family:%s,values:%s,ne:%s,swname:%s,rel_ver:%s} | dims=%s",
                time_col, family_col, values_col, ne_col, swname_col, relver_col, dimension_alias_map
            )

            # ë‘ ë‹¨ê³„ í™•ì¥:
            # 1) ìµœìƒìœ„ ì¸ë±ìŠ¤/í‚¤ë¥¼ í¼ì¹¨ (idx)
            # 2) ê°ì²´ë©´ ë‚´ë¶€ PEGë¥¼, ìŠ¤ì¹¼ë¼ì´ë©´ (idx.key, idx.val)ë¡œ ì¹˜í™˜í•´ metricìœ¼ë¡œ í¼ì¹¨
            #    peg_nameì€ ê°ì²´ì¼ ë•Œ index_name í¬í•¨ í˜•ì‹: 'DimensionName:value,metric.key'
            peg_name_expr = (
                "(CASE WHEN jsonb_typeof(idx.val) = 'object' THEN "
                # index_name ì¶”ì¶œ ë° í¬í•¨ (ìš”êµ¬ì‚¬í•­ 3: index_name ì •ë³´ ë³´ì¡´)
                "COALESCE(jsonb_extract_path_text(idx.val, 'index_name'), 'Dim') "
                "|| ':' || idx.key || ',' || metric.key "
                "ELSE metric.key END) AS peg_name"
            )

            select_parts: List[str] = [
                f"t.{time_col} AS timestamp",
                f"t.{family_col} AS family_name",
                peg_name_expr,
                # ì•ˆì „ ìºìŠ¤íŒ…: ìœ íš¨í•œ ìˆ«ì íŒ¨í„´ì´ë©° ê¸¸ì´ê°€ ê³¼ë„í•˜ì§€ ì•Šì„ ë•Œë§Œ double precision ìºìŠ¤íŒ…
                "CASE WHEN (cv.clean_val ~ '^[+-]?(?:\\\d+(?:\\.\\\d+)?|\\.\\\d+)(?:[eE][+-]?\\\d+)?$' AND length(cv.clean_val) <= 40) "
                "THEN cv.clean_val::double precision ELSE NULL END AS value",
            ]

            # ì„ íƒì  ì»¬ëŸ¼ë“¤ ì¶”ê°€ (ì¡´ì¬ ì‹œ)
            if ne_col:
                select_parts.append(f"t.{ne_col} AS ne")
            if swname_col:
                select_parts.append(f"t.{swname_col} AS swname")
            if relver_col:
                select_parts.append(f"t.{relver_col} AS rel_ver")

            query = (
                f"SELECT {', '.join(select_parts)} FROM {table_name} t "
                f"CROSS JOIN LATERAL jsonb_each(t.{values_col}) AS idx(key, val) "
                f"CROSS JOIN LATERAL jsonb_each_text("
                f"CASE WHEN jsonb_typeof(idx.val) = 'object' THEN idx.val ELSE jsonb_build_object(idx.key, idx.val) END"
                f") AS metric(key, value) "
                f"CROSS JOIN LATERAL ("
                f"SELECT NULLIF(regexp_replace(metric.value, '[^0-9\\.\\-eE]', '', 'g'),'') AS clean_val"
                f") AS cv"
            )
            logger.debug("fetch_peg_data(): SELECT êµ¬ì„± ì™„ë£Œ | select_parts=%s", select_parts)

            # ì‹œê°„ ì¡°ê±´ (ë³„ì¹­ t.)
            conditions.append(f"t.{time_col} BETWEEN %(start_time)s AND %(end_time)s")
            params['start_time'] = start_time
            params['end_time'] = end_time

            # ì¶”ê°€ í•„í„°
            if filters:
                index_name_expr = f"jsonb_extract_path_text(t.{values_col}, 'index_name')"

                # 1) ì°¨ì› í•„í„°(cellid/qci/bpu_id ë“±):
                #    ì›ì¹™ - ì–´ë–¤ ì°¨ì› í•„í„°ê°€ ì™€ë„ í•´ë‹¹ index_nameì—ëŠ” key ì¡°ê±´ì„ ì ìš©í•˜ê³ ,
                #           ê·¸ ì™¸ index_nameì€ í•­ìƒ í¬í•¨(ë¬´ì¡°ê±´ íŒŒì‹±)ë˜ë„ë¡ OR ê·¸ë£¹ êµ¬ì„±
                dim_filters = {k: v for k, v in filters.items() if k in dimension_alias_map and v is not None}
                if dim_filters:
                    logger.debug("fetch_peg_data(): ì°¨ì› í•„í„° ê°ì§€ | %s", {k: (v if isinstance(v, (list,tuple,set)) else [v]) for k,v in dim_filters.items()})
                    per_dim_clauses: List[str] = []
                    dim_in_names: List[str] = []
                    for dim_key, dim_value in dim_filters.items():
                        iname = dimension_alias_map[dim_key]
                        dim_in_names.append(iname)
                        pname_iname = f"{dim_key}_index_name"
                        params[pname_iname] = iname
                        if isinstance(dim_value, (list, tuple, set)) and dim_value:
                            placeholders = ",".join([f"%({dim_key}_{i})s" for i, _ in enumerate(dim_value)])
                            for i, v in enumerate(dim_value):
                                params[f"{dim_key}_{i}"] = str(v)
                            per_dim_clauses.append(f"( {index_name_expr} = %({pname_iname})s AND idx.key IN ({placeholders}) )")
                        else:
                            params[dim_key] = str(dim_value)
                            per_dim_clauses.append(f"( {index_name_expr} = %({pname_iname})s AND idx.key = %({dim_key})s )")

                    # others clause: index_nameì´ ì–´ë–¤ ì§€ì • inameì—ë„ ì†í•˜ì§€ ì•Šê±°ë‚˜ NULLì¸ ê²½ìš° ëª¨ë‘ í¬í•¨
                    other_names_placeholders = ",".join([f"%(dim_iname_{i})s" for i in range(len(dim_in_names))])
                    for i, nm in enumerate(dim_in_names):
                        params[f"dim_iname_{i}"] = nm
                    others_clause = f"( {index_name_expr} IS NULL OR {index_name_expr} NOT IN ({other_names_placeholders}) )"

                    clause_preview = " OR ".join(per_dim_clauses + ["..."])
                    logger.debug("fetch_peg_data(): ì°¨ì› í•„í„° WHERE êµ¬ì„± | preview=%s", clause_preview[:160])
                    conditions.append("( " + " OR ".join(per_dim_clauses + [others_clause]) + " )")

                # 2) í…Œì´ë¸” ì»¬ëŸ¼ ê¸°ë°˜ í•„í„° (columns ë§¤í•‘ëœ í‚¤ë§Œ í—ˆìš©, t. ì ‘ë‘ì‚¬ ì ìš©)
                for key, value in filters.items():
                    if value is None:
                        continue
                    col_name = columns.get(key)
                    if not col_name:
                        continue
                    qualified = f"t.{col_name}"
                    if isinstance(value, (list, tuple, set)) and value:
                        placeholders = ",".join([f"%({key}_{i})s" for i, _ in enumerate(value)])
                        conditions.append(f"{qualified} IN ({placeholders})")
                        for i, v in enumerate(value):
                            params[f"{key}_{i}"] = v
                    else:
                        conditions.append(f"{qualified} = %({key})s")
                        params[key] = value

            # ë©”íƒ€/ë¹„ìˆ˜ì¹˜ ê°’ ì œì™¸ ì¡°ê±´ë§Œ ìœ ì§€ (numeric í•„í„°ëŠ” SELECTì˜ CASEë¡œ ì²˜ë¦¬)
            conditions.append("metric.key <> 'index_name'")

            if conditions:
                logger.debug("fetch_peg_data(): WHERE êµ¬ì„± | %dê°œ ì¡°ê±´", len(conditions))
                query += " WHERE " + " AND ".join(conditions)

            query += f" ORDER BY t.{time_col}"
            if limit and limit > 0:
                query += f" LIMIT {limit}"

            logger.info(
                "fetch_peg_data(): JSONB 2ë‹¨ê³„ í™•ì¥ ëª¨ë“œ(Aì•ˆ) ì¿¼ë¦¬ êµ¬ì„± ì™„ë£Œ | sql_len=%d, params_keys=%s",
                len(query), list(params.keys())
            )
            logger.debug("fetch_peg_data(): SQL preview=%s", query[:5000].replace('\n',' '))
            # ì£¼ì˜: ì´ë¯¸ WHERE/ORDER BY/LIMITê°€ í¬í•¨ë˜ì–´ ìˆìœ¼ë¯€ë¡œ fetch_dataì— time_range/limit ì „ë‹¬í•˜ì§€ ì•ŠìŒ
            
            # ğŸ” ë””ë²„ê¹…: ì¡°íšŒëœ ë°ì´í„°ì˜ value ì»¬ëŸ¼ í†µê³„
            result_data = self.fetch_data(query, params)
            if result_data:
                logger.debug(
                    "fetch_peg_data() ê²°ê³¼: ì´=%dí–‰, ìƒ˜í”Œ ë°ì´í„°=%s",
                    len(result_data),
                    result_data[:3] if len(result_data) > 0 else []
                )
                
                # value ì»¬ëŸ¼ í†µê³„ (null, 0 ê°œìˆ˜)
                value_list = [row.get('value') for row in result_data]
                null_count = sum(1 for v in value_list if v is None)
                zero_count = sum(1 for v in value_list if v == 0 or v == 0.0)
                non_zero_count = sum(1 for v in value_list if v is not None and v != 0 and v != 0.0)
                
                logger.debug(
                    "fetch_peg_data() value ì»¬ëŸ¼ í†µê³„: null=%dê°œ, 0=%dê°œ, 0ì´_ì•„ë‹Œ_ê°’=%dê°œ, ìƒ˜í”Œ_value=%s",
                    null_count, zero_count, non_zero_count,
                    [v for v in value_list[:10] if v is not None]
                )
            else:
                logger.warning("fetch_peg_data() ê²°ê³¼ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤!")
            
            return result_data

        # ë¹„-JSONB ë ˆê±°ì‹œ ìŠ¤í‚¤ë§ˆ: ê¸°ì¡´ ê²½ë¡œ ìœ ì§€
        select_columns = [
            f"{columns['time']} as timestamp",
            f"{columns['peg_name']} as peg_name",
            f"{columns['value']} as value",
        ]

        # ì„ íƒì  ì»¬ëŸ¼ë“¤ ì¶”ê°€
        optional_columns = ["ne", "cellid", "swname"]
        for col_key in optional_columns:
            if col_key in columns and columns[col_key]:
                select_columns.append(f"{columns[col_key]} as {col_key}")

        # ì¿¼ë¦¬ êµ¬ì„±
        query = f"SELECT {', '.join(select_columns)} FROM {table_name}"

        # ì‹œê°„ ë²”ìœ„ ì¡°ê±´
        conditions.append(f"{columns['time']} BETWEEN %(start_time)s AND %(end_time)s")
        params["start_time"] = start_time
        params["end_time"] = end_time

        # ì¶”ê°€ í•„í„° ì¡°ê±´ (ì»¬ëŸ¼ ë§¤í•‘ëœ í‚¤ë§Œ)
        if filters:
            for key, value in filters.items():
                if key in columns and value is not None:
                    col_name = columns[key]
                    if isinstance(value, (list, tuple, set)) and value:
                        placeholders = ",".join([f"%({key}_{i})s" for i, _ in enumerate(value)])
                        conditions.append(f"{col_name} IN ({placeholders})")
                        for i, v in enumerate(value):
                            params[f"{key}_{i}"] = v
                    else:
                        conditions.append(f"{col_name} = %({key})s")
                        params[key] = value

        # WHERE ì ˆ ì¶”ê°€
        if conditions:
            query += " WHERE " + " AND ".join(conditions)

        # ì •ë ¬ (ì‹œê°„ìˆœ)
        query += f" ORDER BY {columns['time']}"

        # LIMIT ì¶”ê°€
        if limit and limit > 0:
            query += f" LIMIT {limit}"

        logger.debug("fetch_peg_data(): (ë ˆê±°ì‹œ) SQL preview=%s", query[:5000].replace('\n',' '))
        # ì£¼ì˜: ì´ë¯¸ WHERE/ORDER BY/LIMITê°€ í¬í•¨ë˜ì–´ ìˆìœ¼ë¯€ë¡œ fetch_dataì— time_range/limit ì „ë‹¬í•˜ì§€ ì•ŠìŒ
        return self.fetch_data(query, params)

    def get_table_info(self, table_name: str) -> Dict[str, Any]:
        """
        í…Œì´ë¸” ì •ë³´ ì¡°íšŒ

        Args:
            table_name (str): í…Œì´ë¸”ëª…

        Returns:
            Dict[str, Any]: í…Œì´ë¸” ì •ë³´ (ì»¬ëŸ¼, ì¸ë±ìŠ¤ ë“±)
        """
        logger.debug("get_table_info() í˜¸ì¶œ: table=%s", table_name)

        # ì»¬ëŸ¼ ì •ë³´ ì¡°íšŒ
        column_query = """
        SELECT column_name, data_type, is_nullable, column_default
        FROM information_schema.columns 
        WHERE table_name = %(table_name)s
        ORDER BY ordinal_position
        """

        columns = self.fetch_data(column_query, {"table_name": table_name})

        # ì¸ë±ìŠ¤ ì •ë³´ ì¡°íšŒ
        index_query = """
        SELECT indexname, indexdef
        FROM pg_indexes 
        WHERE tablename = %(table_name)s
        """

        indexes = self.fetch_data(index_query, {"table_name": table_name})

        return {
            "table_name": table_name,
            "columns": columns,
            "indexes": indexes,
            "column_count": len(columns),
            "index_count": len(indexes),
        }

    def get_connection_info(self) -> Dict[str, Any]:
        """ì—°ê²° ì •ë³´ ë°˜í™˜ (ë¯¼ê° ì •ë³´ ì œì™¸)"""
        return {
            "host": self.config["host"],
            "port": self.config["port"],
            "database": self.config["database"],
            "user": self.config["user"],
            "pool_size": self.config["pool_size"],
            "is_connected": self._is_connected,
            "pool_status": "active" if self._pool else "inactive",
        }

    def __enter__(self):
        """ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì € ì§„ì…"""
        self.connect()
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        """ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì € ì¢…ë£Œ"""
        self.disconnect()

        # ì˜ˆì™¸ ë°œìƒ ì‹œ ë¡œê·¸ ê¸°ë¡
        if exc_type:
            logger.error("ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €ì—ì„œ ì˜ˆì™¸ ë°œìƒ: %s", exc_val)

        return False  # ì˜ˆì™¸ë¥¼ ë‹¤ì‹œ ë°œìƒì‹œí‚´
