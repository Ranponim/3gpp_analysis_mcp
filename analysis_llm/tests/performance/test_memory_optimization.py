"""
Memory Usage Analysis and Optimization Tests

ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ ë¶„ì„í•˜ê³  ìµœì í™”í•©ë‹ˆë‹¤.
"""

import gc
import os
import sys
import time

import numpy as np
import pandas as pd
import pytest

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python pathì— ì¶”ê°€
project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))
sys.path.insert(0, project_root)

from services import AnalysisService, LLMAnalysisService, PEGCalculator, PEGProcessingService
from utils import DataProcessor, TimeRangeParser


class TestMemoryOptimization:
    """ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì í™” í…ŒìŠ¤íŠ¸"""
    
    def test_analysis_service_memory_profiling(
        self,
        performance_analysis_request,
        mock_performance_database_repository,
        mock_performance_llm_repository,
        memory_tracker,
        performance_logger
    ):
        """AnalysisService ë©”ëª¨ë¦¬ í”„ë¡œíŒŒì¼ë§"""
        # ì´ˆê¸° ë©”ëª¨ë¦¬ ìƒíƒœ
        initial_memory = memory_tracker.get_memory_usage()
        performance_logger.info(f"ì´ˆê¸° ë©”ëª¨ë¦¬: {initial_memory['current_mb']:.2f}MB")
        
        # ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ ì‹¤í–‰
        gc.collect()
        
        # ì„œë¹„ìŠ¤ êµ¬ì„±
        time_parser = TimeRangeParser()
        data_processor = DataProcessor()
        peg_calculator = PEGCalculator()
        
        memory_tracker.update_peak()
        setup_memory = memory_tracker.get_memory_usage()
        performance_logger.info(f"ìœ í‹¸ë¦¬í‹° ì„¤ì • í›„ ë©”ëª¨ë¦¬: {setup_memory['current_mb']:.2f}MB")
        
        peg_processing_service = PEGProcessingService(
            database_repository=mock_performance_database_repository,
            peg_calculator=peg_calculator
        )
        
        memory_tracker.update_peak()
        peg_service_memory = memory_tracker.get_memory_usage()
        performance_logger.info(f"PEG ì„œë¹„ìŠ¤ ì„¤ì • í›„ ë©”ëª¨ë¦¬: {peg_service_memory['current_mb']:.2f}MB")
        
        llm_analysis_service = LLMAnalysisService(
            llm_repository=mock_performance_llm_repository
        )
        
        memory_tracker.update_peak()
        llm_service_memory = memory_tracker.get_memory_usage()
        performance_logger.info(f"LLM ì„œë¹„ìŠ¤ ì„¤ì • í›„ ë©”ëª¨ë¦¬: {llm_service_memory['current_mb']:.2f}MB")
        
        analysis_service = AnalysisService(
            database_repository=mock_performance_database_repository,
            peg_processing_service=peg_processing_service,
            llm_analysis_service=llm_analysis_service,
            time_parser=time_parser,
            data_processor=data_processor
        )
        
        memory_tracker.update_peak()
        full_setup_memory = memory_tracker.get_memory_usage()
        performance_logger.info(f"ì „ì²´ ì„œë¹„ìŠ¤ ì„¤ì • í›„ ë©”ëª¨ë¦¬: {full_setup_memory['current_mb']:.2f}MB")
        
        # ë¶„ì„ ì‹¤í–‰
        result = analysis_service.perform_analysis(performance_analysis_request)
        
        memory_tracker.update_peak()
        analysis_memory = memory_tracker.get_memory_usage()
        performance_logger.info(f"ë¶„ì„ ì‹¤í–‰ í›„ ë©”ëª¨ë¦¬: {analysis_memory['current_mb']:.2f}MB")
        
        # ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ í›„ ë©”ëª¨ë¦¬ í™•ì¸
        gc.collect()
        final_memory = memory_tracker.get_memory_usage()
        
        # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë¶„ì„
        setup_increase = full_setup_memory['current_mb'] - initial_memory['current_mb']
        analysis_increase = analysis_memory['current_mb'] - full_setup_memory['current_mb']
        total_increase = final_memory['current_mb'] - initial_memory['current_mb']
        
        performance_logger.info("=== ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë¶„ì„ ===")
        performance_logger.info(f"ì„œë¹„ìŠ¤ ì„¤ì • ì¦ê°€: {setup_increase:.2f}MB")
        performance_logger.info(f"ë¶„ì„ ì‹¤í–‰ ì¦ê°€: {analysis_increase:.2f}MB")
        performance_logger.info(f"ì´ ë©”ëª¨ë¦¬ ì¦ê°€: {total_increase:.2f}MB")
        performance_logger.info(f"í”¼í¬ ë©”ëª¨ë¦¬: {final_memory['peak_mb']:.2f}MB")
        
        # ê²°ê³¼ ê²€ì¦
        assert isinstance(result, dict)
        assert result.get('status') in ['success', 'completed']
        
        # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê¸°ì¤€ ê²€ì¦
        assert total_increase < 100, f"ì´ ë©”ëª¨ë¦¬ ì¦ê°€ëŸ‰ì´ ë„ˆë¬´ í½ë‹ˆë‹¤: {total_increase:.2f}MB"
        assert final_memory['peak_mb'] < 300, f"í”¼í¬ ë©”ëª¨ë¦¬ê°€ ë„ˆë¬´ ë†’ìŠµë‹ˆë‹¤: {final_memory['peak_mb']:.2f}MB"
        
        performance_logger.info("âœ… AnalysisService ë©”ëª¨ë¦¬ í”„ë¡œíŒŒì¼ë§ ì™„ë£Œ")
    
    def test_dataframe_chunked_processing_optimization(
        self,
        memory_tracker,
        performance_logger
    ):
        """DataFrame ì²­í¬ ì²˜ë¦¬ ë©”ëª¨ë¦¬ ìµœì í™”"""
        # ëŒ€ìš©ëŸ‰ DataFrame ìƒì„± (10,000ê°œ ë ˆì½”ë“œ)
        large_size = 10000
        
        performance_logger.info("=== DataFrame ì²­í¬ ì²˜ë¦¬ ìµœì í™” ===")
        performance_logger.info(f"í…ŒìŠ¤íŠ¸ ë°ì´í„° í¬ê¸°: {large_size:,}ê°œ ë ˆì½”ë“œ")
        
        # ì´ˆê¸° ë©”ëª¨ë¦¬ ìƒíƒœ
        memory_tracker.get_memory_usage()
        gc.collect()
        
        # ëŒ€ìš©ëŸ‰ DataFrame ìƒì„±
        large_df = pd.DataFrame({
            'datetime': pd.date_range('2025-01-01', periods=large_size, freq='1min'),
            'peg_name': np.random.choice(['preamble_count', 'response_count', 'success_count'], large_size),
            'value': np.random.normal(1000, 200, large_size),
            'ne': np.random.choice([f'nvgnb#{10000+i}' for i in range(100)], large_size),
            'cellid': np.random.choice([f'cell_{i:03d}' for i in range(200)], large_size)
        })
        
        memory_tracker.update_peak()
        creation_memory = memory_tracker.get_memory_usage()
        df_memory_mb = large_df.memory_usage(deep=True).sum() / 1024 / 1024
        
        performance_logger.info(f"ëŒ€ìš©ëŸ‰ DataFrame ìƒì„± í›„ ë©”ëª¨ë¦¬: {creation_memory['current_mb']:.2f}MB")
        performance_logger.info(f"DataFrame ìì²´ ë©”ëª¨ë¦¬: {df_memory_mb:.2f}MB")
        
        # 1. ì „ì²´ ë°ì´í„° í•œë²ˆì— ì²˜ë¦¬
        start_time = time.time()
        full_result = large_df.groupby(['peg_name', 'ne']).agg({
            'value': ['mean', 'sum', 'count', 'std']
        }).round(2)
        full_time = time.time() - start_time
        
        memory_tracker.update_peak()
        full_processing_memory = memory_tracker.get_memory_usage()
        
        # 2. ì²­í¬ ë‹¨ìœ„ ì²˜ë¦¬ (ë©”ëª¨ë¦¬ íš¨ìœ¨ì )
        chunk_size = 1000
        chunk_results = []
        
        start_time = time.time()
        for i in range(0, len(large_df), chunk_size):
            chunk = large_df.iloc[i:i+chunk_size]
            
            # ì²­í¬ë³„ ì§‘ê³„
            chunk_agg = chunk.groupby(['peg_name', 'ne']).agg({
                'value': ['sum', 'count']
            })
            chunk_results.append(chunk_agg)
            
            # ì¤‘ê°„ ë©”ëª¨ë¦¬ ì •ë¦¬
            del chunk
        
        # ì²­í¬ ê²°ê³¼ ë³‘í•© ë° ìµœì¢… ê³„ì‚°
        if chunk_results:
            combined = pd.concat(chunk_results).groupby(['peg_name', 'ne']).agg({
                ('value', 'sum'): 'sum',
                ('value', 'count'): 'sum'
            })
            combined[('value', 'mean')] = combined[('value', 'sum')] / combined[('value', 'count')]
        
        chunk_time = time.time() - start_time
        
        memory_tracker.update_peak()
        chunk_processing_memory = memory_tracker.get_memory_usage()
        
        # ë©”ëª¨ë¦¬ ì •ë¦¬
        del large_df, full_result, chunk_results
        gc.collect()
        
        final_memory = memory_tracker.get_memory_usage()
        
        # ì„±ëŠ¥ ë¹„êµ ë¶„ì„
        performance_logger.info("ğŸ“Š ì²˜ë¦¬ ë°©ì‹ë³„ ì„±ëŠ¥ ë¹„êµ:")
        performance_logger.info(f"   ì „ì²´ ì²˜ë¦¬ ì‹œê°„: {full_time*1000:.2f}ms")
        performance_logger.info(f"   ì²­í¬ ì²˜ë¦¬ ì‹œê°„: {chunk_time*1000:.2f}ms")
        performance_logger.info(f"   ì²­í¬ í¬ê¸°: {chunk_size:,}ê°œ")
        performance_logger.info(f"   ì²­í¬ ìˆ˜: {len(range(0, large_size, chunk_size))}ê°œ")
        
        # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë¹„êµ
        full_memory_increase = full_processing_memory['current_mb'] - creation_memory['current_mb']
        chunk_memory_increase = chunk_processing_memory['current_mb'] - creation_memory['current_mb']
        memory_savings = full_memory_increase - chunk_memory_increase
        
        performance_logger.info("ğŸ“Š ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë¹„êµ:")
        performance_logger.info(f"   ì „ì²´ ì²˜ë¦¬ ë©”ëª¨ë¦¬ ì¦ê°€: {full_memory_increase:.2f}MB")
        performance_logger.info(f"   ì²­í¬ ì²˜ë¦¬ ë©”ëª¨ë¦¬ ì¦ê°€: {chunk_memory_increase:.2f}MB")
        performance_logger.info(f"   ë©”ëª¨ë¦¬ ì ˆì•½: {memory_savings:.2f}MB")
        performance_logger.info(f"   í”¼í¬ ë©”ëª¨ë¦¬: {final_memory['peak_mb']:.2f}MB")
        
        # ìµœì í™” íš¨ê³¼ ê²€ì¦
        if memory_savings > 0:
            savings_pct = (memory_savings / full_memory_increase) * 100 if full_memory_increase > 0 else 0
            performance_logger.info(f"ğŸš€ ì²­í¬ ì²˜ë¦¬ê°€ ë©”ëª¨ë¦¬ {savings_pct:.1f}% ì ˆì•½")
        
        # ì„±ëŠ¥ ê¸°ì¤€ ê²€ì¦
        assert chunk_time <= full_time * 2.0, "ì²­í¬ ì²˜ë¦¬ê°€ ë„ˆë¬´ ëŠë¦½ë‹ˆë‹¤"  # 2ë°° ì´ë‚´ í—ˆìš©
        assert final_memory['peak_mb'] < 500, f"í”¼í¬ ë©”ëª¨ë¦¬ê°€ ë„ˆë¬´ ë†’ìŠµë‹ˆë‹¤: {final_memory['peak_mb']:.2f}MB"
        
        performance_logger.info("âœ… DataFrame ì²­í¬ ì²˜ë¦¬ ìµœì í™” ì™„ë£Œ")
    
    def test_memory_leak_detection(
        self,
        performance_analysis_request,
        mock_performance_database_repository,
        mock_performance_llm_repository,
        memory_tracker,
        performance_logger
    ):
        """ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ê°ì§€ í…ŒìŠ¤íŠ¸"""
        performance_logger.info("=== ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ê°ì§€ í…ŒìŠ¤íŠ¸ ===")
        
        # ì´ˆê¸° ë©”ëª¨ë¦¬ ìƒíƒœ
        gc.collect()
        initial_memory = memory_tracker.get_memory_usage()
        performance_logger.info(f"ì´ˆê¸° ë©”ëª¨ë¦¬: {initial_memory['current_mb']:.2f}MB")
        
        # ë°˜ë³µì ì¸ ë¶„ì„ ì‹¤í–‰ (ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ í™•ì¸)
        memory_measurements = []
        num_iterations = 5
        
        for i in range(num_iterations):
            # ì„œë¹„ìŠ¤ êµ¬ì„± (ë§¤ë²ˆ ìƒˆë¡œ ìƒì„±)
            time_parser = TimeRangeParser()
            data_processor = DataProcessor()
            peg_calculator = PEGCalculator()
            
            peg_processing_service = PEGProcessingService(
                database_repository=mock_performance_database_repository,
                peg_calculator=peg_calculator
            )
            
            llm_analysis_service = LLMAnalysisService(
                llm_repository=mock_performance_llm_repository
            )
            
            analysis_service = AnalysisService(
                database_repository=mock_performance_database_repository,
                peg_processing_service=peg_processing_service,
                llm_analysis_service=llm_analysis_service,
                time_parser=time_parser,
                data_processor=data_processor
            )
            
            # ë¶„ì„ ì‹¤í–‰
            result = analysis_service.perform_analysis(performance_analysis_request)
            
            # ë©”ëª¨ë¦¬ ì¸¡ì •
            memory_tracker.update_peak()
            current_memory = memory_tracker.get_memory_usage()
            memory_measurements.append(current_memory['current_mb'])
            
            # ëª…ì‹œì  ì •ë¦¬
            del analysis_service, peg_processing_service, llm_analysis_service
            del time_parser, data_processor, peg_calculator, result
            
            # ê°€ë¹„ì§€ ì»¬ë ‰ì…˜
            gc.collect()
            
            performance_logger.info(f"ë°˜ë³µ {i+1}: {current_memory['current_mb']:.2f}MB")
        
        # ìµœì¢… ë©”ëª¨ë¦¬ ìƒíƒœ
        final_memory = memory_tracker.get_memory_usage()
        
        # ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ë¶„ì„
        memory_trend = []
        for i in range(1, len(memory_measurements)):
            trend = memory_measurements[i] - memory_measurements[i-1]
            memory_trend.append(trend)
        
        avg_memory_increase = sum(memory_trend) / len(memory_trend) if memory_trend else 0
        total_memory_increase = final_memory['current_mb'] - initial_memory['current_mb']
        
        performance_logger.info("ğŸ“Š ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ë¶„ì„:")
        performance_logger.info(f"   ë°˜ë³µ ì‹¤í–‰ ìˆ˜: {num_iterations}")
        performance_logger.info(f"   í‰ê·  ë°˜ë³µë‹¹ ë©”ëª¨ë¦¬ ì¦ê°€: {avg_memory_increase:.2f}MB")
        performance_logger.info(f"   ì´ ë©”ëª¨ë¦¬ ì¦ê°€: {total_memory_increase:.2f}MB")
        performance_logger.info(f"   ìµœì¢… ë©”ëª¨ë¦¬: {final_memory['current_mb']:.2f}MB")
        performance_logger.info(f"   í”¼í¬ ë©”ëª¨ë¦¬: {final_memory['peak_mb']:.2f}MB")
        
        # ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ê²€ì¦
        assert avg_memory_increase < 5, f"ë°˜ë³µë‹¹ ë©”ëª¨ë¦¬ ì¦ê°€ëŸ‰ì´ ë„ˆë¬´ í½ë‹ˆë‹¤: {avg_memory_increase:.2f}MB"
        assert total_memory_increase < 50, f"ì´ ë©”ëª¨ë¦¬ ì¦ê°€ëŸ‰ì´ ë„ˆë¬´ í½ë‹ˆë‹¤: {total_memory_increase:.2f}MB"
        
        # ë©”ëª¨ë¦¬ ì‚¬ìš© íŒ¨í„´ ë¶„ì„
        if avg_memory_increase < 1:
            performance_logger.info("ğŸš€ ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ì—†ìŒ - ìš°ìˆ˜í•œ ë©”ëª¨ë¦¬ ê´€ë¦¬")
        elif avg_memory_increase < 3:
            performance_logger.info("âœ… í—ˆìš© ê°€ëŠ¥í•œ ë©”ëª¨ë¦¬ ì¦ê°€ - ì–‘í˜¸í•œ ë©”ëª¨ë¦¬ ê´€ë¦¬")
        else:
            performance_logger.warning("âš ï¸ ë©”ëª¨ë¦¬ ì¦ê°€ ì£¼ì˜ - ìµœì í™” ê²€í†  í•„ìš”")
        
        performance_logger.info("âœ… ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ê°ì§€ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
    
    def test_large_dataset_memory_efficiency(
        self,
        memory_tracker,
        performance_logger
    ):
        """ëŒ€ìš©ëŸ‰ ë°ì´í„°ì…‹ ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± í…ŒìŠ¤íŠ¸"""
        performance_logger.info("=== ëŒ€ìš©ëŸ‰ ë°ì´í„°ì…‹ ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± í…ŒìŠ¤íŠ¸ ===")
        
        # ì´ˆê¸° ë©”ëª¨ë¦¬ ìƒíƒœ
        gc.collect()
        memory_tracker.get_memory_usage()
        
        # ë‹¤ì–‘í•œ í¬ê¸°ì˜ ë°ì´í„°ì…‹ìœ¼ë¡œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¸¡ì •
        dataset_sizes = [1000, 5000, 10000, 20000]
        memory_usage_by_size = {}
        
        for size in dataset_sizes:
            gc.collect()  # ì´ì „ í…ŒìŠ¤íŠ¸ ì •ë¦¬
            size_start_memory = memory_tracker.get_memory_usage()
            
            # ë°ì´í„°ì…‹ ìƒì„±
            test_df = pd.DataFrame({
                'datetime': pd.date_range('2025-01-01', periods=size, freq='1min'),
                'peg_name': np.random.choice(['preamble_count', 'response_count'], size),
                'value': np.random.normal(1000, 200, size),
                'ne': np.random.choice([f'nvgnb#{10000+i}' for i in range(50)], size),
                'cellid': np.random.choice([f'cell_{i:03d}' for i in range(100)], size)
            })
            
            memory_tracker.update_peak()
            
            # ë°ì´í„° íƒ€ì… ìµœì í™”
            optimized_df = test_df.copy()
            optimized_df['value'] = pd.to_numeric(optimized_df['value'], downcast='float')
            optimized_df['peg_name'] = optimized_df['peg_name'].astype('category')
            optimized_df['ne'] = optimized_df['ne'].astype('category')
            optimized_df['cellid'] = optimized_df['cellid'].astype('category')
            
            memory_tracker.update_peak()
            
            # ì§‘ê³„ ì—°ì‚° ì‹¤í–‰
            start_time = time.time()
            result = optimized_df.groupby(['peg_name', 'ne']).agg({
                'value': ['mean', 'count']
            })
            processing_time = time.time() - start_time
            
            memory_tracker.update_peak()
            size_end_memory = memory_tracker.get_memory_usage()
            
            # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê³„ì‚°
            original_df_memory = test_df.memory_usage(deep=True).sum() / 1024 / 1024
            optimized_df_memory = optimized_df.memory_usage(deep=True).sum() / 1024 / 1024
            memory_increase = size_end_memory['current_mb'] - size_start_memory['current_mb']
            
            memory_usage_by_size[size] = {
                'original_df_mb': original_df_memory,
                'optimized_df_mb': optimized_df_memory,
                'memory_savings_mb': original_df_memory - optimized_df_memory,
                'memory_savings_pct': ((original_df_memory - optimized_df_memory) / original_df_memory) * 100,
                'processing_time_ms': processing_time * 1000,
                'total_memory_increase_mb': memory_increase
            }
            
            performance_logger.info(f"ğŸ“Š í¬ê¸° {size:,}ê°œ ë ˆì½”ë“œ:")
            performance_logger.info(f"   ì›ë³¸ DataFrame: {original_df_memory:.2f}MB")
            performance_logger.info(f"   ìµœì í™” DataFrame: {optimized_df_memory:.2f}MB")
            performance_logger.info(f"   ë©”ëª¨ë¦¬ ì ˆì•½: {original_df_memory - optimized_df_memory:.2f}MB "
                                  f"({((original_df_memory - optimized_df_memory) / original_df_memory) * 100:.1f}%)")
            performance_logger.info(f"   ì²˜ë¦¬ ì‹œê°„: {processing_time*1000:.2f}ms")
            
            # ë©”ëª¨ë¦¬ ì •ë¦¬
            del test_df, optimized_df, result
            gc.collect()
        
        # í™•ì¥ì„± ë¶„ì„
        performance_logger.info("ğŸ“Š í™•ì¥ì„± ë¶„ì„:")
        for size, metrics in memory_usage_by_size.items():
            mb_per_1k_records = (metrics['optimized_df_mb'] / size) * 1000
            performance_logger.info(f"   {size:,}ê°œ: {mb_per_1k_records:.3f}MB/1kë ˆì½”ë“œ")
        
        # ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± ê²€ì¦
        for size, metrics in memory_usage_by_size.items():
            assert metrics['memory_savings_pct'] > 50, f"í¬ê¸° {size} ë©”ëª¨ë¦¬ ì ˆì•½ íš¨ê³¼ê°€ ë¯¸ë¯¸í•©ë‹ˆë‹¤"
            assert metrics['processing_time_ms'] < 1000, f"í¬ê¸° {size} ì²˜ë¦¬ê°€ ë„ˆë¬´ ëŠë¦½ë‹ˆë‹¤"
        
        performance_logger.info("âœ… ëŒ€ìš©ëŸ‰ ë°ì´í„°ì…‹ ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
    
    def test_garbage_collection_optimization(
        self,
        memory_tracker,
        performance_logger
    ):
        """ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ ìµœì í™” í…ŒìŠ¤íŠ¸"""
        performance_logger.info("=== ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ ìµœì í™” í…ŒìŠ¤íŠ¸ ===")
        
        # ì´ˆê¸° ìƒíƒœ
        gc.collect()
        initial_memory = memory_tracker.get_memory_usage()
        initial_gc_stats = gc.get_stats()
        
        performance_logger.info(f"ì´ˆê¸° ë©”ëª¨ë¦¬: {initial_memory['current_mb']:.2f}MB")
        performance_logger.info(f"ì´ˆê¸° GC í†µê³„: {initial_gc_stats}")
        
        # ë©”ëª¨ë¦¬ ì§‘ì•½ì  ì‘ì—… ì‹œë®¬ë ˆì´ì…˜
        memory_intensive_objects = []
        
        for i in range(10):
            # ëŒ€ìš©ëŸ‰ DataFrame ìƒì„± ë° ì²˜ë¦¬
            df = pd.DataFrame({
                'data': np.random.normal(0, 1, 5000),
                'category': np.random.choice(['A', 'B', 'C'], 5000)
            })
            
            # ì§‘ê³„ ì—°ì‚°
            result = df.groupby('category').agg({
                'data': ['mean', 'std', 'count']
            })
            
            memory_intensive_objects.append((df, result))
            
            # 5ë²ˆì§¸ë§ˆë‹¤ ì¤‘ê°„ ì •ë¦¬
            if (i + 1) % 5 == 0:
                memory_tracker.update_peak()
                mid_memory = memory_tracker.get_memory_usage()
                performance_logger.info(f"ì¤‘ê°„ {i+1}: {mid_memory['current_mb']:.2f}MB")
                
                # ëª…ì‹œì  ê°€ë¹„ì§€ ì»¬ë ‰ì…˜
                collected = gc.collect()
                performance_logger.info(f"GC ìˆ˜ì§‘ ê°ì²´: {collected}ê°œ")
        
        # ì‘ì—… ì™„ë£Œ í›„ ë©”ëª¨ë¦¬ ìƒíƒœ
        before_cleanup_memory = memory_tracker.get_memory_usage()
        
        # ëª…ì‹œì  ì •ë¦¬
        del memory_intensive_objects
        collected_objects = gc.collect()
        
        # ìµœì¢… ë©”ëª¨ë¦¬ ìƒíƒœ
        final_memory = memory_tracker.get_memory_usage()
        final_gc_stats = gc.get_stats()
        
        # ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ íš¨ê³¼ ë¶„ì„
        memory_before_gc = before_cleanup_memory['current_mb']
        memory_after_gc = final_memory['current_mb']
        gc_memory_freed = memory_before_gc - memory_after_gc
        
        performance_logger.info("ğŸ“Š ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ íš¨ê³¼:")
        performance_logger.info(f"   ì •ë¦¬ ì „ ë©”ëª¨ë¦¬: {memory_before_gc:.2f}MB")
        performance_logger.info(f"   ì •ë¦¬ í›„ ë©”ëª¨ë¦¬: {memory_after_gc:.2f}MB")
        performance_logger.info(f"   í•´ì œëœ ë©”ëª¨ë¦¬: {gc_memory_freed:.2f}MB")
        performance_logger.info(f"   ìˆ˜ì§‘ëœ ê°ì²´: {collected_objects}ê°œ")
        performance_logger.info(f"   í”¼í¬ ë©”ëª¨ë¦¬: {final_memory['peak_mb']:.2f}MB")
        
        # GC í†µê³„ ë¹„êµ
        performance_logger.info("ğŸ“Š GC í†µê³„ ë³€í™”:")
        for i, (initial, final) in enumerate(zip(initial_gc_stats, final_gc_stats)):
            performance_logger.info(f"   Gen {i}: {initial['collections']} â†’ {final['collections']} "
                                  f"(+{final['collections'] - initial['collections']})")
        
        # ë©”ëª¨ë¦¬ ê´€ë¦¬ íš¨ìœ¨ì„± ê²€ì¦
        assert gc_memory_freed >= 0, "ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ì´ ë©”ëª¨ë¦¬ë¥¼ í•´ì œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤"
        assert final_memory['peak_mb'] < 400, f"í”¼í¬ ë©”ëª¨ë¦¬ê°€ ë„ˆë¬´ ë†’ìŠµë‹ˆë‹¤: {final_memory['peak_mb']:.2f}MB"
        
        if gc_memory_freed > 10:
            performance_logger.info(f"ğŸš€ íš¨ê³¼ì ì¸ ë©”ëª¨ë¦¬ ì •ë¦¬: {gc_memory_freed:.2f}MB í•´ì œ")
        else:
            performance_logger.info("âœ… ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ ì´ë¯¸ íš¨ìœ¨ì ")
        
        performance_logger.info("âœ… ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ ìµœì í™” í…ŒìŠ¤íŠ¸ ì™„ë£Œ")


if __name__ == '__main__':
    pytest.main([__file__, '-v'])
