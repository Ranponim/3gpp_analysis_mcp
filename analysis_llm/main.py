"""
=====================================================================================
Cell ì„±ëŠ¥ LLM ë¶„ì„ê¸° (ì‹œê°„ë²”ìœ„ ì…ë ¥ + PostgreSQL ì§‘ê³„ + í†µí•© ë¶„ì„ + HTML/ë°±ì—”ë“œ POST)
=====================================================================================

## ğŸ“‹ ì‹œìŠ¤í…œ ê°œìš”
3GPP ì´ë™í†µì‹ ë§ì˜ Cell ì„±ëŠ¥ ë°ì´í„°ë¥¼ LLMì„ í™œìš©í•˜ì—¬ ì¢…í•© ë¶„ì„í•˜ëŠ” ì‹œìŠ¤í…œì…ë‹ˆë‹¤.
PostgreSQLì—ì„œ PEG(Performance Event Group) ë°ì´í„°ë¥¼ ì§‘ê³„í•˜ê³ , LLMì„ í†µí•´ ì „ë¬¸ê°€ ìˆ˜ì¤€ì˜ ë¶„ì„ ê²°ê³¼ë¥¼ ì œê³µí•©ë‹ˆë‹¤.

## ğŸ”„ ì£¼ìš” ì²˜ë¦¬ íë¦„
1. **ì‹œê°„ ë²”ìœ„ íŒŒì‹±**: ì‚¬ìš©ì ì…ë ¥ ì‹œê°„ ë²”ìœ„ë¥¼ íŒŒì‹±í•˜ì—¬ ì‹œì‘/ì¢…ë£Œ ì‹œì  ì¶”ì¶œ
2. **ë°ì´í„°ë² ì´ìŠ¤ ì¡°íšŒ**: PostgreSQLì—ì„œ ì§€ì •ëœ ê¸°ê°„ì˜ PEG ë°ì´í„° ì§‘ê³„
3. **íŒŒìƒ PEG ê³„ì‚°**: ì‚¬ìš©ì ì •ì˜ ìˆ˜ì‹ì„ ì´ìš©í•œ íŒŒìƒ ì§€í‘œ ê³„ì‚°
4. **ë°ì´í„° ì²˜ë¦¬**: N-1ê³¼ N ê¸°ê°„ ë°ì´í„° ë³‘í•© ë° ë³€í™”ìœ¨ ê³„ì‚°
5. **LLM ë¶„ì„**: ì „ë¬¸ê°€ ìˆ˜ì¤€ì˜ ì„±ëŠ¥ ë¶„ì„ ë° ê¶Œê³ ì‚¬í•­ ìƒì„±
6. **ê²°ê³¼ ì¶œë ¥**: HTML ë¦¬í¬íŠ¸ ìƒì„± ë° ë°±ì—”ë“œ APIë¡œ ê²°ê³¼ ì „ì†¡

## ğŸ¯ í•µì‹¬ ê¸°ëŠ¥
- **í†µí•© ë¶„ì„**: PEG ë‹¨ìœ„ê°€ ì•„ë‹Œ ì…€ ë‹¨ìœ„ ì „ì²´ ë°ì´í„°ë¥¼ í†µí•©í•˜ì—¬ ì¢…í•© ì„±ëŠ¥ í‰ê°€
- **íŠ¹ì • PEG ë¶„ì„**: preferenceë‚˜ selected_pegsë¡œ ì§€ì •ëœ PEGë§Œ ë³„ë„ ë¶„ì„
- **íŒŒìƒ PEG ì§€ì›**: peg_definitionsë¡œ (pegA/pegB)*100 ê°™ì€ ìˆ˜ì‹ ì •ì˜
- **í™˜ê²½ë³€ìˆ˜ ì§€ì›**: ëª¨ë“  ì„¤ì •ê°’ì„ í™˜ê²½ë³€ìˆ˜ë¡œ ê´€ë¦¬ ê°€ëŠ¥
- **í˜ì¼ì˜¤ë²„ ì§€ì›**: LLM API ë‹¤ì¤‘ ì—”ë“œí¬ì¸íŠ¸ ì§€ì›

## ğŸ“ ì‚¬ìš© ì˜ˆì‹œ (MCP tool í˜¸ì¶œ request ì˜ˆ):
{
  "n_minus_1": "2025-07-01_00:00~2025-07-01_23:59",
  "n": "2025-07-02_00:00~2025-07-02_23:59",
  "output_dir": "./analysis_output",
  "backend_url": "http://localhost:8000/api/analysis-result",
  "db": {"host": "127.0.0.1", "port": 5432, "user": "postgres", "password": "pass", "dbname": "netperf"},
  "table": "summary",
  "columns": {"time": "datetime", "peg_name": "peg_name", "value": "value"},
  "preference": "Random_access_preamble_count,Random_access_response",
  "peg_definitions": {
    "telus_RACH_Success": "Random_access_preamble_count/Random_access_response*100"
  }
}

## ğŸ”§ í™˜ê²½ë³€ìˆ˜ ì„¤ì •
ìì„¸í•œ í™˜ê²½ë³€ìˆ˜ ì„¤ì •ì€ ENV_SETTINGS.md íŒŒì¼ì„ ì°¸ì¡°í•˜ì„¸ìš”.
"""

from __future__ import annotations

import base64  # Base64 ì¸ì½”ë”© (ì´ë¯¸ì§€ ë°ì´í„° ì „ì†¡ìš©)
import datetime  # ë‚ ì§œ/ì‹œê°„ ì²˜ë¦¬ ë° íƒ€ì„ì¡´ ê´€ë¦¬
import io  # ë°”ì´íŠ¸ ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬ (ì´ë¯¸ì§€ ë°ì´í„° ë“±)
import json  # JSON ë°ì´í„° ì§ë ¬í™”/ì—­ì§ë ¬í™”
import logging  # ë¡œê¹… ì‹œìŠ¤í…œ
import math  # ìˆ˜í•™ ì—°ì‚° (í† í° ì¶”ì •, NaN ì²˜ë¦¬ ë“±)

# ===========================================
# í‘œì¤€ ë¼ì´ë¸ŒëŸ¬ë¦¬ imports
# ===========================================
import os  # í™˜ê²½ë³€ìˆ˜ ë° íŒŒì¼ ì‹œìŠ¤í…œ ì ‘ê·¼

# ===========================================
# Configuration Manager í†µí•©
# ===========================================
import sys
import time  # ì„±ëŠ¥ ì¸¡ì • ë° ì‹œê°„ ê´€ë ¨ ê¸°ëŠ¥

from .repositories import LLMClient, PostgreSQLRepository
from .services import AnalysisService, AnalysisServiceError
from .models.request import AnalysisRequest

# ===========================================
# ë¡œì»¬ ëª¨ë“ˆ imports
# ===========================================
from .utils import TimeParsingError, TimeRangeParser

# ì „ì—­ ì„¤ì • ì¸ìŠ¤í„´ìŠ¤ (ì§€ì—° ë¡œë”©)
_app_settings = None

def get_app_settings():
    """ì• í”Œë¦¬ì¼€ì´ì…˜ ì„¤ì • ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _app_settings
    if _app_settings is None:
        # í”„ë¡œì íŠ¸ ë£¨íŠ¸ì˜ config ëª¨ë“ˆ import
        project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
        config_path = os.path.join(project_root, 'config')
        if config_path not in sys.path:
            sys.path.insert(0, project_root)
        
        from config import get_settings
        _app_settings = get_settings()
    return _app_settings

# ===========================================
# ê¸€ë¡œë²Œ ì•ˆì „ ìƒìˆ˜ (í™˜ê²½ë³€ìˆ˜ë¡œ ì„¤ì • ê°€ëŠ¥)
# ===========================================
# LLM í”„ë¡¬í”„íŠ¸ ê´€ë ¨ ìƒí•œê°’ë“¤ - ë©”ëª¨ë¦¬ ë° ì„±ëŠ¥ ë³´í˜¸ë¥¼ ìœ„í•œ ì„¤ì •
def get_prompt_limits():
    """í”„ë¡¬í”„íŠ¸ ì œí•œê°’ë“¤ì„ ì„¤ì •ì—ì„œ ê°€ì ¸ì˜¤ê¸°"""
    return {
        'max_prompt_tokens': int(os.getenv('DEFAULT_MAX_PROMPT_TOKENS', '24000')),
        'max_prompt_chars': int(os.getenv('DEFAULT_MAX_PROMPT_CHARS', '80000')),
        'max_specific_rows': int(os.getenv('DEFAULT_SPECIFIC_MAX_ROWS', '500')),
        'max_raw_str': int(os.getenv('DEFAULT_MAX_RAW_STR', '4000')),
        'max_raw_array': int(os.getenv('DEFAULT_MAX_RAW_ARRAY', '100'))
    }

# í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•œ ì „ì—­ ë³€ìˆ˜ë“¤ (ì¶”í›„ ì œê±° ì˜ˆì •)
DEFAULT_MAX_PROMPT_TOKENS = int(os.getenv('DEFAULT_MAX_PROMPT_TOKENS', '24000'))
DEFAULT_MAX_PROMPT_CHARS = int(os.getenv('DEFAULT_MAX_PROMPT_CHARS', '80000'))
DEFAULT_SPECIFIC_MAX_ROWS = int(os.getenv('DEFAULT_SPECIFIC_MAX_ROWS', '500'))
DEFAULT_MAX_RAW_STR = int(os.getenv('DEFAULT_MAX_RAW_STR', '4000'))
DEFAULT_MAX_RAW_ARRAY = int(os.getenv('DEFAULT_MAX_RAW_ARRAY', '100'))





from fastmcp import FastMCP  # MCP ì„œë²„ í”„ë ˆì„ì›Œí¬
import requests  # HTTP í´ë¼ì´ì–¸íŠ¸
from requests.adapters import HTTPAdapter  # HTTP ì–´ëŒ‘í„° (ì¬ì‹œë„ ë¡œì§)
from urllib3.util.retry import Retry  # ì¬ì‹œë„ ì „ëµ
from typing import Any  # íƒ€ì… íŒíŠ¸ ì§€ì›

# ===========================================
# ë¡œê¹… ì‹œìŠ¤í…œ ì„¤ì • (í‘œì¤€í™”)
# ===========================================
# ì¤‘ì•™ ì„¤ì •(config.settings)ì˜ setup_loggingì„ ë‹¨ì¼ ì§„ì…ì ìœ¼ë¡œ ì‚¬ìš©
try:
    # get_app_settings()ëŠ” ë‚´ë¶€ì ìœ¼ë¡œ config.get_settings()ë¥¼ í˜¸ì¶œí•˜ë©°,
    # get_settings()ëŠ” settings.setup_logging()ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    _ = get_app_settings()
    logging.getLogger(__name__).info("ë¡œê¹… ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ (config.settings)")
except Exception as e:
    # ìµœì¢… í´ë°±: í•˜ë“œì½”ë”©ëœ ê¸°ë³¸ê°’
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )
    logging.getLogger(__name__).error("ë¡œê¹… ì„¤ì • ì‹¤íŒ¨, ê¸°ë³¸ê°’ ì‚¬ìš©: %s", e)


# ===========================================
# HTTP ì„¸ì…˜ ê´€ë¦¬
# ===========================================

def create_http_session() -> requests.Session:
    """
    ì¬ì‹œë„ ë¡œì§ê³¼ íƒ€ì„ì•„ì›ƒì´ ì„¤ì •ëœ requests ì„¸ì…˜ì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜
    
    LLM API í˜¸ì¶œì„ ìœ„í•œ ì•ˆì •ì ì¸ HTTP ì„¸ì…˜ì„ ìƒì„±í•©ë‹ˆë‹¤.
    ìë™ ì¬ì‹œë„, ë°±ì˜¤í”„ ì „ëµ, íƒ€ì„ì•„ì›ƒ ì„¤ì •ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.
    
    Returns:
        requests.Session: ì„¤ì •ëœ HTTP ì„¸ì…˜ ê°ì²´
    """
    logging.info("create_http_session() í˜¸ì¶œ: HTTP ì„¸ì…˜ ìƒì„± ì‹œì‘")
    
    try:
        # ìƒˆë¡œìš´ ì„¸ì…˜ ê°ì²´ ìƒì„±
        session = requests.Session()
        logging.debug("requests.Session ê°ì²´ ìƒì„± ì™„ë£Œ")
        
        # ì¬ì‹œë„ ì „ëµ ì„¤ì •
        retry_total = int(os.getenv('LLM_RETRY_TOTAL', '3'))
        retry_backoff = float(os.getenv('LLM_RETRY_BACKOFF', '1.0'))
        timeout_seconds = int(os.getenv('LLM_TIMEOUT', '180'))
        
        logging.debug("ì¬ì‹œë„ ì„¤ì •: ì´_ì¬ì‹œë„=%d, ë°±ì˜¤í”„_íŒ©í„°=%.1f, íƒ€ì„ì•„ì›ƒ=%ds", 
                     retry_total, retry_backoff, timeout_seconds)
        
        retry_strategy = Retry(
            total=retry_total,                                    # ì´ ì¬ì‹œë„ íšŸìˆ˜
            backoff_factor=retry_backoff,                         # ì¬ì‹œë„ ê°„ê²© ë°°ìˆ˜ (1.0 = 1ì´ˆ, 2ì´ˆ, 4ì´ˆ...)
            status_forcelist=[429, 500, 502, 503, 504],          # ì¬ì‹œë„í•  HTTP ìƒíƒœ ì½”ë“œ
            allowed_methods=["POST"]                              # POST ìš”ì²­ë§Œ ì¬ì‹œë„
        )
        
        # HTTP ì–´ëŒ‘í„° ì„¤ì • ë° ë§ˆìš´íŠ¸
        adapter = HTTPAdapter(max_retries=retry_strategy)
        session.mount("http://", adapter)
        session.mount("https://", adapter)
        logging.debug("HTTP/HTTPS ì–´ëŒ‘í„° ë§ˆìš´íŠ¸ ì™„ë£Œ")
        
        # ê¸°ë³¸ íƒ€ì„ì•„ì›ƒ ì„¤ì •
        session.timeout = timeout_seconds
        logging.debug("ì„¸ì…˜ íƒ€ì„ì•„ì›ƒ ì„¤ì •: %ds", session.timeout)
        
        # User-Agent ì„¤ì • (í™˜ê²½ë³€ìˆ˜ì—ì„œ ì„¤ì • ê°€ëŠ¥)
        user_agent = os.getenv('HTTP_USER_AGENT', 'Cell-Performance-LLM-Analyzer/1.0')
        session.headers.update({
            'User-Agent': user_agent
        })
        logging.debug("User-Agent í—¤ë” ì„¤ì • ì™„ë£Œ")
        
        logging.info("HTTP ì„¸ì…˜ ìƒì„± ì™„ë£Œ: retry_total=%d, timeout=%ds, backoff=%.1f", 
                    retry_strategy.total, session.timeout, retry_backoff)
        
        return session
        
    except Exception as e:
        logging.exception("HTTP ì„¸ì…˜ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: %s", e)
        raise


# ===========================================
# MCP ì„œë²„ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
# ===========================================
# FastMCP ì„œë²„ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
# ì´ ì¸ìŠ¤í„´ìŠ¤ëŠ” MCP(Model Context Protocol) ë„êµ¬ë“¤ì„ ë“±ë¡í•˜ê³  ì„œë¹™í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤.
mcp = FastMCP(name="Cell LLM ì¢…í•© ë¶„ì„ê¸°")
logging.info("FastMCP ì„œë²„ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì™„ë£Œ: name=%s", mcp.name)










 














# --- MCP Handler (Presentation Layer) ---
class MCPHandler:
    """
    MCP ìš”ì²­ì„ ì²˜ë¦¬í•˜ëŠ” Presentation Layer Handler
    
    ê¸°ì¡´ì˜ monolithic _analyze_cell_performance_logic()ë¥¼ leaní•œ í•¸ë“¤ëŸ¬ë¡œ ë¦¬íŒ©í† ë§
    AnalysisServiceì— ìœ„ì„í•˜ì—¬ ì‹¤ì œ ë¶„ì„ ë¡œì§ì„ ì²˜ë¦¬í•˜ê³ ,
    MCP ì‘ë‹µ í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ì—­í• ë§Œ ë‹´ë‹¹
    """
    
    def __init__(self, analysis_service: AnalysisService = None):
        """
        MCPHandler ì´ˆê¸°í™”
        
        Args:
            analysis_service (AnalysisService, optional): ë¶„ì„ ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤
        """
        self.analysis_service = analysis_service
        self.logger = logging.getLogger(__name__ + '.MCPHandler')
        
        # ê¸°ë³¸ ì„¤ì • ë¡œë“œ
        self._load_default_settings()
        
        self.logger.info("MCPHandler ì´ˆê¸°í™” ì™„ë£Œ")
    
    def _sanitize_for_logging(self, payload: dict | None) -> dict:
        """ë¯¼ê°ì •ë³´ë¥¼ ë§ˆìŠ¤í‚¹í•œ ì‚¬ë³¸ì„ ë°˜í™˜í•˜ì—¬ ì•ˆì „í•˜ê²Œ ë¡œê¹…í•œë‹¤."""
        if not isinstance(payload, dict):
            return {}

        redacted: dict[str, object] = {}
        for key, value in payload.items():
            lowered = str(key).lower()

            if any(token in lowered for token in ["password", "secret", "token", "authorization"]):
                redacted[key] = "***REDACTED***"
                continue

            if lowered in {"db", "database", "connection"}:
                # DB ì„¤ì •ì€ ì¤‘ì²© ë”•ì…”ë„ˆë¦¬ì¼ í™•ë¥ ì´ ë†’ìœ¼ë¯€ë¡œ ì¬ê·€ì ìœ¼ë¡œ ë§ˆìŠ¤í‚¹í•œë‹¤.
                redacted[key] = self._sanitize_for_logging(value)
                continue

            if isinstance(value, dict):
                redacted[key] = self._sanitize_for_logging(value)
            elif isinstance(value, list):
                redacted[key] = [self._sanitize_for_logging(item) if isinstance(item, dict) else item for item in value]
            else:
                redacted[key] = value

        return redacted

    def _load_default_settings(self) -> None:
        """ê¸°ë³¸ ì„¤ì • ë¡œë“œ (Configuration Manager ìš°ì„ , í™˜ê²½ë³€ìˆ˜ í´ë°±)"""
        try:
            settings = get_app_settings()
            self.default_backend_url = str(settings.backend_service_url)
            
            # ë””ë²„ê¹…: db_password ìƒíƒœ í™•ì¸
            self.logger.debug("db_password íƒ€ì…: %s", type(settings.db_password))
            self.logger.debug("db_password ê°’: %s", settings.db_password)
            
            # ì•ˆì „í•œ password ì²˜ë¦¬
            db_password = ""
            if settings.db_password is not None:
                try:
                    db_password = settings.db_password.get_secret_value()
                    self.logger.debug("db_password ì„±ê³µì ìœ¼ë¡œ ì½ìŒ: ê¸¸ì´=%d", len(db_password))
                except Exception as e:
                    self.logger.warning("db_password.get_secret_value() ì‹¤íŒ¨, ë¹ˆ ë¬¸ìì—´ ì‚¬ìš©: %s", e)
                    db_password = ""
            else:
                self.logger.warning("settings.db_passwordê°€ Noneì…ë‹ˆë‹¤!")
            
            self.default_db = {
                "host": settings.db_host,
                "port": settings.db_port,
                "user": settings.db_user,
                "password": db_password,
                "dbname": settings.db_name
            }
            self.logger.debug("Configuration Managerì—ì„œ ê¸°ë³¸ ì„¤ì • ë¡œë“œ ì™„ë£Œ")
        except Exception as e:
            self.logger.warning("Configuration Manager ë¡œë”© ì‹¤íŒ¨, ê¸°ë³¸ê°’ ì‚¬ìš©: %s", e)
            self.default_backend_url = 'http://165.213.69.30:8000/api/analysis/results/'
            self.default_db = {
                "host": "127.0.0.1",
                "port": 5432,
                "user": "postgres",
                "password": "",
                "dbname": "postgres"
            }
    
    def _validate_basic_request(self, request: dict) -> None:
        """
        ê¸°ë³¸ ìš”ì²­ ê²€ì¦
        
        Args:
            request (dict): MCP ìš”ì²­ ë°ì´í„°
            
        Raises:
            ValueError: í•„ìˆ˜ í•„ë“œ ëˆ„ë½ ë˜ëŠ” ì˜ëª»ëœ í˜•ì‹
        """
        self.logger.debug(
            "_validate_basic_request() í˜¸ì¶œ: íƒ€ì…=%s, í‚¤=%s",
            type(request).__name__,
            list(request.keys()) if isinstance(request, dict) else None,
        )
        
        # í•„ìˆ˜ í•„ë“œ í™•ì¸
        n1_text = request.get('n_minus_1') or request.get('n1')
        n_text = request.get('n')
        
        if not n1_text or not n_text:
            raise ValueError("'n_minus_1'ì™€ 'n' ì‹œê°„ ë²”ìœ„ë¥¼ ëª¨ë‘ ì œê³µí•´ì•¼ í•©ë‹ˆë‹¤.")
        
        # ê¸°ë³¸ íƒ€ì… ê²€ì¦
        if not isinstance(request, dict):
            raise ValueError("ìš”ì²­ì€ ë”•ì…”ë„ˆë¦¬ í˜•íƒœì—¬ì•¼ í•©ë‹ˆë‹¤.")
        
        self.logger.info("ê¸°ë³¸ ìš”ì²­ ê²€ì¦ í†µê³¼: n_minus_1=%s, n=%s", n1_text, n_text)
    
    def _parse_request_to_analysis_format(self, request: dict) -> dict:
        """MCP ìš”ì²­ì„ í‘œì¤€ AnalysisRequest ìŠ¤í‚¤ë§ˆë¡œ ë³€í™˜"""
        self.logger.debug("_parse_request_to_analysis_format() í˜¸ì¶œ: ìš”ì²­ í˜•ì‹ ë³€í™˜")

        enriched_request = {
            **request,
            "backend_url": request.get("backend_url") or self.default_backend_url,
            "db": request.get("db") or self.default_db,
            "max_prompt_tokens": request.get("max_prompt_tokens", DEFAULT_MAX_PROMPT_TOKENS),
            "max_prompt_chars": request.get("max_prompt_chars", DEFAULT_MAX_PROMPT_CHARS),
        }

        analysis_request = AnalysisRequest.from_dict(enriched_request)
        request_dict = analysis_request.to_dict()

        self.logger.info(
            "ìš”ì²­ í˜•ì‹ ë³€í™˜ ì™„ë£Œ: í•„ë“œìˆ˜=%d, ìš”ì•½=%s",
            len(request_dict),
            {
                "table": request_dict.get("table"),
                "columns_keys": list(request_dict.get("columns", {}).keys()),
                "filters": self._sanitize_for_logging({
                    key: request_dict.get(key)
                    for key in ("ne", "cellid", "host")
                    if request_dict.get(key) is not None
                }),
                "selected_pegs": request_dict.get("selected_pegs"),
            },
        )

        return request_dict
    
    def _build_backend_payload(self, analysis_result: dict, analysis_request: dict) -> dict:
        """ë°±ì—”ë“œ POST í˜¸ì¶œì— ì‚¬ìš©í•  í˜ì´ë¡œë“œë¥¼ êµ¬ì„±í•œë‹¤."""

        if not isinstance(analysis_result, dict):
            return {"analysis_result": analysis_result}

        payload: dict[str, Any] = analysis_result.copy()

        request_context = {
            "n_minus_1": analysis_request.get("n_minus_1"),
            "n": analysis_request.get("n"),
            "filters": self._sanitize_for_logging(analysis_request.get("filters", {})),
            "analysis_type": analysis_request.get("analysis_type"),
            "selected_pegs": analysis_request.get("selected_pegs"),
        }

        payload.setdefault("analysis_type", analysis_request.get("analysis_type"))
        payload.setdefault("request_context", request_context)

        return payload

    def _create_analysis_service(self) -> AnalysisService:
        """
        AnalysisService ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (ì˜ì¡´ì„± ì£¼ì…)
        
        Returns:
            AnalysisService: êµ¬ì„±ëœ ë¶„ì„ ì„œë¹„ìŠ¤
        """
        self.logger.debug("_create_analysis_service() í˜¸ì¶œ: AnalysisService ìƒì„±")
        
        # DatabaseRepository ìƒì„±
        db_repo = PostgreSQLRepository()
        
        # LLMRepository ìƒì„±
        llm_repo = LLMClient()
        
        # AnalysisService ìƒì„± (ì˜ì¡´ì„± ì£¼ì…)
        service = AnalysisService(
            database_repository=db_repo,
            llm_analysis_service=None  # LLMAnalysisServiceëŠ” ë‚´ë¶€ì—ì„œ ìƒì„±
        )
        
        self.logger.info("AnalysisService ìƒì„± ì™„ë£Œ")
        return service
    
    def _format_response_for_mcp(self, analysis_result: dict) -> dict:
        """
        AnalysisService ê²°ê³¼ë¥¼ MCP í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        
        Args:
            analysis_result (dict): AnalysisService ê²°ê³¼
            
        Returns:
            dict: MCP í˜¸í™˜ ì‘ë‹µ í˜•ì‹
        """
        self.logger.debug("_format_response_for_mcp() í˜¸ì¶œ: ì‘ë‹µ í˜•ì‹ ë³€í™˜")
        
        # ì¤‘ë³µ ì œê±°: AnalysisService ê²°ê³¼ë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ê³  í•„ìš”í•œ í•„ë“œë§Œ ì¶”ê°€/ë³€ê²½
        mcp_response = analysis_result.copy()
        
        # MCP ì „ìš© í•„ë“œ ì¶”ê°€
        if mcp_response.get("status") == "success":
            mcp_response["message"] = "ë¶„ì„ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤."
        elif mcp_response.get("status") == "error":
            mcp_response["message"] = mcp_response.get("message", "ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
        
        # ë°±ì—”ë“œì—ì„œ ì¤‘ë³µ ì²˜ë¦¬í•˜ë¯€ë¡œ MCP ì¸¡ ì¤‘ë³µ ì½”ë“œ ì œê±°ë¨
        # í•˜ìœ„ í˜¸í™˜ì„±ì€ ë°±ì—”ë“œ ì‘ë‹µì—ì„œ ì²˜ë¦¬
        
        # ë°±ì—”ë“œ ì „ì†¡ ê²°ê³¼ê°€ ìˆìœ¼ë©´ í¬í•¨ (ì´ë¯¸ analysis_resultì— ìˆìœ¼ë©´ ì¤‘ë³µ ë°©ì§€)
        if "backend_response" in analysis_result and "backend_response" not in mcp_response:
            mcp_response["backend_response"] = analysis_result["backend_response"]
        
        self.logger.info("MCP ì‘ë‹µ í˜•ì‹ ë³€í™˜ ì™„ë£Œ: %dê°œ í‚¤ (ì¤‘ë³µ ì œê±°ë¨)", len(mcp_response))
        return mcp_response
    
    def handle_request(self, request: dict) -> dict:
        """
        MCP ìš”ì²­ ì²˜ë¦¬ ë©”ì¸ ì—”íŠ¸ë¦¬í¬ì¸íŠ¸
        
        Args:
            request (dict): MCP ìš”ì²­ ë°ì´í„°
            
        Returns:
            dict: MCP ì‘ë‹µ ë°ì´í„°
            
        Raises:
            ValueError: ìš”ì²­ ê²€ì¦ ì‹¤íŒ¨
            Exception: ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ
        """
        sanitized_request = self._sanitize_for_logging(request)
        self.logger.info(
            "%s MCP Handler ìš”ì²­ ì²˜ë¦¬ ì‹œì‘ | í‚¤=%s | ìš”ì•½=%s",
            "=" * 10,
            list(request.keys()) if isinstance(request, dict) else None,
            sanitized_request,
        )
        
        try:
            # 1ë‹¨ê³„: ê¸°ë³¸ ìš”ì²­ ê²€ì¦
            self.logger.info("1ë‹¨ê³„: ê¸°ë³¸ ìš”ì²­ ê²€ì¦")
            self._validate_basic_request(request)
            
            # 2ë‹¨ê³„: ìš”ì²­ í˜•ì‹ ë³€í™˜
            self.logger.info("2ë‹¨ê³„: ìš”ì²­ í˜•ì‹ ë³€í™˜")
            analysis_request = self._parse_request_to_analysis_format(request)
            self.logger.debug(
                "AnalysisService ì „ë‹¬ìš© ìš”ì²­ ìš”ì•½: %s",
                {
                    "backend_url": bool(analysis_request.get('backend_url')),
                    "db_keys": list(analysis_request.get('db', {}).keys()),
                    "time_ranges_text": {
                        "n_minus_1": analysis_request.get('n_minus_1'),
                        "n": analysis_request.get('n'),
                    },
                    "filters": self._sanitize_for_logging(analysis_request.get('filters', {})),
                },
            )
            
            # 3ë‹¨ê³„: AnalysisService ìƒì„± (í•„ìš”ì‹œ)
            if not self.analysis_service:
                self.logger.info("3ë‹¨ê³„: AnalysisService ìƒì„±")
                self.analysis_service = self._create_analysis_service()
            
            # 4ë‹¨ê³„: ë¶„ì„ ì‹¤í–‰
            self.logger.info("4ë‹¨ê³„: ë¶„ì„ ì‹¤í–‰ (AnalysisService ìœ„ì„)")
            self.logger.debug(
                "AnalysisService.perform_analysis í˜¸ì¶œ ì¤€ë¹„ | backend_url=%s | table=%s | columns=%s",
                analysis_request.get('backend_url'),
                analysis_request.get('table'),
                analysis_request.get('columns'),
            )
            analysis_result = self.analysis_service.perform_analysis(analysis_request)
            self.logger.debug(
                "AnalysisService ìˆ˜í–‰ ì™„ë£Œ: status=%s, keys=%s",
                analysis_result.get('status') if isinstance(analysis_result, dict) else None,
                list(analysis_result.keys()) if isinstance(analysis_result, dict) else type(analysis_result).__name__,
            )

            backend_url = analysis_request.get('backend_url')
            if backend_url:
                self.logger.info("4.5ë‹¨ê³„: ë°±ì—”ë“œ ì—…ë¡œë“œ ì‹¤í–‰")
                backend_payload = self._build_backend_payload(analysis_result, analysis_request)
                self.logger.debug(
                    "ë°±ì—”ë“œ ì—…ë¡œë“œ í˜ì´ë¡œë“œ í‚¤: %s",
                    list(backend_payload.keys()) if isinstance(backend_payload, dict) else type(backend_payload).__name__,
                )
                # ë°±ì—”ë“œ ì—…ë¡œë“œ ê¸°ëŠ¥ì€ í–¥í›„ ì¬êµ¬í˜„ ì˜ˆì •
                backend_response = None
                if isinstance(analysis_result, dict):
                    analysis_result = analysis_result.copy()
                    analysis_result['backend_response'] = backend_response
                else:
                    analysis_result = {
                        "status": "success",
                        "raw_result": analysis_result,
                        "backend_response": backend_response,
                    }
                self.logger.info(
                    "ë°±ì—”ë“œ ì—…ë¡œë“œ ì™„ë£Œ: ì‘ë‹µ ìš”ì•½=%s",
                    self._sanitize_for_logging(backend_response) if backend_response else None,
                )
            
            # 5ë‹¨ê³„: ì‘ë‹µ í˜•ì‹ ë³€í™˜
            self.logger.info("5ë‹¨ê³„: MCP ì‘ë‹µ í˜•ì‹ ë³€í™˜")
            mcp_response = self._format_response_for_mcp(analysis_result)
            
            self.logger.info("=" * 20 + " MCP Handler ìš”ì²­ ì²˜ë¦¬ ì™„ë£Œ " + "=" * 20)
            return mcp_response
            
        except ValueError as e:
            # ê²€ì¦ ì˜¤ë¥˜ (400 Bad Request)
            self.logger.error("ìš”ì²­ ê²€ì¦ ì‹¤íŒ¨: %s", e)
            return {
                "status": "error",
                "error_type": "validation_error",
                "message": str(e),
                "details": "ìš”ì²­ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤."
            }
            
        except AnalysisServiceError as e:
            # ë¶„ì„ ì„œë¹„ìŠ¤ ì˜¤ë¥˜ (500 Internal Server Error)
            self.logger.error("ë¶„ì„ ì„œë¹„ìŠ¤ ì˜¤ë¥˜: %s", e)
            return {
                "status": "error", 
                "error_type": "analysis_error",
                "message": str(e),
                "details": e.to_dict() if hasattr(e, 'to_dict') else None,
                "workflow_step": getattr(e, 'workflow_step', None)
            }
            
        except Exception as e:
            # ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ (500 Internal Server Error)
            self.logger.exception("ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: %s", e)
            return {
                "status": "error",
                "error_type": "internal_error", 
                "message": "ë‚´ë¶€ ì„œë²„ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
                "details": str(e)
            }
    
    def close(self) -> None:
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        if self.analysis_service:
            self.analysis_service.close()
        self.logger.info("MCPHandler ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ")
    
    def __enter__(self):
        """ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì € ì§„ì…"""
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        """ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì € ì¢…ë£Œ"""
        self.close()
        return False




@mcp.tool
def analyze_cell_performance_with_llm(request: dict) -> dict:
    """
    MCP ì—”ë“œí¬ì¸íŠ¸: ì‹œê°„ ë²”ìœ„ ê¸°ë°˜ í†µí•© ì…€ ì„±ëŠ¥ ë¶„ì„ ì‹¤í–‰
    
    ìƒˆë¡œìš´ ì•„í‚¤í…ì²˜: MCPHandler -> AnalysisService -> ê°ì¢… Repository/Service íŒ¨í„´
    """
    # ìƒˆë¡œìš´ MCPHandler ì‚¬ìš©
    with MCPHandler() as handler:
        return handler.handle_request(request)


@mcp.tool
def analyze_peg_comparison(request: dict) -> dict:
    """
    MCP ì—”ë“œí¬ì¸íŠ¸: PEG ë¹„êµë¶„ì„ ì‹¤í–‰
    
    N-1 ê¸°ê°„ê³¼ N ê¸°ê°„ì˜ PEG ì„±ëŠ¥ ì§€í‘œë¥¼ ë¹„êµí•˜ì—¬ í†µê³„ì  ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    í”„ë¡ íŠ¸ì—”ë“œì˜ ê³„ì‚° ë¡œì§ì„ MCP ì„œë²„ë¡œ ì´ì „í•˜ì—¬ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤.
    
    Args:
        request (dict): PEG ë¹„êµë¶„ì„ ìš”ì²­ ë°ì´í„°
            - analysis_id (str): ë¶„ì„ ê³ ìœ  ì‹ë³„ì
            - raw_data (dict): ì›ì‹œ KPI ë°ì´í„°
                - stats (list): KPI í†µê³„ ë°ì´í„° ë¦¬ìŠ¤íŠ¸
                    - kpi_name (str): KPI ì´ë¦„
                    - period (str): ê¸°ê°„ ("N-1" ë˜ëŠ” "N")
                    - avg (float): í‰ê· ê°’
                    - cell_id (str): ì…€ ID
                - peg_definitions (dict): PEG ì •ì˜
                    - peg_name (str): PEG ì´ë¦„
                    - weight (int): ê°€ì¤‘ì¹˜
                    - thresholds (dict): ì„ê³„ê°’ ì„¤ì •
            - options (dict, optional): ë¶„ì„ ì˜µì…˜
                - include_metadata (bool): ë©”íƒ€ë°ì´í„° í¬í•¨ ì—¬ë¶€
                - algorithm_version (str): ì•Œê³ ë¦¬ì¦˜ ë²„ì „
    
    Returns:
        dict: PEG ë¹„êµë¶„ì„ ê²°ê³¼
            - success (bool): ì„±ê³µ ì—¬ë¶€
            - data (dict): ë¶„ì„ ê²°ê³¼ ë°ì´í„°
                - analysis_id (str): ë¶„ì„ ID
                - peg_comparison_results (list): PEGë³„ ë¹„êµ ê²°ê³¼
                - summary (dict): ì „ì²´ ìš”ì•½ í†µê³„
                - analysis_metadata (dict): ë¶„ì„ ë©”íƒ€ë°ì´í„°
            - error (dict, optional): ì˜¤ë¥˜ ì •ë³´
            - processing_time (float): ì²˜ë¦¬ ì‹œê°„ (ì´ˆ)
            - algorithm_version (str): ì‚¬ìš©ëœ ì•Œê³ ë¦¬ì¦˜ ë²„ì „
            - cached (bool): ìºì‹œ ì‚¬ìš© ì—¬ë¶€
    
    Example:
        {
            "analysis_id": "peg_analysis_001",
            "raw_data": {
                "stats": [
                    {
                        "kpi_name": "UL_throughput_avg",
                        "period": "N-1",
                        "avg": 45.2,
                        "cell_id": "cell_001"
                    },
                    {
                        "kpi_name": "UL_throughput_avg", 
                        "period": "N",
                        "avg": 48.7,
                        "cell_id": "cell_001"
                    }
                ],
                "peg_definitions": {
                    "UL_throughput_avg": {
                        "weight": 3,
                        "thresholds": {"high": 20.0, "medium": 10.0}
                    }
                }
            },
            "options": {
                "include_metadata": true,
                "algorithm_version": "v2.1.0"
            }
        }
    """
    logger = logging.getLogger(__name__ + '.peg_comparison')
    logger.info("=" * 20 + " PEG ë¹„êµë¶„ì„ MCP ìš”ì²­ ì²˜ë¦¬ ì‹œì‘ " + "=" * 20)
    
    try:
        # 1ë‹¨ê³„: ìš”ì²­ ë°ì´í„° ê²€ì¦ ë° ë³€í™˜
        logger.info("1ë‹¨ê³„: ìš”ì²­ ë°ì´í„° ê²€ì¦ ë° ë³€í™˜")
        
        # Pydantic ëª¨ë¸ì„ ì‚¬ìš©í•œ ìš”ì²­ ê²€ì¦
        from models.peg_comparison import PEGComparisonRequest, RawData, Options
        
        # raw_data ê²€ì¦
        if 'raw_data' not in request:
            raise ValueError("'raw_data' í•„ë“œê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        raw_data = RawData(**request['raw_data'])
        logger.info("RawData ê²€ì¦ ì™„ë£Œ: stats=%dê°œ, peg_definitions=%dê°œ", 
                   len(raw_data.stats), len(raw_data.peg_definitions))
        
        # options ê²€ì¦ (ì„ íƒì )
        options = None
        if 'options' in request and request['options']:
            options = Options(**request['options'])
            logger.info("Options ê²€ì¦ ì™„ë£Œ: include_metadata=%s, algorithm_version=%s",
                       options.include_metadata, options.algorithm_version)
        
        # analysis_id ê²€ì¦
        analysis_id = request.get('analysis_id', 'default_analysis_id')
        if not isinstance(analysis_id, str) or not analysis_id.strip():
            analysis_id = f"peg_analysis_{int(time.time())}"
        
        logger.info("ìš”ì²­ ê²€ì¦ ì™„ë£Œ: analysis_id=%s", analysis_id)
        
        # 2ë‹¨ê³„: PEGComparisonAnalyzer ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
        logger.info("2ë‹¨ê³„: PEGComparisonAnalyzer ì¸ìŠ¤í„´ìŠ¤ ìƒì„±")
        from services.peg_comparison_service import PEGComparisonAnalyzer
        
        analyzer = PEGComparisonAnalyzer()
        logger.info("PEGComparisonAnalyzer ì´ˆê¸°í™” ì™„ë£Œ")
        
        # 3ë‹¨ê³„: PEG ë¹„êµë¶„ì„ ì‹¤í–‰
        logger.info("3ë‹¨ê³„: PEG ë¹„êµë¶„ì„ ì‹¤í–‰")
        start_time = time.perf_counter()
        
        # optionsë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜ (PEGComparisonAnalyzerê°€ ë”•ì…”ë„ˆë¦¬ë¥¼ ê¸°ëŒ€)
        options_dict = None
        if options:
            options_dict = options.dict()
        
        # async í•¨ìˆ˜ë¥¼ ë™ê¸°ì ìœ¼ë¡œ ì‹¤í–‰
        import asyncio
        response = asyncio.run(analyzer.analysis_peg_comparison(raw_data, options_dict))
        
        processing_time = time.perf_counter() - start_time
        logger.info("PEG ë¹„êµë¶„ì„ ì™„ë£Œ: %.4fì´ˆ ì†Œìš”", processing_time)
        
        # 4ë‹¨ê³„: ì‘ë‹µ í˜•ì‹ ë³€í™˜ (Pydantic ëª¨ë¸ì„ ë”•ì…”ë„ˆë¦¬ë¡œ)
        logger.info("4ë‹¨ê³„: ì‘ë‹µ í˜•ì‹ ë³€í™˜")
        
        if response.success:
            # ì„±ê³µ ì‘ë‹µì„ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
            mcp_response = {
                "success": True,
                "data": response.data.dict() if response.data else None,
                "processing_time": processing_time,
                "algorithm_version": response.algorithm_version,
                "cached": response.cached
            }
            logger.info("ì„±ê³µ ì‘ë‹µ ìƒì„±: data_keys=%s", 
                       list(response.data.dict().keys()) if response.data else "None")
        else:
            # ì‹¤íŒ¨ ì‘ë‹µ
            mcp_response = {
                "success": False,
                "error": response.error,
                "processing_time": processing_time,
                "algorithm_version": response.algorithm_version,
                "cached": response.cached
            }
            logger.warning("ì‹¤íŒ¨ ì‘ë‹µ ìƒì„±: error=%s", response.error)
        
        logger.info("=" * 20 + " PEG ë¹„êµë¶„ì„ MCP ìš”ì²­ ì²˜ë¦¬ ì™„ë£Œ " + "=" * 20)
        return mcp_response
        
    except ValueError as ve:
        # ê²€ì¦ ì˜¤ë¥˜
        logger.error("ìš”ì²­ ê²€ì¦ ì‹¤íŒ¨: %s", ve)
        return {
            "success": False,
            "error": {
                "code": "VALIDATION_ERROR",
                "message": str(ve),
                "details": "ìš”ì²­ ë°ì´í„° í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤."
            },
            "processing_time": 0.0,
            "algorithm_version": "unknown"
        }
        
    except Exception as e:
        # ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜
        logger.exception("PEG ë¹„êµë¶„ì„ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: %s", e)
        return {
            "success": False,
            "error": {
                "code": "INTERNAL_ERROR",
                "message": f"ë‚´ë¶€ ì„œë²„ ì˜¤ë¥˜: {str(e)}",
                "details": "PEG ë¹„êµë¶„ì„ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
            },
            "processing_time": 0.0,
            "algorithm_version": "unknown"
        }


# ===========================================
# End-to-End Integration & Testing
# ===========================================

def initialize_integrated_components():
    """
    ëª¨ë“  ì»´í¬ë„ŒíŠ¸ë¥¼ ì˜ì¡´ì„± ì£¼ì…ìœ¼ë¡œ í†µí•© ì´ˆê¸°í™”
    
    Returns:
        tuple: (mcp_handler, analysis_service, logger) í†µí•©ëœ ì»´í¬ë„ŒíŠ¸ë“¤
    """
    logger = logging.getLogger(__name__ + '.integration')
    logger.info("=== í†µí•© ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™” ì‹œì‘ ===")
    
    try:
        # 1ë‹¨ê³„: Configuration Managerì™€ ë¡œê¹… ì´ˆê¸°í™”
        logger.info("1ë‹¨ê³„: Configuration Manager ì´ˆê¸°í™”")
        settings = get_app_settings()
        logger.info("âœ… Configuration Manager ë¡œë“œ ì™„ë£Œ")
        
        # 2ë‹¨ê³„: Core Utilities ì´ˆê¸°í™” (ìµœì†Œ ì˜ì¡´ì„±)
        logger.info("2ë‹¨ê³„: Core Utilities ì´ˆê¸°í™”")
        from services import PEGCalculator
        from utils import DataProcessor, RequestValidator, ResponseFormatter, TimeRangeParser
        
        time_parser = TimeRangeParser()
        peg_calculator = PEGCalculator()
        data_processor = DataProcessor()
        request_validator = RequestValidator(time_parser=time_parser)
        response_formatter = ResponseFormatter()
        
        logger.info("âœ… Core Utilities ì´ˆê¸°í™” ì™„ë£Œ: TimeRangeParser, PEGCalculator, DataProcessor, RequestValidator, ResponseFormatter")
        
        # 3ë‹¨ê³„: Repository Layer ì´ˆê¸°í™”
        logger.info("3ë‹¨ê³„: Repository Layer ì´ˆê¸°í™”")
        from repositories import LLMClient, PostgreSQLRepository

        # PostgreSQL Repository (DB ì„¤ì • ì£¼ì…)
        db_repository = PostgreSQLRepository()
        logger.info("âœ… PostgreSQLRepository ì´ˆê¸°í™” ì™„ë£Œ")
        
        # LLM Repository (LLM ì„¤ì • ì£¼ì…)
        llm_repository = LLMClient()
        logger.info("âœ… LLMClient ì´ˆê¸°í™” ì™„ë£Œ")
        
        # 4ë‹¨ê³„: Service Layer ì´ˆê¸°í™”
        logger.info("4ë‹¨ê³„: Service Layer ì´ˆê¸°í™”")
        from services import AnalysisService, LLMAnalysisService, PEGProcessingService

        # PEG Processing Service (DB Repository + PEG Calculator ì£¼ì…)
        peg_processing_service = PEGProcessingService(
            database_repository=db_repository,
            peg_calculator=peg_calculator
        )
        logger.info("âœ… PEGProcessingService ì´ˆê¸°í™” ì™„ë£Œ")
        
        # LLM Analysis Service (LLM Repository ì£¼ì…)
        llm_analysis_service = LLMAnalysisService(
            llm_repository=llm_repository
        )
        logger.info("âœ… LLMAnalysisService ì´ˆê¸°í™” ì™„ë£Œ")
        
        # Analysis Service (ëª¨ë“  ì„œë¹„ìŠ¤ í†µí•©)
        analysis_service = AnalysisService(
            database_repository=db_repository,
            peg_processing_service=peg_processing_service,
            llm_analysis_service=llm_analysis_service,
            time_parser=time_parser,
            data_processor=data_processor
        )
        logger.info("âœ… AnalysisService ì´ˆê¸°í™” ì™„ë£Œ")
        
        # 5ë‹¨ê³„: Presentation Layer ì´ˆê¸°í™” (MCPHandler)
        logger.info("5ë‹¨ê³„: Presentation Layer ì´ˆê¸°í™”")
        
        # MCPHandler (ëª¨ë“  ì»´í¬ë„ŒíŠ¸ ì£¼ì…)
        mcp_handler = MCPHandler(
            request_validator=request_validator,
            analysis_service=analysis_service,
            response_formatter=response_formatter
        )
        logger.info("âœ… MCPHandler ì´ˆê¸°í™” ì™„ë£Œ")
        
        logger.info("=== í†µí•© ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™” ì™„ë£Œ ===")
        logger.info("ì´ˆê¸°í™”ëœ ì»´í¬ë„ŒíŠ¸: MCPHandler, AnalysisService, 7ê°œ ìœ í‹¸ë¦¬í‹°/ì„œë¹„ìŠ¤")
        
        return mcp_handler, analysis_service, logger
        
    except Exception as e:
        logger.error("í†µí•© ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: %s", e)
        logger.exception("ì´ˆê¸°í™” ì˜¤ë¥˜ ìƒì„¸ ì •ë³´")
        raise


def run_end_to_end_test():
    """
    End-to-End í†µí•© í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    
    ëª¨ë“  ì»´í¬ë„ŒíŠ¸ê°€ ì˜¬ë°”ë¥´ê²Œ í†µí•©ë˜ì—ˆëŠ”ì§€ ê²€ì¦í•©ë‹ˆë‹¤.
    """
    logger = logging.getLogger(__name__ + '.e2e_test')
    logger.info("=== End-to-End í†µí•© í…ŒìŠ¤íŠ¸ ì‹œì‘ ===")
    
    try:
        # 1ë‹¨ê³„: ëª¨ë“  ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
        logger.info("1ë‹¨ê³„: í†µí•© ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”")
        mcp_handler, analysis_service, integration_logger = initialize_integrated_components()
        
        # 2ë‹¨ê³„: ìƒ˜í”Œ MCP ìš”ì²­ ì •ì˜
        logger.info("2ë‹¨ê³„: ìƒ˜í”Œ MCP ìš”ì²­ ì •ì˜")
        sample_request = {
            "n_minus_1": "2025-01-01_09:00~2025-01-01_18:00",
            "n": "2025-01-02_09:00~2025-01-02_18:00",
            "output_dir": "./test_analysis_output",
            "table": "summary",
            "analysis_type": "enhanced",
            "enable_mock": True,  # í…ŒìŠ¤íŠ¸ìš© Mock ëª¨ë“œ
            "max_prompt_tokens": 8000,
            "db": {
                "host": "localhost",
                "port": 5432,
                "dbname": "test_db",
                "user": "test_user",
                "password": "test_pass"
            },
            "filters": {
                "ne": "nvgnb#10000",
                "cellid": ["2010", "2011"],
                "host": "192.168.1.1"
            },
            "selected_pegs": ["preamble_count", "response_count"],
            "peg_definitions": {
                "success_rate": "response_count/preamble_count*100"
            }
        }
        
        logger.info("âœ… ìƒ˜í”Œ ìš”ì²­ ì •ì˜ ì™„ë£Œ: %dê°œ í•„ë“œ", len(sample_request))
        
        # 3ë‹¨ê³„: End-to-End ìš”ì²­ ì²˜ë¦¬
        logger.info("3ë‹¨ê³„: End-to-End ìš”ì²­ ì²˜ë¦¬ ì‹¤í–‰")
        
        start_time = time.time()
        response = mcp_handler.handle_request(sample_request)
        end_time = time.time()
        
        processing_time = end_time - start_time
        logger.info("âœ… ìš”ì²­ ì²˜ë¦¬ ì™„ë£Œ: %.2fì´ˆ ì†Œìš”", processing_time)
        
        # 4ë‹¨ê³„: ì‘ë‹µ ê²€ì¦
        logger.info("4ë‹¨ê³„: ì‘ë‹µ ê²€ì¦")
        
        if not response:
            raise ValueError("ì‘ë‹µì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤")
        
        if not isinstance(response, dict):
            raise ValueError(f"ì‘ë‹µì´ ë”•ì…”ë„ˆë¦¬ê°€ ì•„ë‹™ë‹ˆë‹¤: {type(response)}")
        
        response_status = response.get('status', 'unknown')
        response_keys = list(response.keys())
        
        logger.info("ì‘ë‹µ ìƒíƒœ: %s", response_status)
        logger.info("ì‘ë‹µ í‚¤: %s", response_keys)
        
        if response_status == 'success':
            logger.info("âœ… End-to-End í…ŒìŠ¤íŠ¸ ì„±ê³µ!")
            
            # ì‘ë‹µ ì„¸ë¶€ ì •ë³´ ë¡œê¹…
            if 'data_summary' in response:
                data_summary = response['data_summary']
                logger.info("ë°ì´í„° ìš”ì•½: %s", data_summary)
            
            if 'peg_analysis' in response:
                peg_analysis = response['peg_analysis']
                peg_count = len(peg_analysis.get('results', []))
                logger.info("PEG ë¶„ì„ ê²°ê³¼: %dê°œ", peg_count)
            
            if 'llm_analysis' in response:
                llm_analysis = response['llm_analysis']
                model_used = llm_analysis.get('model_used', 'unknown')
                logger.info("LLM ë¶„ì„ ëª¨ë¸: %s", model_used)
            
            if 'metadata' in response:
                metadata = response['metadata']
                request_id = metadata.get('request_id', 'unknown')
                logger.info("ìš”ì²­ ID: %s", request_id)
        
        elif response_status == 'error':
            error_message = response.get('message', 'Unknown error')
            logger.warning("âš ï¸ End-to-End í…ŒìŠ¤íŠ¸ì—ì„œ ì˜¤ë¥˜ ì‘ë‹µ ë°›ìŒ: %s", error_message)
            
            # ì˜¤ë¥˜ì—¬ë„ ì‹œìŠ¤í…œì´ ì •ìƒì ìœ¼ë¡œ ì‘ë‹µì„ ë°˜í™˜í–ˆìœ¼ë¯€ë¡œ ë¶€ë¶„ì  ì„±ê³µ
            logger.info("âœ… ì˜¤ë¥˜ ì²˜ë¦¬ ì‹œìŠ¤í…œ ì •ìƒ ì‘ë™ í™•ì¸")
        
        else:
            logger.warning("âš ï¸ ì˜ˆìƒì¹˜ ëª»í•œ ì‘ë‹µ ìƒíƒœ: %s", response_status)
        
        # 5ë‹¨ê³„: ì»´í¬ë„ŒíŠ¸ ìƒíƒœ ê²€ì¦
        logger.info("5ë‹¨ê³„: ì»´í¬ë„ŒíŠ¸ ìƒíƒœ ê²€ì¦")
        
        # AnalysisService ìƒíƒœ í™•ì¸
        service_info = analysis_service.get_service_info()
        workflow_status = analysis_service.get_workflow_status()
        
        logger.info("AnalysisService ì •ë³´: %s", service_info)
        logger.info("ì›Œí¬í”Œë¡œìš° ìƒíƒœ: %s", workflow_status)
        
        logger.info("=== End-to-End í†µí•© í…ŒìŠ¤íŠ¸ ì™„ë£Œ ===")
        logger.info("ì „ì²´ ì²˜ë¦¬ ì‹œê°„: %.2fì´ˆ", processing_time)
        logger.info("í…ŒìŠ¤íŠ¸ ê²°ê³¼: %s", "ì„±ê³µ" if response_status in ['success', 'error'] else "ë¶€ë¶„ì  ì„±ê³µ")
        
        return response
        
    except Exception as e:
        logger.error("End-to-End í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: %s", e)
        logger.exception("í…ŒìŠ¤íŠ¸ ì˜¤ë¥˜ ìƒì„¸ ì •ë³´")
        
        # ì‹¤íŒ¨í•´ë„ ì˜¤ë¥˜ ì •ë³´ë¥¼ ë°˜í™˜
        return {
            "status": "test_error",
            "message": f"End-to-End í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}",
            "error_type": type(e).__name__
        }


if __name__ == '__main__':
    import sys

    # End-to-End í…ŒìŠ¤íŠ¸ ëª¨ë“œ
    if len(sys.argv) > 1 and sys.argv[1] == "--e2e-test":
        print("=" * 60)
        print("End-to-End Integration Test")
        print("=" * 60)
        
        # ë¡œê¹… ì„¤ì •
        # ê³µí†µ ì„¤ì • ì‚¬ìš©(ì´ë¯¸ get_app_settings() í˜¸ì¶œ ì‹œ ì„¤ì •ë¨). ì¶”ê°€ íŒŒì¼ í•¸ë“¤ëŸ¬ë§Œ ë§ë¶™ì„
        from config.settings import get_settings
        settings = get_settings()
        if settings.log_file_enabled:
            pass  # íŒŒì¼ ë¡œê¹…ì€ settings.setup_loggingì—ì„œ ì²˜ë¦¬ë¨
        else:
            fh = logging.FileHandler('e2e_test.log', mode='w', encoding='utf-8')
            fh.setFormatter(logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s'))
            logging.getLogger().addHandler(fh)
        
        try:
            result = run_end_to_end_test()
            print("\n" + "=" * 60)
            print("í…ŒìŠ¤íŠ¸ ê²°ê³¼:")
            print(json.dumps(result, ensure_ascii=False, indent=2))
            print("=" * 60)
            
            # ì„±ê³µ ì‹œ 0, ì‹¤íŒ¨ ì‹œ 1ë¡œ ì¢…ë£Œ
            sys.exit(0 if result.get('status') in ['success', 'error'] else 1)
            
        except Exception as e:
            print(f"\ní…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘ ì¹˜ëª…ì  ì˜¤ë¥˜: {e}")
            sys.exit(1)
    
    # CLI ëª¨ë“œ ì§€ì›: Backendì—ì„œ í”„ë¡œì„¸ìŠ¤ë¡œ í˜¸ì¶œ ì‹œ ì‚¬ìš©
    elif len(sys.argv) > 2 and sys.argv[1] == "--request":
        try:
            request_json = sys.argv[2]
            request_data = json.loads(request_json)
            
            logging.info("CLI ëª¨ë“œë¡œ LLM ë¶„ì„ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.")
            logging.info("ìš”ì²­ ë°ì´í„°: %s", json.dumps(request_data, ensure_ascii=False, indent=2))
            
            # í†µí•©ëœ ì»´í¬ë„ŒíŠ¸ ì‚¬ìš©
            mcp_handler, _, _ = initialize_integrated_components()
            result = mcp_handler.handle_request(request_data)
            
            # JSON ê²°ê³¼ ì¶œë ¥ (Backendì—ì„œ capture)
            print(json.dumps(result, ensure_ascii=False))
            
            # ì„±ê³µ ì¢…ë£Œ
            sys.exit(0)
            
        except Exception as e:
            logging.exception("CLI ëª¨ë“œ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: %s", e)
            error_result = {
                "status": "error",
                "message": f"CLI ëª¨ë“œ ì‹¤í–‰ ì˜¤ë¥˜: {str(e)}"
            }
            print(json.dumps(error_result, ensure_ascii=False))
            sys.exit(1)
    else:
        logging.info("streamable-http ëª¨ë“œë¡œ MCPë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.")
        mcp.run(transport="streamable-http", host="0.0.0.0", port=8001)