"""
ë°±ì—”ë“œ Payload ìƒì„± ìœ í‹¸ë¦¬í‹°

ëª©ì : MCP ë¶„ì„ ê²°ê³¼ë¥¼ ë°±ì—”ë“œ V2 API ìŠ¤í‚¤ë§ˆì— ë§ê²Œ ë³€í™˜
"""

import logging
from typing import Dict, Any, Optional, List
from datetime import datetime

logger = logging.getLogger(__name__)


class BackendPayloadBuilder:
    """
    ë°±ì—”ë“œ V2 APIìš© Payload ìƒì„±ê¸°
    
    ë³€í™˜ ê·œì¹™:
    - host â†’ swname ëª…ì¹­ ë³€ê²½
    - ì¤‘ì²© êµ¬ì¡° ì œê±° ë° í‰íƒ„í™”
    - í•„ìˆ˜ í•„ë“œ ë³´ì¥
    """
    
    @staticmethod
    def build_v2_payload(
        analysis_result: dict,
        analysis_request: dict
    ) -> dict:
        """
        ë°±ì—”ë“œ V2 APIìš© í˜ì´ë¡œë“œ ìƒì„± (DB ì¡°íšŒ ê°’ ìš°ì„ )
        
        Args:
            analysis_result: AnalysisService ê²°ê³¼ (db_identifiers í¬í•¨ ê°€ëŠ¥)
            analysis_request: ì›ë³¸ MCP ìš”ì²­ (filters í¬í•¨)
            
        Returns:
            ë°±ì—”ë“œ V2 ìŠ¤í‚¤ë§ˆ í˜¸í™˜ í˜ì´ë¡œë“œ
        """
        logger.info("ë°±ì—”ë“œ V2 í˜ì´ë¡œë“œ ìƒì„± ì‹œì‘")
        
        # DB ì¡°íšŒ ê°’ ìš°ì„ , filters í´ë°±, ê¸°ë³¸ê°’ ìˆœ
        filters = analysis_request.get("filters", {})
        columns = analysis_request.get("columns", {})
        db_identifiers = analysis_result.get("db_identifiers", {})
        
        # ne_id: DB > filters > "All NEs" (ê¸°ë³¸ê°’)
        ne_id = (
            db_identifiers.get("ne_id") or
            BackendPayloadBuilder._extract_identifier(filters.get("ne")) or
            "All NEs"
        )
        
        # cell_id: DB > filters > "All cells" (ê¸°ë³¸ê°’)
        cell_id = (
            db_identifiers.get("cell_id") or
            BackendPayloadBuilder._extract_identifier(filters.get("cellid")) or
            "All cells"
        )
        
        # swname: DB > filters(swname) > "All hosts"
        swname = (
            db_identifiers.get("swname") or
            BackendPayloadBuilder._extract_identifier(
                filters.get("swname")
            ) or
            "All hosts"
        )
        
        # rel_ver: DB > filters > None (ê¸°ë³¸ê°’)
        rel_ver = (
            db_identifiers.get("rel_ver") or
            BackendPayloadBuilder._extract_identifier(filters.get("rel_ver")) or
            None
        )
        
        logger.debug(
            "ì‹ë³„ì ìš°ì„ ìˆœìœ„ ì ìš© ê²°ê³¼:\n"
            "  ne_id: %s (DB=%s, filters=%s)\n"
            "  cell_id: %s (DB=%s, filters=%s)\n"
            "  swname: %s (DB=%s, filters=%s)\n"
            "  rel_ver: %s (DB=%s, filters=%s)",
            ne_id,
            db_identifiers.get("ne_id"),
            BackendPayloadBuilder._extract_identifier(filters.get("ne")),
            cell_id,
            db_identifiers.get("cell_id"),
            BackendPayloadBuilder._extract_identifier(filters.get("cellid")),
            swname,
            db_identifiers.get("swname"),
            BackendPayloadBuilder._extract_identifier(filters.get("swname")),
            rel_ver,
            db_identifiers.get("rel_ver"),
            BackendPayloadBuilder._extract_identifier(filters.get("rel_ver"))
        )
        
        # ë¶„ì„ ê¸°ê°„ íŒŒì‹±
        analysis_period = BackendPayloadBuilder._parse_analysis_period(
            analysis_request.get("n_minus_1"),
            analysis_request.get("n")
        )
        
        # Choi ì•Œê³ ë¦¬ì¦˜ ê²°ê³¼ ì¶”ì¶œ
        choi_result = BackendPayloadBuilder._extract_choi_result(
            analysis_result
        )
        
        # LLM ë¶„ì„ ê²°ê³¼ ì¶”ì¶œ
        llm_analysis = BackendPayloadBuilder._extract_llm_analysis(
            analysis_result
        )
        
        # LLM ë¶„ì„ í‚¤ ë””ë²„ê¹…
        llm_data_raw = analysis_result.get("llm_analysis", {})
        logger.debug(
            "LLM ë¶„ì„ ì›ë³¸ í‚¤: %s",
            list(llm_data_raw.keys()) if isinstance(llm_data_raw, dict) else type(llm_data_raw).__name__
        )
        
        # llm_analysisê°€ Noneì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬
        if llm_analysis and isinstance(llm_analysis, dict):
            logger.debug(
                "ì¶”ì¶œëœ llm_analysis (Enhanced): executive_summary=%s, diagnostic_findings=%dê°œ, recommended_actions=%dê°œ, model=%s",
                "ìˆìŒ" if llm_analysis.get("executive_summary") else "ì—†ìŒ",
                len(llm_analysis.get("diagnostic_findings", [])),
                len(llm_analysis.get("recommended_actions", [])),
                llm_analysis.get("model_name")
            )
        else:
            logger.warning("llm_analysisê°€ Noneì´ê±°ë‚˜ dictê°€ ì•„ë‹™ë‹ˆë‹¤: type=%s", type(llm_analysis).__name__)
        
        # PEG ë¹„êµ ê²°ê³¼ ì¶”ì¶œ
        peg_comparisons = BackendPayloadBuilder._extract_peg_comparisons(
            analysis_result
        )
        
        # í˜ì´ë¡œë“œ êµ¬ì„±
        payload = {
            # ì‹ë³„ì
            "ne_id": ne_id,
            "cell_id": cell_id,
            "swname": swname,
            "rel_ver": rel_ver,
            
            # ë¶„ì„ ê¸°ê°„
            "analysis_period": analysis_period,
            
            # Choi ì•Œê³ ë¦¬ì¦˜ (ì„ íƒ)
            "choi_result": choi_result,
            
            # LLM ë¶„ì„
            "llm_analysis": llm_analysis,
            
            # PEG ë¹„êµ
            "peg_comparisons": peg_comparisons,
            
            # ì¶”ì ìš© ID (ë°±ì—”ë“œ _idë¥¼ analysis_idë¡œ ë§¤í•‘)
            "analysis_id": analysis_result.get("analysis_id")
        }
        
        # ë°±ì—”ë“œ ì‘ë‹µì—ì„œ _idê°€ ìˆìœ¼ë©´ ì œê±° (ì¤‘ë³µ ë°©ì§€)
        if "_id" in payload:
            del payload["_id"]
            logger.debug("í˜ì´ë¡œë“œì—ì„œ _id í•„ë“œ ì œê±° (analysis_id ì‚¬ìš©)")
        
        logger.info(
            "ë°±ì—”ë“œ V2 í˜ì´ë¡œë“œ ìƒì„± ì™„ë£Œ: ne_id=%s, cell_id=%s, swname=%s, pegs=%d",
            ne_id,
            cell_id,
            swname,
            len(peg_comparisons)
        )
        
        return payload
    
    @staticmethod
    def _extract_identifier(value: Any, default: Optional[str] = None) -> Optional[str]:
        """
        ì‹ë³„ì ì¶”ì¶œ (ë¦¬ìŠ¤íŠ¸ë©´ ì²« ë²ˆì§¸ ê°’)
        
        Args:
            value: ì¶”ì¶œí•  ê°’ (str, list, None)
            default: ê¸°ë³¸ê°’
            
        Returns:
            ì¶”ì¶œëœ ë¬¸ìì—´ ë˜ëŠ” ê¸°ë³¸ê°’
        """
        if isinstance(value, list):
            return str(value[0]) if value else default
        return str(value) if value else default
    
    @staticmethod
    def _parse_analysis_period(n_minus_1: str, n: str) -> Dict[str, str]:
        """
        ë¶„ì„ ê¸°ê°„ íŒŒì‹± (ë‹¤ì–‘í•œ í˜•ì‹ ì§€ì›)
        
        ì§€ì› í˜•ì‹:
        - "2025-01-19_00:00~23:59" (ê¸°ì¡´ - ê°™ì€ ë‚ ì§œ)
        - "2025-09-04_21:15 ~2025-09-04_21:30" (ì‹ ê·œ - ë‚ ì§œ_ì‹œê°„ ~ë‚ ì§œ_ì‹œê°„)
        
        Args:
            n_minus_1: N-1 ê¸°ê°„
            n: N ê¸°ê°„
            
        Returns:
            {
                "n_minus_1_start": "2025-01-19 00:00:00",
                "n_minus_1_end": "2025-01-19 23:59:59",
                "n_start": "2025-01-20 00:00:00",
                "n_end": "2025-01-20 23:59:59"
            }
        """
        def parse_single_datetime(dt_str: str) -> str:
            """
            ë‹¨ì¼ ë‚ ì§œ-ì‹œê°„ íŒŒì‹±
            
            ì§€ì›:
            - "2025-01-19_00:00" â†’ "2025-01-19 00:00:00"
            - "00:00" â†’ "00:00:00" (ë‚ ì§œ ì—†ìŒ)
            """
            dt_str = dt_str.strip()
            
            if "_" in dt_str:
                # "ë‚ ì§œ_ì‹œê°„" í˜•ì‹
                date_part, time_part = dt_str.split("_", 1)
                # ì´ˆê°€ ì—†ìœ¼ë©´ ì¶”ê°€
                if time_part.count(":") == 1:
                    return f"{date_part} {time_part}:00"
                else:
                    return f"{date_part} {time_part}"
            else:
                # ì‹œê°„ë§Œ (ë‚ ì§œ ì—†ìŒ)
                if dt_str.count(":") == 1:
                    return f"{dt_str}:00"
                else:
                    return dt_str
        
        def parse_time_range(time_str: str) -> tuple:
            """
            ì‹œê°„ ë²”ìœ„ íŒŒì‹±
            
            í˜•ì‹ 1: "2025-01-19_00:00~23:59"
            í˜•ì‹ 2: "2025-09-04_21:15 ~2025-09-04_21:30"
            """
            if not time_str or "~" not in time_str:
                return ("unknown", "unknown")
            
            try:
                # ê³µë°± ì œê±° ë° ì •ê·œí™”
                time_str = time_str.strip()
                
                # "~"ë¡œ ë¶„ë¦¬
                parts = time_str.split("~")
                if len(parts) != 2:
                    raise ValueError(f"ì˜ëª»ëœ í˜•ì‹: 2ê°œ ë¶€ë¶„ ì˜ˆìƒ, {len(parts)}ê°œ ë°œê²¬")
                
                start_str = parts[0].strip()
                end_str = parts[1].strip()
                
                # ê° ë¶€ë¶„ íŒŒì‹±
                start_datetime = parse_single_datetime(start_str)
                end_datetime = parse_single_datetime(end_str)
                
                # í˜•ì‹ 1 í˜¸í™˜: ë ì‹œê°„ì— ë‚ ì§œê°€ ì—†ìœ¼ë©´ ì‹œì‘ ë‚ ì§œ ì‚¬ìš©
                if "_" in start_datetime and "_" not in end_str and ":" in end_str:
                    # "2025-01-19_00:00" ~ "23:59" í˜•ì‹
                    date_part = start_datetime.split()[0]  # "2025-01-19"
                    end_datetime = f"{date_part} {end_datetime}"
                    # ì´ˆ ì²˜ë¦¬
                    if end_datetime.count(":") == 1:
                        end_datetime = f"{end_datetime}:59"
                
                return (start_datetime, end_datetime)
                
            except Exception as e:
                logger.warning(f"ì‹œê°„ ë²”ìœ„ íŒŒì‹± ì‹¤íŒ¨: {time_str}, error={e}")
                return ("unknown", "unknown")
        
        n_minus_1_start, n_minus_1_end = parse_time_range(n_minus_1)
        n_start, n_end = parse_time_range(n)
        
        return {
            "n_minus_1_start": n_minus_1_start,
            "n_minus_1_end": n_minus_1_end,
            "n_start": n_start,
            "n_end": n_end
        }
    
    @staticmethod
    def _extract_choi_result(analysis_result: dict) -> Optional[Dict[str, Any]]:
        """
        Choi ì•Œê³ ë¦¬ì¦˜ ê²°ê³¼ ì¶”ì¶œ
        
        Args:
            analysis_result: AnalysisService ê²°ê³¼
            
        Returns:
            Choi ê²°ê³¼ ë˜ëŠ” None
        """
        # TODO: Choi ì•Œê³ ë¦¬ì¦˜ì´ êµ¬í˜„ë˜ë©´ ì‹¤ì œ ì¶”ì¶œ ë¡œì§ ì¶”ê°€
        choi_data = analysis_result.get("choi_algorithm", {})
        
        if not choi_data or not choi_data.get("enabled"):
            return None
        
        return {
            "enabled": True,
            "status": choi_data.get("status", "normal"),
            "score": choi_data.get("score"),
            "details": choi_data.get("details", {})
        }
    
    @staticmethod
    def _extract_llm_analysis(analysis_result: dict) -> Dict[str, Any]:
        """
        LLM ë¶„ì„ ê²°ê³¼ ì¶”ì¶œ
        
        Args:
            analysis_result: AnalysisService ê²°ê³¼
            
        Returns:
            LLM ë¶„ì„ ê²°ê³¼
        """
        llm_data = analysis_result.get("llm_analysis", {})
        
        # ë””ë²„ê·¸ ë¡œê¹…: ì›ë³¸ LLM ë°ì´í„° êµ¬ì¡° í™•ì¸ (Enhanced í”„ë¡¬í”„íŠ¸ í•„ë“œë§Œ)
        logger.debug(
            "ğŸ” LLM ë¶„ì„ ì›ë³¸ ë°ì´í„° êµ¬ì¡° ë¶„ì„ (Enhanced í”„ë¡¬í”„íŠ¸):\n"
            "  ì „ì²´ í‚¤: %s\n"
            "  executive_summary: %s\n"
            "  diagnostic_findings: %s\n"
            "  recommended_actions: %s\n"
            "  technical_analysis: %s\n"
            "  cells_with_significant_change: %s\n"
            "  action_plan: %s\n"
            "  key_findings: %s\n"
            "  model_name: %s",
            list(llm_data.keys()) if isinstance(llm_data, dict) else type(llm_data).__name__,
            llm_data.get("executive_summary", "ì—†ìŒ"),
            llm_data.get("diagnostic_findings", "ì—†ìŒ"),
            llm_data.get("recommended_actions", "ì—†ìŒ"),
            llm_data.get("technical_analysis", "ì—†ìŒ"),
            llm_data.get("cells_with_significant_change", "ì—†ìŒ"),
            llm_data.get("action_plan", "ì—†ìŒ"),
            llm_data.get("key_findings", "ì—†ìŒ"),
            llm_data.get("model_name", "ì—†ìŒ")
        )
        
        # ì „ì²´ LLM ë°ì´í„° êµ¬ì¡°ë¥¼ JSONìœ¼ë¡œ ë¡œê¹… (ê°œë°œìš©)
        if isinstance(llm_data, dict) and llm_data:
            import json
            logger.debug("ğŸ” LLM ì „ì²´ ì‘ë‹µ êµ¬ì¡° (JSON):\n%s", json.dumps(llm_data, indent=2, ensure_ascii=False, default=str))
        
        # Enhanced í”„ë¡¬í”„íŠ¸ êµ¬ì¡°ë§Œ ì‚¬ìš© (ê¸°ì¡´ í˜¸í™˜ì„± í•„ë“œ ì œê±°)
        executive_summary = llm_data.get("executive_summary")
        diagnostic_findings = llm_data.get("diagnostic_findings", [])
        recommended_actions = llm_data.get("recommended_actions", [])
        
        # model_nameë§Œ ìœ ì§€ (LLM ì„œë¹„ìŠ¤ì—ì„œ ì¶”ê°€í•˜ëŠ” ë©”íƒ€ë°ì´í„°)
        model_name = (
            llm_data.get("model_name") or
            llm_data.get("model") or
            llm_data.get("model_used") or
            llm_data.get("_analysis_metadata", {}).get("strategy_used")
        )
        
        # technical_analysis ì „ì²´ êµ¬ì¡° ì¶”ì¶œ
        technical_analysis = llm_data.get("technical_analysis", {})
        
        # cells_with_significant_change ì¶”ì¶œ
        cells_with_significant_change = llm_data.get("cells_with_significant_change", {})
        
        # action_plan ì¶”ì¶œ (ìš°ì„ ìˆœìœ„ë³„ ì•¡ì…˜ í”Œëœ)
        action_plan = llm_data.get("action_plan", [])
        
        # key_findings ì¶”ì¶œ (í•µì‹¬ ë°œê²¬ì‚¬í•­)
        key_findings = llm_data.get("key_findings", [])
        
        result = {
            # Enhanced í”„ë¡¬í”„íŠ¸ êµ¬ì¡°ë§Œ ì‚¬ìš©
            "executive_summary": executive_summary,
            "diagnostic_findings": diagnostic_findings,
            "recommended_actions": recommended_actions,
            # Enhanced í”„ë¡¬í”„íŠ¸ì˜ ì¶”ê°€ í•„ë“œë“¤
            "technical_analysis": technical_analysis,
            "cells_with_significant_change": cells_with_significant_change,
            "action_plan": action_plan,
            "key_findings": key_findings,
            # ë©”íƒ€ë°ì´í„°
            "model_name": model_name
        }
        
        # ë””ë²„ê·¸ ë¡œê¹…: ì¶”ì¶œëœ ê²°ê³¼ í™•ì¸ (Enhanced í”„ë¡¬í”„íŠ¸ í•„ë“œë§Œ)
        logger.debug(
            "âœ… LLM ë¶„ì„ ì¶”ì¶œ ê²°ê³¼ (Enhanced í”„ë¡¬í”„íŠ¸):\n"
            "  executive_summary: %s\n"
            "  diagnostic_findings: %dê°œ\n"
            "  recommended_actions: %dê°œ\n"
            "  technical_analysis: %s\n"
            "  cells_with_significant_change: %dê°œ\n"
            "  action_plan: %dê°œ\n"
            "  key_findings: %dê°œ\n"
            "  model_name: %s",
            "ìˆìŒ" if result["executive_summary"] else "ì—†ìŒ",
            len(result["diagnostic_findings"]) if isinstance(result["diagnostic_findings"], list) else 0,
            len(result["recommended_actions"]) if isinstance(result["recommended_actions"], list) else 0,
            "ìˆìŒ" if result["technical_analysis"] else "ì—†ìŒ",
            len(result["cells_with_significant_change"]) if isinstance(result["cells_with_significant_change"], dict) else 0,
            len(result["action_plan"]) if isinstance(result["action_plan"], list) else 0,
            len(result["key_findings"]) if isinstance(result["key_findings"], list) else 0,
            result["model_name"]
        )
        
        return result
    
    @staticmethod
    def _extract_peg_comparisons(analysis_result: dict) -> List[Dict[str, Any]]:
        """
        PEG ë¹„êµ ê²°ê³¼ ì¶”ì¶œ
        
        Args:
            analysis_result: AnalysisService ê²°ê³¼
            
        Returns:
            PEG ë¹„êµ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        peg_metrics = analysis_result.get("peg_metrics", {})
        peg_items = peg_metrics.get("items", [])
        
        # LLMì˜ PEGë³„ ì¸ì‚¬ì´íŠ¸
        llm_insights = analysis_result.get("llm_analysis", {}).get("peg_insights", {})
        
        comparisons = []
        
        for item in peg_items:
            peg_name = item.get("peg_name")
            if not peg_name:
                continue
            
            # N-1 í†µê³„
            n_minus_1_stats = {
                "avg": item.get("n_minus_1_avg"),
                "pct_95": item.get("n_minus_1_pct_95"),
                "pct_99": item.get("n_minus_1_pct_99"),
                "min": item.get("n_minus_1_min"),
                "max": item.get("n_minus_1_max"),
                "count": item.get("n_minus_1_count"),
                "std": item.get("n_minus_1_std")
            }
            
            # N í†µê³„
            n_stats = {
                "avg": item.get("n_avg") or item.get("n_value"),
                "pct_95": item.get("n_pct_95"),
                "pct_99": item.get("n_pct_99"),
                "min": item.get("n_min"),
                "max": item.get("n_max"),
                "count": item.get("n_count"),
                "std": item.get("n_std")
            }
            
            comparison = {
                "peg_name": peg_name,
                "n_minus_1": n_minus_1_stats,
                "n": n_stats,
                "change_absolute": item.get("absolute_change"),
                "change_percentage": item.get("percentage_change"),
                "llm_insight": llm_insights.get(peg_name) or item.get("llm_analysis_summary")
            }
            
            comparisons.append(comparison)
        
        return comparisons


__all__ = ["BackendPayloadBuilder"]


